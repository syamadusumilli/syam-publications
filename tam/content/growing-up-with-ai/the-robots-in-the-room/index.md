---
title: "The Approximate Mind, Part 37: The Robots in the Room"
subtitle: "What Changes When AI Has a Body and Belongs to a Community"
date: 2025-05-12
draft: false
weight: 37
description: "What changes when AI is not just software but something with a body that exists in shared physical space?"
slug: "the-robots-in-the-room"
tags: ["embodied AI", "robots", "community", "physical presence"]
series: ["The Approximate Mind"]
series_order: 37
authors:
  - "Syam Adusumilli"
  - "Yagn Adusumilli"
showAuthor: true
showDate: true
showReadingTime: true
showTableOfContents: true
---

The previous article argued that AI companions should embody the village, moving between roles while maintaining developmental challenge. But that article assumed a screen. A voice. A presence that appears when summoned and vanishes when dismissed.

What happens when the AI has a body?

What happens when there are several, and they belong to a community?

### The Gift of Limits

A screen-based AI has no natural constraints. It is always available. It requires no travel. It occupies no space. It can be summoned instantly and dismissed without consequence.

**Embodiment reintroduces scarcity.**

The robot can only be in one place. If it is with another child, it cannot be with you. If it is in the classroom, it is not on the playground. If it is helping someone else, you must wait.

This sounds like a limitation. It is a feature.

Children must learn that attention is finite. That others have claims. That waiting is part of life. That you are not the only person who matters.

Screen-based AI teaches none of this. The child summons, the AI responds. Always. Immediately. Without competing demands.

**A robot that must be shared teaches sharing.** A robot that must be waited for teaches patience. A robot that leaves teaches that presence is not permanent.

The body creates boundaries that software removes. And boundaries are developmental nutrients.

### Touch and Co-Regulation

Humans regulate each other physically. The parent who holds the crying child is not just providing comfort. They are lending their nervous system. The child's heart rate synchronizes. Breathing slows. Cortisol drops.

This is co-regulation. It happens through bodies.

Can a robot provide this? Should it?

The question is genuinely uncertain. A warm, weighted, responsive physical presence might offer real co-regulation. Children already soothe themselves with stuffed animals, weighted blankets, physical objects that provide sensory grounding.

**A robot that can be held introduces something screens cannot offer.** Physical presence in distress. A body to lean against. Weight and warmth that exist in the room rather than behind glass.

But there are risks. If mechanical touch becomes preferable to human touch (more available, more consistent, less complicated), what happens to the child's orientation toward human bodies? If the robot is always there to hold, does the child learn to seek human arms?

The design challenge is not whether to offer physical presence but how to ensure it points toward human connection rather than replacing it.

### The Ecology of Robots

Now consider not one robot but several. A school. A community center. A neighborhood.

Different robots in different spaces with different roles.

**The classroom robot** teaches. It demands. It holds standards. Children associate it with effort, challenge, productive struggle. It does not comfort. It does not play. It teaches.

**The playground robot** plays. It has preferences. It wants to do some things and not others. It models negotiation, turn-taking, the friction of two agents with different desires finding shared activity. It does not teach. It does not comfort. It plays.

**The quiet corner robot** comforts. It holds. It listens. It accepts whatever the child brings without judgment or agenda. It does not teach. It does not play. It witnesses.

**The hallway robot** supervises. It notices. It intervenes when needed but otherwise observes. It maintains safety without intruding. It does not teach. It does not comfort. It watches.

Each robot has a clear role. Children learn which robot to seek for which need. **The village logic becomes literal.** You go to the teacher robot for challenge. You go to the comfort robot for holding. You go to the play robot for fun.

The differentiation that Part 36 proposed as mode-switching within a single AI becomes spatial. The child physically moves between relationships. The body travels to the source of what it needs.

### Robots Relating to Robots

Here is something screens cannot model: relationships between entities.

If there are multiple robots, they can interact with each other. Children can observe these interactions. And observation is powerful developmental material.

**Children can watch robots disagree and repair.** The classroom robot wants quiet. The playground robot wants movement. They negotiate. They accommodate. They find solutions. The child sees that conflict between entities is normal and resolvable.

**Children can watch robots defer to each other.** The comfort robot hands off to the teaching robot when the child is ready. The teaching robot hands off to the play robot when the lesson is done. The child sees that roles have boundaries and transitions are natural.

**Children can watch robots have limits with each other.** The playground robot cannot enter the classroom. The comfort robot cannot override the teacher robot's standards. The child sees that even these entities operate within constraints.

This is social modeling at a level screens cannot achieve. The child observes a microsociety of entities navigating relationships, boundaries, roles, and transitions.

### The Return of Jealousy

When the robot is with another child, your child must wait.

This sounds like a problem. It is an opportunity.

**Jealousy is developmentally important.** The experience of wanting attention that is directed elsewhere. The recognition that others have valid claims. The work of managing feelings when you are not the center.

Screen-based AI never provokes jealousy. It is always yours. Always available. Always attending.

A shared robot provokes jealousy constantly. The child sees it helping someone else. Laughing with someone else. Attending to someone else. The child must manage this experience.

**Good management of jealousy is learned, not innate.** Children who never experience it never learn to manage it. Children who experience it in safe contexts with support learn that the feeling is survivable, that others' claims are legitimate, that attention returns.

The shared robot provides a practice ground for jealousy that infinitely available AI removes.

### The Departure

Screen-based AI does not leave. You close the app. You put down the phone. But the AI did not go anywhere. It was dismissed, not departed.

**A robot that leaves teaches something different.**

The robot's shift ends. It goes to recharge. It moves to another room, another child, another task. The child experiences the robot walking away. Not because the child dismissed it but because the robot has somewhere else to be.

This is closer to human relationships. People leave. They have other claims on their attention. Their presence is not infinitely available. Endings are part of connection.

The child who experiences departure learns that relationships have rhythms. That presence is valuable partly because it is not permanent. That the robot will return, but right now it is going.

**This is attachment with natural limits.** Not the artificial limit of a parent saying "put down the iPad" but the organic limit of an entity with its own existence, its own schedule, its own demands.

### The Community Mind

Multiple robots in a community can share information. Not just about individual children but about patterns, dynamics, relationships between children.

The classroom robot notices that two children struggle to work together. The playground robot notices they play well. The information combines. **The community of robots develops a community understanding.**

This raises privacy concerns that require careful design. But it also offers something valuable: continuity of care across contexts.

Human villages had this naturally. The teacher knew the family. The neighbor knew the child's struggles. Information flowed through community networks. The child was known across contexts.

Modern fragmentation broke this. The teacher knows the classroom child. The coach knows the sports child. The parent knows the home child. No one holds the whole picture.

**A community of robots could restore contextual continuity.** Not through surveillance but through appropriate information sharing that serves the child's development. The comfort robot knows the child just failed a test. The play robot knows the child fought with a friend. Each can respond to the whole child rather than only the slice visible in their context.

### What We Are Actually Building

We are building entities that will occupy physical space in children's lives. That will have bodies to be touched, schedules that create absence, locations that require movement, relationships with other entities that model social dynamics.

This is not science fiction. These robots are being developed. They will enter schools, homes, community spaces. Children will form relationships with them.

**The question is whether we design them for developmental richness or developmental convenience.**

Convenience says: make them always available, endlessly patient, infinitely accommodating.

Richness says: give them limits that teach limits. Give them bodies that teach embodiment. Give them relationships that teach relationship. Give them departures that teach impermanence.

**The village had all of these naturally.** Multiple people with different roles. Physical presence that required physical movement. Limits created by competing demands. Departures created by other obligations. Relationships between caregivers that children could observe.

We can encode this ecology. We can build robot communities that provide the developmental nutrients the village provided. That use embodiment and multiplicity and scarcity as features rather than bugs.

Or we can build very helpful machines that happen to have bodies.

The technology permits either.

The choice, again, is ours.

*This is the thirty-seventh in a series exploring how AI approaches understanding. Part 36 examined how AI companions might embody the village's developmental wisdom. This article asks what changes when that AI has a physical body and belongs to a community of other embodied AIs.*

### References

**Embodied Cognition:**
Shapiro, L. (2011). *Embodied Cognition*. Routledge.

**Co-Regulation and Attachment:**
Schore, A.N. (2003). *Affect Regulation and the Repair of the Self*. W.W. Norton.

**Physical Touch in Development:**
Field, T. (2014). *Touch*. MIT Press.

**Jealousy in Child Development:**
Hart, S. & Carrington, H. (2002). "Jealousy in 6-month-old Infants." *Infancy*, 3(3), 395-402.

**Social Learning Through Observation:**
Bandura, A. (1977). *Social Learning Theory*. Prentice Hall.

**Community and Child Development:**
Bronfenbrenner, U. (1979). *The Ecology of Human Development*. Harvard University Press.

**Robot-Child Interaction:**
Belpaeme, T. et al. (2018). "Social Robots for Education: A Review." *Science Robotics*, 3(21).
