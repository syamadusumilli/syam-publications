---
title: "The Approximate Mind, Part 50: The Monoculture"
date: 2025-06-26
draft: false
weight: 50
description: "Margaret's grocery AI has never recommended Dot's honey. Not because the algorithm is biased against Dot. Because Dot does not exist in the data."
slug: "the-monoculture"
tags: ["monoculture", "diversity", "local economy", "recommendations", "Dot"]
series: ["The Approximate Mind"]
series_order: 50
authors:
  - "Syam Adusumilli"
  - "Yagn Adusumilli"
showAuthor: true
showDate: true
showReadingTime: true
showTableOfContents: true
---

Dot has sold honey from a wooden stand on Route 9 for twenty-three years. The stand is a plywood box she built with her husband before he died, painted white and repainted every spring, with a hand-lettered sign that says HONEY and a coffee can for cash. She keeps bees on eleven acres behind her house. The operation, if you can call it an operation, produces about four hundred pounds a year in a good season. She sells it in Mason jars with handwritten labels that say the date and whether it's wildflower or clover.

Margaret has been buying Dot's honey for fifteen of those twenty-three years. She discovered it by accident, driving Route 9 to a dentist appointment and spotting the sign. She pulled over because it was a nice day and she was early. She bought a jar because Dot was friendly and the honey was golden and warm from the sun. She came back because the honey was better than anything at the grocery store, and because she liked Dot, and because after a few visits she felt that buying Dot's honey was part of who she was. A person who buys local honey. A person who stops at farm stands. A person who has a relationship with the woman who keeps the bees.

Margaret's grocery AI has never recommended Dot's honey.

This is not because the algorithm is biased against Dot. It is because Dot does not exist in the data the algorithm uses to make recommendations. She has no website, no customer reviews, no delivery infrastructure, no SKU, no supply chain integration, no nutritional information panel, no brand identity, no digital presence of any kind. By every metric the recommendation system uses to evaluate honey, Dot's product is invisible. Not rejected. Not ranked low. Simply absent.

**By the measures that matter to the algorithm, Dot does not exist.**

Dot would find this funny, in the way she finds most technology funny, which is to say with genuine bemusement rather than hostility. She has survived twenty-three years without an algorithm. Her customers find her the way they have always found her: by driving past, by hearing from a neighbor, by noticing the sign. These are analog discovery mechanisms. They work slowly, unreliably, and within a narrow radius. They also work.

The question is how long they will continue to work in an environment optimized for their replacement.

### Friction as Habitat

Ecologists use a concept called habitat requirements. Every species depends not just on the presence of food and the absence of predators, but on a set of environmental conditions that make its way of life possible. Salmon need cold water and gravel beds. Monarch butterflies need milkweed along their migration route. Prairie dogs need open grassland with the right soil density for burrowing. Remove any of these conditions and the species does not die from direct attack. It dies from habitat loss. The environment no longer supports the life.

Market diversity has habitat requirements too.

Small businesses, local producers, eccentric entrepreneurs, regional specialists, these economic species depend on three forms of friction that AI-mediated commerce is systematically eroding. The first is discovery friction: finding things by accident, through proximity, through word of mouth, through the serendipity of driving past a hand-lettered sign on a nice day. The second is loyalty friction: continuing to buy from someone because of relationship, because of habit, because of identity, because of what it says about you that you buy local honey even though it costs more. The third is tolerance for imperfection: accepting that the farm stand isn't open on Tuesdays, that the local bookshop doesn't have every title, that the neighborhood restaurant's menu is small, that the experience is not optimized.

Each of these frictions is, from the perspective of the individual consumer, a cost. Discovery friction means you might never find the best product. Loyalty friction means you might pay more than necessary. Tolerance for imperfection means you might be inconvenienced. AI recommendation systems are designed, correctly from a narrow perspective, to reduce these costs. They surface the best-reviewed, lowest-priced, most-available option. They optimize the individual transaction.

But the frictions they are eliminating are not waste. They are habitat.

**Dot's honey exists because the road exists, and the road is slow, and slowness creates the conditions for noticing, and noticing creates the conditions for stopping, and stopping creates the conditions for relationship.** Remove any link in that chain and the honey still exists on Dot's shelves, but nobody new buys it.

This is already happening. Not to Dot specifically, not yet, but to the economic class she represents. The small, the local, the idiosyncratic, the things that depend on being stumbled upon rather than searched for. AI recommendation systems do not compete with these businesses. That would imply a contest. What they do is subtler and more thorough: they build an environment in which the conditions for small-scale economic life quietly disappear.

The species dies from habitat loss, not predators.

### The Flywheel

The mathematics are unforgiving.

A recommendation system needs data to make recommendations. The more purchase data a product generates, the better the system can predict who will want it. Better predictions produce more purchases. More purchases produce more data. The cycle repeats.

This is not a conspiracy. It is a feedback loop. And feedback loops do not need anyone to intend their consequences.

Consider honey. A large commercial brand sells millions of jars. Every purchase generates data: who bought it, what else they bought, when they bought it, whether they bought it again. The recommendation algorithm can model this product with extraordinary precision. It knows which demographic segments prefer it, which price points trigger purchase, which competing products it wins against. When Margaret's grocery AI evaluates honey options, this brand arrives with a dense data profile that allows confident recommendation.

Dot's honey has been purchased by perhaps two thousand people over twenty-three years. Most paid cash. None of these transactions generated data that any recommendation system can access. The algorithm cannot model Dot's honey because there is nothing to model. It is not that the algorithm evaluated Dot's product and found it lacking. It is that Dot's product never entered the evaluation.

**More data produces better recommendations. Better recommendations produce more customers. More customers produce more data. This is not monopoly by conspiracy. It is monopoly by algorithm.**

James, who at twenty-three is building his life in a world Margaret did not grow up in, experiences this flywheel differently. When he moved to a new neighborhood last year, he asked his AI assistant to find good coffee nearby. It recommended three shops, all chains or well-reviewed independents with robust digital presences. Two blocks from his apartment, there is a Dominican cafe run by a woman named Elena's cousin. It has no website, no Yelp reviews, no Google listing. The coffee is strong and comes in small cups and the woman behind the counter knows everyone's name within two visits.

James has never been there. He walks past it every morning on his way to the shop the algorithm recommended. He is not choosing against Elena's cousin's cafe. He is choosing from a menu that does not include it. His world has been curated, and the curation is invisible to him, and the invisibility is the point.

This is Part 26's observation about democratized cognition turned toward its economic shadow. When inference becomes influence, the influence extends beyond what you think to what you buy, what you eat, where you go, and who you encounter. The algorithm that helps James find good coffee also determines which coffee shops survive. Discovery is not neutral. In an algorithmic economy, what cannot be discovered cannot exist.

### The Biological Lesson

There is a reason we use the word "monoculture" as a warning.

In agriculture, monoculture means planting the same crop across vast acreages. It is spectacularly efficient. You optimize one seed variety for yield, disease resistance, and harvesting ease. You plant it everywhere. You develop equipment specifically for this crop. You build supply chains around it. Output per acre rises. Cost per unit falls. By every measure of productivity, monoculture wins.

Until it doesn't.

The Irish Potato Famine killed a million people and displaced a million more because an entire nation's food supply depended on a single variety of potato. When blight arrived, there was no genetic variation to resist it. The Gros Michel banana, once the world's dominant commercial variety, was effectively wiped out by Panama disease in the 1950s. The Cavendish banana that replaced it now faces the same pathogen's successor, and there is no obvious replacement because the industry optimized around a single variety again.

Monoculture trades resilience for efficiency. It produces abundance under normal conditions and catastrophe under stress. The vulnerability is not a design flaw. It is a mathematical consequence of optimization itself. When you select for a single variable across an entire system, you get convergence. Convergence means every node fails to the same threat.

Economic monocultures work identically.

When every AI recommendation system points customers toward the same three suppliers in a given category, those suppliers become systemically important. Their success is not earned through persistent excellence. It is maintained through data advantage. They have more reviews, more purchase history, more algorithmic visibility. They become the default. When everyone buys from the default, the default becomes infrastructure. And when infrastructure fails, there is no alternative ecosystem to absorb the shock, because the alternative ecosystem was made of small producers who went dark when nobody could discover them anymore.

**Resilience requires redundancy. Redundancy requires variety. Variety requires friction. Remove the friction and you begin the collapse from the bottom.**

Dot's honey operation is, from a systems perspective, a form of biodiversity. Not because her honey is better than commercial honey (though Margaret would argue it is), but because her existence as an independent producer represents optionality. If the commercial supply chain breaks, if the large brand faces contamination, if shipping routes are disrupted, Dot and the thousands of producers like her represent an alternative path. They are the wild varieties that breeders turn to when the cultivated strain fails.

But optionality, like biodiversity, is not valued by the system that benefits from its presence until the moment it is needed and already gone.

### The Shaping of Want

There is a subtler loss than the disappearance of products. It is the disappearance of the desires that products served.

AI recommendation does not merely surface existing preferences. It shapes what people learn to want. If every food recommendation system nudges toward the same set of highly rated, data-rich options, users converge not just in purchasing but in taste. The person who would have discovered Ethiopian cuisine through an adventurous friend's recommendation never encounters it, because their engagement profile says Italian. The person who would have developed a passion for obscure jazz never hears it, because the algorithm determined that mainstream alternatives generate more listening time. The person who would have found Dot's honey and developed a relationship with a beekeeper never stops on Route 9, because their grocery needs are met before they reach the car.

Part 48 explored how algorithmic perception constructs identity, how being seen as a particular kind of person makes it easier to become that person. The economic corollary is that being offered a particular kind of world makes it harder to want a different one. We learn to want by encountering things we did not know we wanted. Recommendation systems, by definition, surface things the algorithm predicts we already want. The circle closes.

**Optimization of commerce is also the homogenization of desire.**

This is not the same as saying everyone becomes the same. Personalization creates niches. But the niches are algorithmically determined, which means they are built from patterns in existing data, which means they reflect the past rather than enabling the future. You are offered the version of yourself that the data supports. Growth, surprise, the encounter with the genuinely unfamiliar, these happen at the edges of what recommendation can predict. And the edges are precisely where the algorithm has the least data and therefore the least ability to operate.

Innovation lives at the edges too. The weird product nobody asked for. The regional cuisine that goes national because adventurous eaters carry it across boundaries. The garage startup that solves a problem nobody realized they had. These depend on serendipity, on slack in the system, on the productive disorder of an economy that has not been fully rationalized. AI optimization is structurally hostile to edges. It recommends what has data. What has data is what has volume. What has volume is what already won.

James might have been the person to discover Elena's cousin's cafe and become a regular and bring friends and write about it and turn it into one of those local success stories that neighborhood blogs celebrate. Instead, he drinks good coffee at a place an algorithm chose for him, and Elena's cousin's cafe waits for foot traffic that diminishes each quarter as more of James's generation navigates the world through recommendation rather than exploration.

The loss here is not just economic. It is experiential. James lives in a slightly smaller world than he might have, without knowing it, and the smallness is maintained by systems that experience themselves as helpfully curating a large world on his behalf.

### What Survives

Dot does not think about any of this. She checks her hives in the morning, bottles honey in the afternoon, and puts jars on the stand when they are ready. Her customers come or they do not. She has never had a good year and a bad year that she could explain. Beekeeping is like that.

Margaret still drives to Route 9 when she needs honey. She does this partly because Dot's honey is good, and partly because the drive is pleasant, and partly because buying honey from Dot is one of the things Margaret does that no system told her to do. It is, in the language of Part 49, an unmonitored act. The algorithm does not know about it. The grocery AI has not factored it into Margaret's preference model. Margaret's actuarial identity does not include "buys honey from a roadside stand." This absence, this gap in the data, is a form of freedom Margaret does not know she has and would not think to value until it was gone.

But Margaret is seventy-two, and her driving is becoming less reliable, and the day will come when Route 9 is not a casual errand but an expedition. And then Dot's honey will lose another customer, not because the algorithm took her away but because the world the algorithm built did not include the infrastructure for Margaret to keep choosing the thing the algorithm never offered.

**The monoculture does not kill what it replaces. It removes the conditions for replacement to survive.**

Is there a version of AI-mediated commerce that preserves variety? Possibly. Recommendation systems could be designed to introduce friction deliberately, to surface the unexpected, to weight novelty and locality alongside ratings and data density. Some systems already try this. "You might also like" is sometimes genuinely surprising.

But the incentive structure resists it. Recommendations that lead to purchases generate revenue. Recommendations that lead to exploration generate data but not necessarily transactions. A system optimized for conversion will always tend toward the safe recommendation, the well-reviewed choice, the data-rich option. Variety is a public good. Recommendation systems are private infrastructure. The misalignment is structural, not incidental.

We do not know whether this misalignment is solvable within the current architecture of AI-mediated commerce, or whether it requires something more fundamental: an economic framework that treats variety itself as valuable, the way environmental frameworks treat biodiversity. We do know that the problem cannot be solved by individual consumer choice, because the whole point is that individual choice is being shaped by systems that do not value variety. You cannot choose your way out of a curated world, because the choices themselves are curated.

James will not save Elena's cousin's cafe by deciding to explore more. He would need to know it was there, and the systems he relies on for knowing what is there do not show it to him. Margaret will not save Dot's honey by continuing to drive to Route 9, because Margaret is one person and the ecology that sustained a thousand Dots is changing beneath them both.

What might save them is a recognition that friction, the very thing AI optimization is designed to eliminate, is not always waste. That the slow drive, the accidental discovery, the imperfect choice, the loyalty that exceeds logic, these are not bugs in the economic system. They are the habitat in which economic diversity lives.

And that habitat, like all habitat, is easier to destroy than to rebuild.

---

*This is Part 50 of The Approximate Mind, a series examining how AI might serve human flourishing rather than human extraction. Part 49 explored the confluence of multiple AI systems converging on a single life. This article asks what happens to economic diversity when the friction that sustained it is optimized away, and whether the monoculture that remains can survive its own efficiency.*

---

**Ecology and Monoculture:**
Pollan, Michael. *The Botany of Desire: A Plant's-Eye View of the World*. Random House, 2001.
Scott, James C. *Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed*. Yale University Press, 1998.
Tilman, David. "The Ecological Consequences of Changes in Biodiversity." *Ecology*, vol. 80, no. 5, 1999, pp. 1455-1474.

**Fragility and Resilience:**
Taleb, Nassim Nicholas. *Antifragile: Things That Gain from Disorder*. Random House, 2012.
Perrow, Charles. *Normal Accidents: Living with High-Risk Technologies*. Princeton University Press, 1984.

**Market Concentration and Innovation:**
Schumpeter, Joseph A. *Capitalism, Socialism and Democracy*. Harper & Brothers, 1942.
Wu, Tim. *The Curse of Bigness: Antitrust in the New Gilded Age*. Columbia Global Reports, 2018.
Khan, Lina M. "Amazon's Antitrust Paradox." *Yale Law Journal*, vol. 126, no. 3, 2017, pp. 710-805.

**Recommendation Systems and Economic Effects:**
Hosanagar, Kartik. *A Human's Guide to Machine Intelligence*. Viking, 2019.
Fleder, Daniel, and Kartik Hosanagar. "Blockbuster Culture's Next Rise or Fall: The Impact of Recommender Systems on Sales Diversity." *Management Science*, vol. 55, no. 5, 2009, pp. 697-712.

**Local Economies and Serendipity:**
Jacobs, Jane. *The Death and Life of Great American Cities*. Random House, 1961.
Berry, Wendell. "The Idea of a Local Economy." *Orion Magazine*, Winter 2001.
