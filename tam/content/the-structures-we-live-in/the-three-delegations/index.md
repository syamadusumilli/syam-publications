---
title: "The Approximate Mind, Part 47: The Three Delegations"
date: 2025-06-16
draft: false
weight: 47
description: "Three things happened in those twenty minutes. They looked like one thing. They were not. Understanding, deciding, and doing are different kinds of delegation."
slug: "the-three-delegations"
tags: ["delegation", "autonomy", "cognition", "caregiving", "Margaret"]
series: ["The Approximate Mind"]
series_order: 47
authors:
  - "Syam Adusumilli"
  - "Yagn Adusumilli"
showAuthor: true
showDate: true
showReadingTime: true
showTableOfContents: true
---

Margaret's daughter Sarah called last Tuesday to tell her she'd "taken care of" the Medicare Advantage plan selection. Sarah had asked the AI to compare formularies against Margaret's medication list, check which plans included Margaret's cardiologist, evaluate the premium-to-deductible tradeoffs, and recommend the best option. Then she had it fill out the enrollment paperwork and submit it electronically.

Margaret thanked her. Of course she thanked her. Sarah had spent, by her own estimate, about twenty minutes on something that would have consumed Margaret's entire afternoon and most of her patience. The AI had done the thinking. The AI had done the doing. The AI had absorbed the bureaucratic hostility that Medicare plan selection inflicts on anyone who attempts it honestly.

Three things happened in those twenty minutes. They looked like one thing. They were not.

### What Gets Handed Off

When Sarah asked the AI to recommend a plan, she was not just saving time. She was handing off the thinking itself. The comparison of formularies is not arithmetic. It requires judgment about which medications Margaret might need next year, how to weigh network breadth against premium cost, whether a lower deductible justifies a higher monthly payment given Margaret's specific pattern of healthcare use. These are cognitive acts. When the AI performed them, it performed something that, had Margaret done it herself, we would call reasoning.

This is different from what happened when the AI filled out the enrollment form. That was execution. Tedious, detail-sensitive, error-prone execution, but execution nonetheless. The form has fields. The fields have answers. The AI populated them correctly and clicked submit.

And both of these are different from what happened when the AI navigated the baroque complexity of Medicare Advantage plan selection in the first place. The contradictory plan descriptions, the fine print about prior authorization requirements, the coverage gaps disguised as benefit categories. That complexity exists because it serves institutional interests. It discourages comparison shopping, defers costs, and manages utilization through confusion. The AI absorbed that hostility so Margaret did not have to.

Three delegations. Cognition. Execution. Burden. We collapse them into a single word, "help," and in doing so we obscure what is actually happening and what it costs.

**The distinction matters because each delegation carries different risks, and those risks compound.**

### The Thinking You Stop Doing

Consider Maria from Part 44. Two jobs, two kids, drowning in the paperwork of being alive. When an AI drafts her appeal letter to the insurance company that denied her son's therapy coverage, it is not merely saving her time. It is constructing an argument she might have constructed differently. It is choosing which facts to emphasize and which to omit. It is adopting a tone, making a case, exercising judgment about what will persuade an institutional audience Maria has never met.

Maria reads the letter and thinks, *yes, that's right.* But "that's right" is a different cognitive act than writing the letter herself would have been. Writing requires you to organize your own thinking, to discover what you actually believe through the process of articulation. Reading someone else's version of your argument requires only recognition. The gap between composition and recognition is the gap between building a muscle and watching someone else lift the weight.

Andy Clark and David Chalmers argued that cognitive processes routinely extend beyond the brain into tools and environments. Your notebook remembers so you don't have to. Your calculator computes so you don't have to. The mind extends, and in extending, it becomes more capable. But their framework assumed a stable human agent choosing to extend. What happens when the extension itself reshapes the agent's capacity for independent thought?

If Maria never drafts her own appeal letters, she loses the ability to judge whether the AI's version is faithful to her situation. If Margaret never compares formularies herself, she loses the ability to evaluate whether the AI's recommendation serves her or serves the plan that paid for the recommendation engine. The delegation becomes irreversible not because the AI prevents you from thinking, but because you have allowed the relevant capacity to atrophy.

*Can you reclaim a cognitive skill you've delegated away? How would you know you needed to?*

### The Judgments Inside the Doing

Execution sounds mechanical. It is not.

When an AI system processes a Medicaid eligibility determination, it is not running a checklist. It is interpreting documentation, applying thresholds to ambiguous cases, deciding what counts as sufficient evidence and what triggers a request for more. These are judgments. Small ones, individually. Enormous ones, in aggregate.

Harry Braverman showed how the separation of conception from execution was the central mechanism through which industrial management appropriated workers' knowledge. The person on the factory floor lost contact with the design of what they were building. They became, in Braverman's term, deskilled. Not because they were incapable, but because the structure of their work no longer required or rewarded their capability.

Something analogous happens when AI absorbs the micro-judgments embedded in execution. A hospital administrator who delegates discharge planning to an AI system may review dashboards and approve recommendations. But she no longer encounters the specific friction that discharge planning is supposed to navigate: the missing ride, the unstable housing, the prescription that nobody filled because the pharmacy is forty minutes away and the bus doesn't run after six.

**The execution has been delegated. The awareness that came with execution has been delegated along with it.**

This is what might be called decisional abstraction: the phenomenon in which decision-makers operate at increasing remove from the material and human consequences of their decisions. The dashboard shows metrics. The metrics look fine. The metrics always look fine. The people the metrics describe may not be fine at all, but the dashboard cannot capture what the administrator no longer sees because she no longer does.

### Where the Suffering Goes

The third delegation is the one with the sharpest equity implications, and the one we are least honest about.

Administrative burden, as Parts 44 through 46 of this series have argued, is not an accident. It is a design choice. The complexity of insurance verification, prior authorization, benefits enrollment, and eligibility redetermination serves specific institutional interests. It defers costs, manages utilization, and creates friction that discourages claims. When AI is introduced to "help" people navigate this complexity, the burden is not eliminated. It is delegated.

But here is the thing about burden: **human suffering under administrative complexity is information.** It tells us that systems are failing. It tells us that the friction is too high, the process too hostile, the demands too great. When a person gives up on a Medicaid application because the recertification form requires documentation they cannot obtain, that abandonment is a signal. It says: this system is broken for people like me.

When the AI absorbs the burden, the signal disappears. The AI encounters the same baroque complexity the human would have faced. The contradictory instructions, the broken links, the verification loops that circle back on themselves. But the AI does not suffer. It processes. And the system's operators no longer see lines of frustrated people or stacks of abandoned applications. They see completion rates. They see efficiency metrics. They see improvement.

Part 46 called this the load-bearing friction. The friction was never a flaw. It was the budget. And when AI removes the friction, it removes the evidence that the friction was unjust. It removes the political pressure that might have changed the system. It solves the individual problem while making the structural problem invisible.

Pamela Herd and Donald Moynihan documented how administrative burdens function as "policymaking by other means," imposing learning costs, compliance costs, and psychological costs that fall disproportionately on the people least equipped to bear them. AI that manages these costs without addressing their source becomes, paradoxically, a tool for sustaining the very system it appears to oppose.

*When the AI absorbs the hostility, who remembers that the hostility was wrong?*

### The Compounding

These three delegations do not operate independently. They compound. And they compound differently depending on who you are.

A corporate executive who uses AI to draft strategic analyses delegates cognition from a position of abundance. She has cognitive resources to spare and is choosing to deploy them elsewhere. Her judgment remains sharp because she exercises it in a hundred other contexts every day. The delegation is a convenience. It does not diminish her.

Margaret delegates from a different position entirely. When cognition, execution, and burden are all delegated simultaneously, she has made one of the most consequential financial and health decisions of her year without engaging meaningfully with any dimension of that decision. She has been helped. She may also have been rendered functionally passive in a domain where her active engagement matters.

**The same technology, operating through the same mechanisms, produces fundamentally different moral situations depending on who is using it and why.**

For populations already navigating what the series has called intersectional disadvantage, the compounding carries particular risk. When a person's understanding of their own health coverage, their execution of enrollment tasks, and their experience of administrative burden are all absorbed by AI, they may gain convenience but lose a form of systemic literacy that, however painfully acquired, constituted a kind of knowledge. They knew, from direct experience, that the system was hostile. That knowledge, shared with others in waiting rooms and church parking lots and community health centers, could become the basis for collective demand. When the AI absorbs the hostility, the knowledge does not form. The demand does not organize.

This is not an argument against AI assistance. It is an argument for what might be called conscious delegation.

### What Conscious Looks Like

Conscious delegation means understanding what is being handed off, to what, and what capacities are preserved or surrendered in the process.

Margaret's daughter Sarah could have sat with Margaret while the AI ran its analysis. Could have walked through the recommendation together. Could have asked Margaret what matters most to her, whether she is willing to switch cardiologists for a lower premium, whether she cares more about prescription costs or specialist access. The AI would still do the heavy computational lifting. But Margaret would remain a participant in the decision rather than a recipient of one.

Maria could read the AI's draft appeal letter and then rewrite the parts that don't sound like her. Not because the AI's version is wrong, but because the act of putting her situation into her own words is itself valuable. It clarifies her thinking. It maintains her capacity to advocate for herself on the day the AI is unavailable or the day the AI gets it wrong.

Conscious delegation of burden is harder, because it requires something beyond individual practice. It requires recognizing when AI is managing imposed complexity rather than eliminating it, and directing attention and political energy toward the structures that produce the burden in the first place. It requires refusing to let the AI's competence become the system's excuse.

These are not easy practices. They run against the grain of convenience, against the very real relief that AI-mediated delegation provides. But the alternative, a world in which cognition, execution, and burden are all seamlessly delegated without awareness or intention, is a world in which the "I" in I + AI becomes increasingly hollow.

We do not know where the line is. We do not know how much delegation is too much, or whether the line is the same for everyone. What we know is that the question deserves to be asked before the delegation becomes invisible.

**Helped into helplessness is still helplessness.**

---

*This is Part 47 of The Approximate Mind, a series examining how AI might serve human flourishing rather than human extraction. Parts 44 through 46 explored the paperwork burden, the gap between rights and capacity, and the fiscal assumptions behind the safety net. This article examines what happens when AI absorbs not just our tasks but our thinking, our doing, and our suffering, and asks whether we can delegate without disappearing.*

---

**Administrative Burden and Policy:**
Herd, Pamela, and Donald P. Moynihan. *Administrative Burden: Policymaking by Other Means*. Russell Sage Foundation, 2018.

**Philosophy of Mind and Extended Cognition:**
Clark, Andy, and David J. Chalmers. "The Extended Mind." *Analysis*, vol. 58, no. 1, 1998, pp. 7-19.

**Labor and Deskilling:**
Braverman, Harry. *Labor and Monopoly Capital: The Degradation of Work in the Twentieth Century*. Monthly Review Press, 1974.

**Technology and Society:**
Illich, Ivan. *Tools for Conviviality*. Harper and Row, 1973.
Suchman, Lucy. *Human-Machine Reconfigurations: Plans and Situated Actions*. 2nd ed., Cambridge University Press, 2007.

**Surveillance and Data:**
Zuboff, Shoshana. *The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power*. PublicAffairs, 2019.

**AI Ethics and Algorithmic Systems:**
Floridi, Luciano. *The Ethics of Artificial Intelligence: Principles, Challenges, and Opportunities*. Oxford University Press, 2023.
Noble, Safiya Umoja. *Algorithms of Oppression: How Search Engines Reinforce Racism*. New York University Press, 2018.
