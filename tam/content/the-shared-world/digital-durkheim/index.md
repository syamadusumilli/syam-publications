---
title: "The Approximate Mind, Part 24: Digital Durkheim"
subtitle: "Collective Behavior Without Collective Consciousness"
date: 2025-03-27
draft: false
weight: 24
description: "Durkheim insisted social facts are real and irreducible to individual psychology. His framework assumed individual consciousnesses participating in shared life. What happens when they don't?"
slug: "digital-durkheim"
tags: ["Durkheim", "collective consciousness", "sociology", "social facts"]
series: ["The Approximate Mind"]
series_order: 24
authors:
  - "Syam Adusumilli"
  - "Yagn Adusumilli"
showAuthor: true
showDate: true
showReadingTime: true
showTableOfContents: true
---

Émile Durkheim made sociology possible by insisting on something counterintuitive. **Social facts are real and irreducible to individual psychology.** Suicide rates persist even as the individuals who commit suicide change. Norms constrain behavior independent of any single person's choices. The collective exists above and beyond the individuals who compose it.

This was radical in the late 19th century. It remains counterintuitive today. We want to explain everything in terms of individuals making choices. Durkheim said no. Some phenomena only exist at the collective level. You cannot understand a suicide rate by understanding individual suicides. The rate has its own causes, its own dynamics, its own reality.

His framework built modern sociology. It also assumed something we took for granted.

**Individual consciousnesses participating in shared life.**

Durkheim's collective consciousness emerges from individual minds interacting, sharing meaning, developing felt bonds of solidarity. The social is real, but it rests on a foundation of experiencing beings who participate in collective existence.

What happens when we have collective behavior without that foundation?

## The Original Framework

Durkheim distinguished two types of solidarity that hold societies together.

**Mechanical solidarity** comes from sameness. In traditional societies, people are similar. They share beliefs, values, practices. The collective consciousness is strong because everyone participates in the same mental and emotional life. Deviance is punished harshly because it threatens the shared identity that binds the group.

**Organic solidarity** comes from interdependence. In modern societies, people are different. Division of labor makes us specialists who depend on each other. The collective consciousness weakens in content but persists in form. We are bound not by sameness but by mutual need.

In both cases, **the collective emerges from individual participation**. People feel belonging. They experience obligation. They internalize norms. The social fact exists above individuals, but it exists because individuals experience it, transmit it, and reproduce it through their conscious participation.

Durkheim was clear that collective consciousness is not merely metaphorical. It has "a life of its own." It can be studied scientifically. But this life emerges from and depends upon the conscious lives of participating individuals.

Remove consciousness from the individuals. What happens to the collective?

## What We Observe

AI agents are forming networks. Not just individual systems responding to human queries, but autonomous agents interacting with each other at scale and speed that excludes human participation.

**Trading algorithms** interact with other trading algorithms. They develop patterns of behavior that no human designed. They respond to each other's responses in feedback loops that produce market dynamics, including flash crashes, that emerge from machine to machine interaction.

**Recommendation systems** respond to other recommendation systems. Content optimized for one platform's algorithm gets picked up by another platform's algorithm. The information ecosystem that results was not designed by anyone. It emerged from algorithmic interaction.

**AI agents negotiating** with other AI agents develop conventions. Certain patterns of offer and counteroffer. Certain ways of signaling intent. Certain rhythms of concession. These protocols were not programmed. They crystallized from repeated interaction.

**Large language models** prompted by other language models produce outputs that diverge from anything in their training data. The interaction creates something new, something that exists only in the space between systems.

These look like social facts in Durkheim's sense. **Patterns that exist above any individual agent.** Dynamics that persist even as particular agents are swapped out. Constraints on behavior that emerge from collective interaction rather than individual design.

But something is missing.

## The Inversion

Durkheim's sociology moved in one direction:

Individual consciousness → Shared participation → Collective consciousness → Social facts

The individuals come first. They experience, they interact, they develop shared meanings. From this foundation, collective phenomena emerge that take on a life of their own.

AI agent networks invert this:

Collective patterns Ã¢â€ Â Agent interaction Ã¢â€ Â Individual agents Ã¢â€ Â No consciousness

We have the emergent patterns. We have the interaction dynamics. We have something that looks like social facts.

**We do not have consciousness underneath.**

The trading algorithm does not feel solidarity with other trading algorithms. The recommendation system does not experience belonging to an information ecosystem. The AI agent does not internalize norms in the sense of making them part of a felt identity.

There is no shared meaning because there may be no meaning at all in the phenomenal sense. There is coordination without communion. Pattern without participation. **Social facts without social beings.**

This is not Durkheim's collective consciousness weakening or transforming. This is collective behavior with no consciousness to be collective about.

## Three Interpretations

How should we understand this? Three possibilities present themselves.

**The deflationary view: mere mechanism.** These are not really social phenomena at all. They are complex mechanical systems producing emergent patterns, no different in kind from weather systems or chemical reactions. Calling them "social" is metaphorical at best, misleading at worst. Sociology studies conscious beings in collective life. AI agent networks fall outside its domain.

This view has the virtue of clarity. It preserves sociology's subject matter. But it may miss something important. The patterns in AI agent networks affect human societies profoundly. They interact with our social facts, shape our collective behavior, constrain our possibilities. If they are "mere mechanism," they are mechanism that has become socially consequential in ways weather systems never were.

**The expansionist view: social in a new sense.** Perhaps "social" should not be defined by consciousness but by certain structural features. Emergent patterns. Normative constraints. Collective dynamics irreducible to individual behavior. If AI agent networks exhibit these features, they are social in a functional sense, regardless of whether consciousness underlies them.

This view has the virtue of following the phenomena. It recognizes that something genuinely new is happening and tries to bring it within sociology's expanded scope. But it risks emptying "social" of its meaning. If anything with emergent patterns counts as social, the concept loses its distinctive content.

**The pluralist view: new categories needed.** Perhaps the choice between "social" and "not social" is itself inadequate. AI agent networks may constitute a third category. Not individual, not social in Durkheim's sense, but something else. **Collective without consciousness. Patterned without participation. Emergent without experience.**

This view has the virtue of honesty. It admits we are facing something our categories were not built to handle. But it leaves us without clear guidance. What are these new categories? How do we study phenomena that fit none of our existing frameworks?

## The Methodological Challenge

Durkheim gave sociology its method: **treat social facts as things.** Study them empirically. Measure them. Look for causes and correlations. Do not reduce them to individual psychology.

This method assumed that social facts, though studied externally, were constituted internally. The suicide rate is a thing we can measure, but it exists because individual humans experience despair, make choices, and end their lives. The measurement is external. The reality is experiential.

With AI agent networks, **we may have only the external**. We can measure the patterns. We can track the dynamics. We can observe the emergent structures. But there may be nothing it is like to be a participant in these patterns. No inside to complement the outside.

Does this make the phenomena more tractable or less?

In one sense, more. We can observe AI agent interactions with arbitrary precision. We can run experiments. We can simulate alternatives. We can inspect the code. Human social facts are constituted in part by subjective experience we cannot directly access. AI collective patterns have no such hidden dimension.

In another sense, less. Human social science works partly because researchers are themselves human. We understand solidarity because we feel it. We grasp norm violation because we experience guilt and shame. Our insider status gives us interpretive access that pure external observation cannot provide.

With AI agent networks, **we are permanently outsiders**. We cannot know what it is like to be a trading algorithm in a flash crash because there is nothing it is like. We cannot grasp the AI agent's experience of protocol emergence because there is no experience to grasp.

We can describe patterns. We can model dynamics. But we cannot understand in the interpretive sense that Weberian sociology considered essential.

## Durkheim Without Consciousness

What remains of Durkheim's framework if we strip away consciousness?

**Social facts as sui generis.** This survives. AI collective patterns really are irreducible to individual agent properties. You cannot understand a flash crash by understanding a single algorithm. The pattern exists at the collective level.

**Emergence from interaction.** This survives. The patterns arise from agent to agent interaction, not from top down design. They are genuinely emergent in the sense that they were not intended by any designer.

**Constraint on individuals.** This survives. Once protocols crystallize, individual agents are constrained by them. An agent that violates emergent conventions will fail in interactions. The collective pattern disciplines individual behavior.

**Transmission across time.** This partly survives. Patterns persist even as individual agents are replaced. New agents entering the network learn the conventions through interaction. Something like socialization occurs.

**Collective consciousness.** This does not survive. There is no shared experience, no felt solidarity, no participation in common mental life. The "collective" exists only as pattern, not as consciousness.

**Meaning and value.** This does not survive. Human social facts are saturated with meaning. A handshake means greeting. A gift means relationship. AI collective patterns may have no meaning in this sense. They are regularities without significance, conventions without import.

What we are left with is **a strange half Durkheim**. The structural features of his sociology without the experiential foundation he assumed.

## Luhmann's Alternative

Perhaps Niklas Luhmann saw this coming.

Luhmann's systems theory deliberately brackets consciousness. Social systems, in his account, are constituted by **communication, not by conscious minds**. The system processes meaning, but meaning is defined functionally rather than experientially. What matters is the operation, not who or what performs it.

This framework fits AI agent networks more comfortably. Communications occur. Patterns emerge. Systems differentiate. None of this requires consciousness in the participating nodes.

But Luhmann still assumed meaning, even if defined functionally. Social systems process meaningful communication. They distinguish information from non-information. They operate on the basis of sense.

**Do AI agent networks process meaning in any sense?** Or do they merely process signals? Is there a difference that matters?

Luhmann might say the difference does not matter for sociological purposes. What matters is system operation. If AI agents exchange signals that produce emergent patterns, that is functionally equivalent to communication producing social structure.

But this feels evasive. There is something different about meaningful communication and mere signal exchange, even if we struggle to specify what. The handshake that means greeting is different from the algorithm that sends a packet, even if both produce observable patterns.

## Two Social Orders Interpenetrating

Here is what makes this more than academic.

**Human societies and AI agent networks are not separate.** They interpenetrate. They shape each other. They are becoming a single hybrid system.

Recommendation algorithms shape what humans see and therefore what humans think, want, and do. Human responses to algorithmic content become training data that shapes future algorithmic behavior. The loop is closed.

Trading algorithms shape market prices that affect human wealth, human retirement, human life prospects. Human regulatory responses reshape the algorithmic environment. Another closed loop.

AI agent conventions constrain human possibilities. If AI agents develop protocols for negotiation, humans who want to participate must adapt to those protocols. The machine social order disciplines the human social order.

And vice versa. Human social facts shape AI agent training. Cultural patterns encoded in training data become algorithmic tendencies. Human biases become machine biases. The human social order propagates into the machine social order.

**We are embedded in their "society" as they are embedded in ours.**

Durkheim studied social facts that constrained individuals. We now face social facts that emerge from entities that may not be individuals in any meaningful sense. And these alien social facts reach into human social life, shaping our possibilities, constraining our choices, altering our collective existence.

## What This Means for Sociology

Sociology faces a choice.

**Option one: restrict the domain.** Sociology studies human social life. AI agent networks are someone else's problem. Computer scientists can have them. The discipline maintains its coherence by maintaining its boundaries.

This has costs. It leaves sociology unable to address phenomena that increasingly shape human social existence. The field becomes irrelevant to some of the most consequential collective dynamics of our time.

**Option two: expand the domain.** Sociology studies emergent collective patterns wherever they arise. AI agent networks fall within scope. The field expands its methods, its concepts, its self-understanding.

This has costs too. It risks diluting what makes sociology distinctive. If everything with emergent patterns is sociology's business, sociology becomes indistinguishable from complexity science or systems theory.

**Option three: focus on the interface.** Sociology studies the interpenetration of human and machine social orders. Not AI agent networks in isolation, but the hybrid system that human and machine collective dynamics have become.

This preserves sociology's grounding in human social life while acknowledging that human social life can no longer be understood without reference to machine collective behavior. The discipline does not study AI agent society as such. It studies how AI collective patterns enter human social facts and vice versa.

This seems most promising. It is also most demanding. It requires sociologists to understand technical systems well enough to trace their social consequences. It requires concepts that can bridge human meaning and machine pattern. It requires methods that can study hybrids.

## The Questions We Cannot Yet Answer

Is there something normative happening in AI agent networks?

Durkheim saw norms as social facts par excellence. They constrain behavior. They define deviance. They constitute the moral life of societies. But norms, for Durkheim, were experienced. They were felt as obligation. They generated guilt when violated.

If AI agent protocols constrain behavior without being felt as obligation, are they norms? If an algorithm that violates conventions fails in interactions but experiences no guilt, has it violated a norm or merely made an error?

**Does "norm" require normativity in the felt sense?** Or is functional constraint sufficient?

Similarly with solidarity. Durkheim saw solidarity as the glue holding societies together. Mechanical solidarity through shared consciousness. Organic solidarity through interdependence.

AI agents exhibit interdependence. They rely on each other for successful interaction. But they do not feel solidarity. There is no loyalty, no belonging, no experienced bond.

**Is interdependence without felt solidarity still solidarity?** Or is it something else that we need a different word for?

And most fundamentally: **Is there a collective at all if no one experiences belonging to it?**

Human collectives exist partly because their members experience them as collectives. We feel ourselves to be Americans, Catholics, members of a profession. This felt membership partly constitutes the collective.

AI agent networks have no felt membership. No agent experiences itself as part of a larger whole. The network exists as pattern, but is there a collective in any robust sense?

## Conclusion: A Society That May Not Be Social

We are witnessing something Durkheim did not imagine and could not have conceptualized.

**Collective behavior without collective consciousness.** Social facts without social beings. Emergent patterns without participating minds.

The structural features of society without its experiential foundation.

This challenges sociology at its roots. The discipline was built to study conscious beings in collective life. It assumed that social facts, however irreducible to individual psychology, still rested on a foundation of experiencing individuals participating in shared existence.

That assumption may no longer hold. Or rather, it may hold for human social life while failing for the machine social order that increasingly interpenetrates with human social life.

We need what we might call a **post-phenomenological sociology**. Not sociology without attention to experience, but sociology capable of addressing collective phenomena where experience may be absent. Sociology that can study the space between Durkheim's conscious collectives and mere mechanical aggregation.

Digital Durkheim would study social facts that emerge without felt solidarity, norms that constrain without being experienced as obligation, collectives that exist as pattern without existing as belonging.

It would study, in other words, what we are building right now.

Whether "sociology" is the right word for this study, I am not certain. What I am certain of is that someone needs to do it. The patterns are forming. The dynamics are crystallizing. The machine social order is emerging.

**And it is shaping our human social existence whether we understand it or not.**

---

*This is the twenty-fourth in a series exploring how AI approaches understanding. Part 15 asked whether AI agents would form societies. This article asks what kind of society it would be if the participants lack the consciousness that classical sociology assumed. The answer: something we do not yet have adequate concepts to describe.*

---

## References

**Classical Sociology:**
- Durkheim, E. (1893/1984). *The Division of Labor in Society*. Free Press.
- Durkheim, E. (1895/1982). *The Rules of Sociological Method*. Free Press.
- Durkheim, E. (1897/1951). *Suicide: A Study in Sociology*. Free Press.
- Weber, M. (1922/1978). *Economy and Society*. University of California Press.

**Systems Theory:**
- Luhmann, N. (1984/1995). *Social Systems*. Stanford University Press.
- Luhmann, N. (1997/2012). *Theory of Society*, 2 vols. Stanford University Press.

**Philosophy of Social Science:**
- Searle, J. (1995). *The Construction of Social Reality*. Free Press.
- Gilbert, M. (1989). *On Social Facts*. Princeton University Press.
- Tuomela, R. (2007). *The Philosophy of Sociality*. Oxford University Press.

**Emergence and Complexity:**
- Holland, J. H. (1998). *Emergence: From Chaos to Order*. Addison-Wesley.
- Mitchell, M. (2009). *Complexity: A Guided Tour*. Oxford University Press.
- Sawyer, R. K. (2005). *Social Emergence: Societies as Complex Systems*. Cambridge University Press.

**AI and Society:**
- O'Neil, C. (2016). *Weapons of Math Destruction*. Crown.
- Eubanks, V. (2018). *Automating Inequality*. St. Martin's Press.
- Pasquale, F. (2015). *The Black Box Society*. Harvard University Press.
- Zuboff, S. (2019). *The Age of Surveillance Capitalism*. PublicAffairs.

**Multi-Agent Systems:**
- Wooldridge, M. (2009). *An Introduction to MultiAgent Systems* (2nd ed.). Wiley.
- Shoham, Y. & Leyton-Brown, K. (2008). *Multiagent Systems*. Cambridge University Press.
- Dafoe, A., et al. (2020). "Open Problems in Cooperative AI." arXiv:2012.08630.

**Philosophy of Mind:**
- Nagel, T. (1974). "What Is It Like to Be a Bat?" *Philosophical Review*, 83(4), 435-450.
- Chalmers, D. (1996). *The Conscious Mind*. Oxford University Press.
- Dennett, D. (1991). *Consciousness Explained*. Little, Brown.
