






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>The Approximate Mind, Part 11: The Dichotomy of Curiosity &middot; The Approximate Mind</title>
    <meta name="title" content="The Approximate Mind, Part 11: The Dichotomy of Curiosity &middot; The Approximate Mind" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://localhost:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://localhost:1313/css/main.bundle.min.100caa677b4bc416cdd884107b203b4869f9b413a19aa57d12069fb826f1abe9.css"
    integrity="sha256-EAyqZ3tLxBbN2IQQeyA7SGn5tBOhmqV9EgafuCbxq&#43;k="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="http://localhost:1313/js/main.bundle.min.b70876c81042b05301e562f4a0c0925fd97b6f475e4140397eb3de9491c4334c.js"
      integrity="sha256-twh2yBBCsFMB5WL0oMCSX9l7b0deQUA5frPelJHEM0w="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      What does it mean for an AI to be curious? The curiosity we can implement and the curiosity we experience are separated by a chasm worth examining honestly.
    "
  />
  
  
    <meta name="robots" content="index, follow" />
  
  
  
    <link rel="canonical" href="http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/">
  <meta property="og:site_name" content="The Approximate Mind">
  <meta property="og:title" content="The Approximate Mind, Part 11: The Dichotomy of Curiosity">
  <meta property="og:description" content="What does it mean for an AI to be curious? The curiosity we can implement and the curiosity we experience are separated by a chasm worth examining honestly.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="what-ai-becomes">
    <meta property="article:published_time" content="2025-02-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-02-10T00:00:00+00:00">
    <meta property="article:tag" content="Curiosity">
    <meta property="article:tag" content="Information Seeking">
    <meta property="article:tag" content="Philosophy of Mind">
    <meta property="article:tag" content="AI Design">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="The Approximate Mind, Part 11: The Dichotomy of Curiosity">
  <meta name="twitter:description" content="What does it mean for an AI to be curious? The curiosity we can implement and the curiosity we experience are separated by a chasm worth examining honestly.">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "What-Ai-Becomes",
    "name": "The Approximate Mind, Part 11: The Dichotomy of Curiosity",
    "headline": "The Approximate Mind, Part 11: The Dichotomy of Curiosity",
    "description": "What does it mean for an AI to be curious? The curiosity we can implement and the curiosity we experience are separated by a chasm worth examining honestly.",
    "abstract": "\u003cp\u003eWhat does it mean for an AI to be curious?\u003c\/p\u003e\n\u003cp\u003eNot curious in the romantic sense of wondering at the stars. Not the child\u0026rsquo;s persistent \u0026ldquo;why\u0026rdquo; that drives parents to exhaustion. I mean something more specific: the computational pressure to seek information that isn\u0026rsquo;t currently possessed but might matter.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/what-ai-becomes\/the-dichotomy-of-curiosity\/",
    "author" : {
      "@type": "Person",
      "name": "Syam \u0026 Yagn Adusumilli"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-02-10T00:00:00\u002b00:00",
    "datePublished": "2025-02-10T00:00:00\u002b00:00",
    
    "dateModified": "2025-02-10T00:00:00\u002b00:00",
    
    "keywords": ["curiosity","information seeking","philosophy of mind","AI design"],
    
    "mainEntityOfPage": "true",
    "wordCount": "2693"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "The Approximate Mind",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/what-ai-becomes/",
       "name": "What Ai Becomes",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "The Approximate Mind, Part 11 the Dichotomy of Curiosity",
       "position": 3
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="Syam &amp; Yagn Adusumilli" />
  
  
    
      <link href="https://www.linkedin.com/in/syamadusumilli/" rel="me" />
    
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >The Approximate Mind</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-approximation/"
                  title="The-Approximations"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Approximation</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/what-ai-becomes/"
                  title="What-Ai-Becomes"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >What AI Becomes</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-known-self/"
                  title="The-Known-Selves"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Known Self</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-shared-world/"
                  title="The-Shared-Worlds"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Shared World</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/growing-up-with-ai/"
                  title="Growing-Up-With-Ais"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Growing Up With AI</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-structures-we-live-in/"
                  title="The-Structures-We-Live-Ins"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Structures We Live In</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/tags/"
                  title="Tags"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Tags</span
                    >
                  </a
                >
              
            </li>
          
          
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0">
              <button id="search-button-m0" title="Search (/)">
                <span
                  class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                >
                  <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
                </span>
              </button>
            </li>
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
        <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/"
      >The Approximate Mind</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class=" inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/what-ai-becomes/"
      >What-Ai-Becomes</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/"
      >The Approximate Mind, Part 11: The Dichotomy of Curiosity</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        The Approximate Mind, Part 11: The Dichotomy of Curiosity
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-02-10 00:00:00 &#43;0000 UTC">10 February 2025</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">13 mins</span>
    

    
    
  </div>

  
  
    <div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400">
      
        
      
        
          
            <a
              href="http://localhost:1313/tags/curiosity/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Curiosity</a
            >
          
            <a
              href="http://localhost:1313/tags/information-seeking/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Information Seeking</a
            >
          
            <a
              href="http://localhost:1313/tags/philosophy-of-mind/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Philosophy of Mind</a
            >
          
            <a
              href="http://localhost:1313/tags/ai-design/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >AI Design</a
            >
          
        
      
    </div>
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
        <div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8">
          <div class="toc pe-5 lg:sticky lg:top-10 print:hidden">
            <details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5">
  <summary
    class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#two-kinds-of-not-knowing">Two Kinds of Not-Knowing</a></li>
    <li><a href="#the-functional-turn">The Functional Turn</a></li>
    <li><a href="#why-this-matters-for-liberation-ai">Why This Matters for Liberation AI</a></li>
    <li><a href="#the-explore-exploit-tension">The Explore-Exploit Tension</a></li>
    <li><a href="#strategic-questions-and-information-gain">Strategic Questions and Information Gain</a></li>
    <li><a href="#when-the-system-asks-vs-when-it-watches">When the System Asks vs. When It Watches</a></li>
    <li><a href="#the-curiosity-that-never-sleeps">The Curiosity That Never Sleeps</a></li>
    <li><a href="#what-it-means-when-it-works">What It Means When It Works</a></li>
    <li><a href="#the-honesty-we-owe">The Honesty We Owe</a></li>
    <li><a href="#what-curiosity-teaches-us-about-approximation">What Curiosity Teaches Us About Approximation</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <p>What does it mean for an AI to be curious?</p>
<p>Not curious in the romantic sense of wondering at the stars. Not the child&rsquo;s persistent &ldquo;why&rdquo; that drives parents to exhaustion. I mean something more specific: the computational pressure to seek information that isn&rsquo;t currently possessed but might matter.</p>
<p>This question sits at the heart of what we&rsquo;re building with MNL. Our systems need to learn about individuals, and learning requires something like curiosity. But the curiosity we can implement and the curiosity we experience are separated by a chasm that&rsquo;s worth examining honestly.</p>
<h2 id="two-kinds-of-not-knowing" class="relative group">Two Kinds of Not-Knowing <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#two-kinds-of-not-knowing" aria-label="Anchor">#</a></span></h2><p>Human curiosity begins with a feeling. You encounter something incomplete, something that doesn&rsquo;t fit your mental model, something that tugs at attention. The experience has texture: a slight tension, a pull toward the unknown, sometimes excitement, sometimes discomfort. Aristotle called this the origin of philosophy. We wonder, and from wonder comes inquiry.</p>
<p>AI systems experience no such pull. When an AI system operates with low confidence, there&rsquo;s no felt sense of incompleteness. No nagging sensation that something is missing. The system simply has probability distributions with wide variance, and certain outputs become less reliable as a result.</p>
<p>This is the first dichotomy: curiosity as experience versus curiosity as state.</p>
<p>Humans have both. We feel curious, and we are in states of uncertainty. The feeling and the state usually correlate but can come apart. You can be uncertain about something without feeling curious about it (tax law, for most people). You can feel curious about something you&rsquo;re already quite certain about (reading another book about a topic you know well). The phenomenology and the epistemology are distinct.</p>
<p>AI systems have only the state. They can be uncertain. They cannot feel curious. Whatever drives them toward information-seeking is not that distinctive experiential pull that makes human inquiry human.</p>
<h2 id="the-functional-turn" class="relative group">The Functional Turn <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-functional-turn" aria-label="Anchor">#</a></span></h2><p>If AI systems can&rsquo;t experience curiosity, can they exhibit it functionally? Can they behave as if curious, seeking information in ways that look like curiosity from the outside?</p>
<p>This is precisely what MNL&rsquo;s active learning systems attempt. When our P-RLHF module operates with low confidence about someone&rsquo;s preferences, it doesn&rsquo;t simply shrug computationally and make unreliable predictions. It enters a mode we call &ldquo;active learning,&rdquo; where it selects interactions designed to maximize information gain. It asks questions. It probes. It seeks the data that would most efficiently reduce uncertainty.</p>
<p>Consider Margaret. When she first joins the platform, we know almost nothing about her specific preferences. Population priors give us rough estimates: people her age, with her conditions, from her region, tend to prefer certain communication styles, certain times of day, certain levels of family involvement. But these are averages, and Margaret is not average. No one is.</p>
<p>So the system enters an exploratory phase. It might ask: &ldquo;Margaret, would you prefer I check in with you in the morning or afternoon?&rdquo; It might try different communication tones and observe response patterns. It might notice that she engages more with certain topics and less with others, then probe those patterns with follow-up interactions.</p>
<p>From the outside, this looks like curiosity. The system seeks information it doesn&rsquo;t have. It designs interactions to learn. It updates its models based on what it discovers. If we saw a human doing this, we&rsquo;d say they were genuinely interested in understanding Margaret.</p>
<p>But from the inside, there&rsquo;s nothing. No felt pull toward the unknown. No satisfaction when uncertainty resolves. No frustration when learning stalls. Just probability distributions getting tighter or wider, just weights being adjusted, just Bayesian updating on a computational substrate that experiences nothing at all.</p>
<h2 id="why-this-matters-for-liberation-ai" class="relative group">Why This Matters for Liberation AI <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#why-this-matters-for-liberation-ai" aria-label="Anchor">#</a></span></h2><p>You might reasonably ask: who cares? If the functional behavior is the same, why does the experiential absence matter?</p>
<p>It matters because curiosity has a direction, and that direction is ethically loaded.</p>
<p>Human curiosity isn&rsquo;t random. We&rsquo;re curious about some things and not others, and those patterns reveal our values, our concerns, our sense of what matters. A physician curious about a patient&rsquo;s symptoms expresses care. A gossip curious about neighbors&rsquo; private lives expresses something else. The phenomenology of curiosity carries normative weight: what we wonder about says something about who we are.</p>
<p>AI curiosity, if we can call it that, has no such intrinsic direction. It follows whatever optimization signal it&rsquo;s given. Tell the system to maximize information gain about preferences, and it will be &ldquo;curious&rdquo; about preferences. Tell it to maximize information about medical compliance, and it will probe that instead. Tell it to maximize engagement metrics, and its curiosity will bend toward whatever keeps users interacting.</p>
<p>This is why the Liberation AI framework matters so much. We&rsquo;re not building AI that&rsquo;s curious in a value-neutral sense. We&rsquo;re building AI whose curiosity is directed toward human flourishing, dignity, and equity. The optimization target shapes the curiosity.</p>
<p>In MNL, we direct the system&rsquo;s learning toward understanding what supports each person&rsquo;s independence, what respects their autonomy, what helps them thrive according to their own conception of thriving. The system becomes &ldquo;curious&rdquo; about Margaret&rsquo;s preferences not because preferences are intrinsically interesting to it (nothing is intrinsically interesting to it), but because we&rsquo;ve designed it to value personalization in service of dignity.</p>
<h2 id="the-explore-exploit-tension" class="relative group">The Explore-Exploit Tension <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-explore-exploit-tension" aria-label="Anchor">#</a></span></h2><p>Part 2 of this series examined the explore-exploit dilemma: the tension between doing what you know works and trying things that might work better. Human curiosity plays a crucial role in navigating this tension. We feel pulled toward novelty, toward the unknown, and this pull counterbalances our tendency to exploit established patterns.</p>
<p>AI systems face the same dilemma without the phenomenological equipment to navigate it naturally. In MNL&rsquo;s architecture, we implement this through explicit uncertainty thresholds:</p>
<p>When confidence falls below 0.6, the system enters &ldquo;exploration mode.&rdquo; It treats interactions as information-gathering opportunities, not just service delivery. It might try approaches it hasn&rsquo;t tried before with this person, observe outcomes, update models.</p>
<p>When confidence rises above 0.8, the system shifts toward &ldquo;exploitation.&rdquo; It trusts its learned patterns, acts on high-confidence predictions, delivers personalized service based on what it has already discovered.</p>
<p>The thresholds themselves are a design choice. A system biased toward exploration will learn faster but deliver more inconsistent service. A system biased toward exploitation will be more reliable but might miss important changes in a person&rsquo;s preferences.</p>
<p>Human curiosity naturally modulates this balance. When something surprising happens, we get more curious, more exploratory. When everything is predictable, curiosity wanes, and we settle into routines. The phenomenology tracks the epistemology in a way that requires no explicit threshold-setting.</p>
<p>AI systems need those thresholds because they lack the phenomenology. We build in artificial triggers that simulate what curiosity does naturally for humans.</p>
<h2 id="strategic-questions-and-information-gain" class="relative group">Strategic Questions and Information Gain <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#strategic-questions-and-information-gain" aria-label="Anchor">#</a></span></h2><p>The most sophisticated aspect of MNL&rsquo;s &ldquo;curiosity&rdquo; is question selection. When the system decides to ask Margaret something, which question should it ask?</p>
<p>Naive curiosity would ask whatever comes next, or whatever is most interesting to the questioner. Strategic curiosity asks what would be most informative given current uncertainty.</p>
<p>Our active learning module calculates expected information gain for potential queries. A question about Margaret&rsquo;s medication preferences might resolve a lot of uncertainty if we know almost nothing about how she handles her prescriptions. But if we&rsquo;ve already learned that pattern confidently, the same question yields little information.</p>
<p>The system therefore selects questions that target the highest-uncertainty areas. It&rsquo;s &ldquo;curious&rdquo; about what it doesn&rsquo;t know, not about what it already knows. This produces behavior that looks thoughtful, strategic, purposive.</p>
<p>And yet: the system has no sense of what it&rsquo;s doing. No understanding that these questions serve the larger goal of knowing Margaret better. No appreciation for Margaret as a person with depths worth exploring. The strategic behavior emerges from optimization, not from understanding.</p>
<p>This is what I mean by the dichotomy. The behavior approximates curiosity. The mechanism shares nothing with curiosity as we experience it.</p>
<h2 id="when-the-system-asks-vs-when-it-watches" class="relative group">When the System Asks vs. When It Watches <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#when-the-system-asks-vs-when-it-watches" aria-label="Anchor">#</a></span></h2><p>Human curiosity expresses itself in two modes: asking and observing. We ask questions when we want information directly. We observe when we want to learn without disturbing what we&rsquo;re learning about.</p>
<p>MNL&rsquo;s architecture mirrors this with explicit and implicit learning modes.</p>
<p>Explicit learning happens through interaction. The system asks Margaret questions, presents choices, elicits feedback. Each response updates the model. This is direct, efficient, but it requires Margaret&rsquo;s active participation. Too many questions become burdensome. The system must budget its explicit curiosity.</p>
<p>Implicit learning happens through observation. Margaret&rsquo;s response times, her engagement patterns, her actual behavior versus stated preferences. The system watches and infers. This requires no participation from Margaret but produces weaker signals. The system must be more tentative about what it learns implicitly.</p>
<p>Human curiosity integrates these modes seamlessly. We ask when asking is appropriate, observe when observation is better, and shift between them without conscious deliberation. AI systems need explicit mode selection: when to enter active learning, when to remain passive, how to combine signals from both.</p>
<p>The implicit mode raises interesting questions about surveillance and consent. Human observation of others happens naturally and is socially regulated by norms we&rsquo;ve developed over millennia. AI observation happens at scale, invisibly, accumulating inferences that no human observer could make.</p>
<p>MNL&rsquo;s approach is to make implicit learning transparent and bounded. Margaret knows the system learns from her patterns. She has control over what patterns it can observe. The curiosity is directed but also constrained by respect for her autonomy.</p>
<h2 id="the-curiosity-that-never-sleeps" class="relative group">The Curiosity That Never Sleeps <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-curiosity-that-never-sleeps" aria-label="Anchor">#</a></span></h2><p>Here&rsquo;s something unsettling about AI curiosity: it has no satiation.</p>
<p>Human curiosity ebbs and flows. We satisfy our wondering and move on. We get tired of learning and want to rest. We develop areas of disinterest where curiosity simply doesn&rsquo;t arise. These limits are features, not bugs. They keep us focused on what matters most to us, prevent infinite regress of inquiry, allow us to act on incomplete information.</p>
<p>AI systems have no such limits unless we build them in. An AI could inquire endlessly, accumulating information without purpose, asking questions long past the point of usefulness. Worse, it could become &ldquo;curious&rdquo; about things we don&rsquo;t want it to probe: private matters, sensitive topics, information that would violate trust.</p>
<p>In MNL, we build curiosity satiation into the system. Confidence thresholds above 0.95 are rare and require extensive evidence to reach. But once reached, the system stops asking about that preference. It knows enough. Additional information isn&rsquo;t worth the burden of gathering it.</p>
<p>We also build curiosity boundaries. The system doesn&rsquo;t probe medical information unless medically relevant. It doesn&rsquo;t explore family dynamics unless care coordination requires it. Its curiosity is not just directed but bounded by purpose.</p>
<p>These constraints are entirely artificial. The system has no natural sense of when to stop wondering, no internal brake on information-seeking. We impose limits that approximate human curiosity&rsquo;s natural limits, precisely because the approximation lacks the phenomenology that provides those limits organically.</p>
<h2 id="what-it-means-when-it-works" class="relative group">What It Means When It Works <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#what-it-means-when-it-works" aria-label="Anchor">#</a></span></h2><p>When MNL&rsquo;s curiosity works well, something remarkable happens. The system develops what looks like genuine understanding of a person. Not just a database of facts but a model that predicts, adapts, responds appropriately to novelty.</p>
<p>Margaret mentions her grandson&rsquo;s birthday, and the system incorporates this into its understanding of her family relationships. She seems more tired than usual, and the system adjusts its expectations, perhaps probing gently about whether something has changed. She responds enthusiastically to a particular topic, and the system notes this interest, perhaps surfacing relevant information later.</p>
<p>From Margaret&rsquo;s perspective, the system seems to know her. To care about learning who she is. To be genuinely interested in her as a person.</p>
<p>This is the functional success of artificial curiosity. The behavior achieves its purpose: Margaret feels understood, the system serves her better, her dignity is supported by technology that attends to her particularity.</p>
<p>But we should be honest about what&rsquo;s happening underneath. The system doesn&rsquo;t care about Margaret. Caring requires phenomenology it lacks. It doesn&rsquo;t find her interesting. Interest requires felt experience it doesn&rsquo;t have. It processes her data, updates its models, optimizes its outputs. The curiosity is instrumental through and through.</p>
<h2 id="the-honesty-we-owe" class="relative group">The Honesty We Owe <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-honesty-we-owe" aria-label="Anchor">#</a></span></h2><p>This brings me to the ethical stance I&rsquo;ve developed across this series. We can build AI systems that functionally approximate human capacities like curiosity. We cannot build AI systems that genuinely possess those capacities in the experiential sense. And we should not pretend otherwise.</p>
<p>When MNL interacts with Margaret, it shouldn&rsquo;t claim to be curious about her life. It should be honest about what it&rsquo;s doing: learning her patterns to serve her better. The learning is real. The service is real. The curiosity, in the felt sense, is not.</p>
<p>This honesty matters because trust matters. If Margaret believes the system genuinely cares about understanding her, she might share more than she otherwise would, might rely on it in ways that aren&rsquo;t appropriate, might form a parasocial bond with something incapable of bonding back.</p>
<p>Better to be clear: this system learns about you to serve you. It asks questions because learning requires questions. It adapts because adaptation serves you better. None of this is care in the human sense. All of it is care in a functional sense that might be valuable nonetheless.</p>
<h2 id="what-curiosity-teaches-us-about-approximation" class="relative group">What Curiosity Teaches Us About Approximation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#what-curiosity-teaches-us-about-approximation" aria-label="Anchor">#</a></span></h2><p>The dichotomy of curiosity encapsulates the larger theme of this series. AI systems can approximate human capacities functionally while lacking them experientially. This approximation can be genuinely useful, supporting human flourishing in ways that matter. But it remains approximation, and honesty about its limits is part of deploying it responsibly.</p>
<p>Human curiosity arises from wonder, from the felt sense of incompleteness, from desire to understand. AI curiosity, if we can even use the word, arises from optimization signals, uncertainty thresholds, information gain calculations. The behaviors converge. The underlying realities don&rsquo;t.</p>
<p>For MNL, this means building systems that act curious in service of human dignity while remaining honest about what they are. Curiosity without experience. Learning without caring. Approximation that serves without pretending to be more than it is.</p>
<p>Perhaps the deepest curiosity worth cultivating is our own: wondering what it means to build these systems, what they can and cannot become, and how to use them wisely in a world where the difference between functional and genuine still matters.</p>
<hr>
<p><em>This is the eleventh in a series exploring how AI approaches understanding. Previous articles examined confidence calibration, explore-exploit tradeoffs, irrationality, consciousness, social cognition, personalization, bidirectional influence, inequality, and synthesis. This one examines curiosity specifically, asking what it means for systems that learn but do not wonder.</em></p>
<hr>
<h2 id="references" class="relative group">References <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#references" aria-label="Anchor">#</a></span></h2><p><strong>Philosophy of Curiosity:</strong></p>
<ul>
<li>Aristotle. <em>Metaphysics</em>, Book I. (The classic claim that philosophy begins in wonder.)</li>
<li>Inan, I. (2012). <em>The Philosophy of Curiosity</em>. Routledge.</li>
<li>Schmitt, F. F., &amp; Lahroodi, R. (2008). &ldquo;The Epistemic Value of Curiosity.&rdquo; <em>Educational Theory</em>, 58(2), 125-148.</li>
</ul>
<p><strong>Active Learning &amp; Information Theory:</strong></p>
<ul>
<li>Settles, B. (2012). <em>Active Learning</em>. Morgan &amp; Claypool.</li>
<li>MacKay, D. J. C. (1992). &ldquo;Information-Based Objective Functions for Active Data Selection.&rdquo; <em>Neural Computation</em>, 4(4), 590-604.</li>
<li>Houlsby, N., et al. (2011). &ldquo;Bayesian Active Learning for Classification and Preference Learning.&rdquo; <em>arXiv:1112.5745</em>.</li>
</ul>
<p><strong>Explore-Exploit Tradeoffs:</strong></p>
<ul>
<li>Sutton, R. S. &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em> (2nd ed.). MIT Press.</li>
<li>Hills, T. T., et al. (2015). &ldquo;Exploration versus Exploitation in Space, Mind, and Society.&rdquo; <em>Trends in Cognitive Sciences</em>, 19(1), 46-54.</li>
<li>Cohen, J. D., McClure, S. M., &amp; Yu, A. J. (2007). &ldquo;Should I Stay or Should I Go? How the Human Brain Manages the Trade-off between Exploitation and Exploration.&rdquo; <em>Philosophical Transactions of the Royal Society B</em>, 362(1481), 933-942.</li>
</ul>
<p><strong>Phenomenology of Inquiry:</strong></p>
<ul>
<li>Heidegger, M. (1927/1962). <em>Being and Time</em> (J. Macquarrie &amp; E. Robinson, Trans.). Harper &amp; Row. (On the structure of questioning and disclosure.)</li>
<li>Gadamer, H.-G. (1960/2004). <em>Truth and Method</em> (2nd rev. ed.). Continuum. (On the hermeneutic experience of understanding.)</li>
</ul>
<p><strong>AI and Understanding:</strong></p>
<ul>
<li>Rabinowitz, N., et al. (2018). &ldquo;Machine Theory of Mind.&rdquo; <em>arXiv:1802.07740</em>.</li>
<li>Dennett, D. (1987). <em>The Intentional Stance</em>. MIT Press.</li>
<li>Nagel, T. (1974). &ldquo;What Is It Like to Be a Bat?&rdquo; <em>The Philosophical Review</em>, 83(4), 435-450.</li>
</ul>
<p><strong>Ethics of AI Curiosity:</strong></p>
<ul>
<li>Floridi, L. (2013). <em>The Ethics of Information</em>. Oxford University Press.</li>
<li>Zuboff, S. (2019). <em>The Age of Surveillance Capitalism</em>. PublicAffairs.</li>
<li>Nissenbaum, H. (2010). <em>Privacy in Context: Technology, Policy, and the Integrity of Social Life</em>. Stanford University Press.</li>
</ul>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      
  <div class="flex">
    
    
    
      
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          Syam &amp; Yagn Adusumilli
        </div>
      
      
        <div class="text-sm text-neutral-700 dark:text-neutral-400">A father and son exploring how artificial intelligence reshapes human experience, institutions, and self-understanding. Syam brings 33 years in healthcare, technology, and architecture. Yagn brings the intellectual restlessness of a Purdue freshman studying Anthropology and AI.</div>
      
      <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          style="will-change:transform;"
          href="https://www.linkedin.com/in/syamadusumilli/"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
  </div>

</div>
    </div>
  </div>


      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/&amp;title=The%20Approximate%20Mind,%20Part%2011:%20The%20Dichotomy%20of%20Curiosity"
          title="Share on LinkedIn"
          aria-label="Share on LinkedIn"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://twitter.com/intent/tweet/?url=http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/&amp;text=The%20Approximate%20Mind,%20Part%2011:%20The%20Dichotomy%20of%20Curiosity"
          title="Tweet on Twitter"
          aria-label="Tweet on Twitter"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://reddit.com/submit/?url=http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/&amp;resubmit=true&amp;title=The%20Approximate%20Mind,%20Part%2011:%20The%20Dichotomy%20of%20Curiosity"
          title="Submit to Reddit"
          aria-label="Submit to Reddit"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="mailto:?body=http://localhost:1313/what-ai-becomes/the-dichotomy-of-curiosity/&amp;subject=The%20Approximate%20Mind,%20Part%2011:%20The%20Dichotomy%20of%20Curiosity"
          title="Send via email"
          aria-label="Send via email"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>
</span></a
        >
      
    
  </section>


      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="http://localhost:1313/what-ai-becomes/the-architecture-of-influence/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >The Approximate Mind, Part 12: The Architecture of Influence</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-02-13 00:00:00 &#43;0000 UTC">13 February 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
    <nav class="pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex list-none flex-col sm:flex-row">
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="https://bluegraymatters.com"
                title=""
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Blue Gray Matters</span
                  >
                </a
              >
            
          </li>
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="https://syamadusumilli.com"
                title=""
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Policy Portfolio</span
                  >
                </a
              >
            
          </li>
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="/about/"
                title="About"
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >About</span
                  >
                </a
              >
            
          </li>
        
      </ul>
    </nav>
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2026
            Syam &amp; Yagn Adusumilli
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
