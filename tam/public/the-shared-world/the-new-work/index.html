






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>The Approximate Mind, Part 19: The New Work &middot; The Approximate Mind</title>
    <meta name="title" content="The Approximate Mind, Part 19: The New Work &middot; The Approximate Mind" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://localhost:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://localhost:1313/css/main.bundle.min.100caa677b4bc416cdd884107b203b4869f9b413a19aa57d12069fb826f1abe9.css"
    integrity="sha256-EAyqZ3tLxBbN2IQQeyA7SGn5tBOhmqV9EgafuCbxq&#43;k="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="http://localhost:1313/js/main.bundle.min.b70876c81042b05301e562f4a0c0925fd97b6f475e4140397eb3de9491c4334c.js"
      integrity="sha256-twh2yBBCsFMB5WL0oMCSX9l7b0deQUA5frPelJHEM0w="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      The question everyone asks is wrong. What jobs will AI take assumes a fixed pie. The better question: what new work does AI create?
    "
  />
  
  
    <meta name="robots" content="index, follow" />
  
  
  
    <link rel="canonical" href="http://localhost:1313/the-shared-world/the-new-work/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/the-shared-world/the-new-work/">
  <meta property="og:site_name" content="The Approximate Mind">
  <meta property="og:title" content="The Approximate Mind, Part 19: The New Work">
  <meta property="og:description" content="The question everyone asks is wrong. What jobs will AI take assumes a fixed pie. The better question: what new work does AI create?">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="the-shared-world">
    <meta property="article:published_time" content="2025-03-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-03-10T00:00:00+00:00">
    <meta property="article:tag" content="Work">
    <meta property="article:tag" content="Labor">
    <meta property="article:tag" content="Automation">
    <meta property="article:tag" content="Purpose">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="The Approximate Mind, Part 19: The New Work">
  <meta name="twitter:description" content="The question everyone asks is wrong. What jobs will AI take assumes a fixed pie. The better question: what new work does AI create?">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "The-Shared-Worlds",
    "name": "The Approximate Mind, Part 19: The New Work",
    "headline": "The Approximate Mind, Part 19: The New Work",
    "description": "The question everyone asks is wrong. What jobs will AI take assumes a fixed pie. The better question: what new work does AI create?",
    "abstract": "\u003cp\u003eThe question everyone asks is wrong.\u003c\/p\u003e\n\u003cp\u003e\u0026ldquo;What jobs will AI take?\u0026rdquo; assumes a fixed pie of work that AI and humans divide between them. It treats labor as a zero-sum competition where every AI capability is a human loss.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/the-shared-world\/the-new-work\/",
    "author" : {
      "@type": "Person",
      "name": "Syam \u0026 Yagn Adusumilli"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-03-10T00:00:00\u002b00:00",
    "datePublished": "2025-03-10T00:00:00\u002b00:00",
    
    "dateModified": "2025-03-10T00:00:00\u002b00:00",
    
    "keywords": ["work","labor","automation","purpose"],
    
    "mainEntityOfPage": "true",
    "wordCount": "5334"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "The Approximate Mind",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/the-shared-world/",
       "name": "The Shared Worlds",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "The Approximate Mind, Part 19 the New Work",
       "position": 3
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="Syam &amp; Yagn Adusumilli" />
  
  
    
      <link href="https://www.linkedin.com/in/syamadusumilli/" rel="me" />
    
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >The Approximate Mind</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-approximation/"
                  title="The-Approximations"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Approximation</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/what-ai-becomes/"
                  title="What-Ai-Becomes"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >What AI Becomes</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-known-self/"
                  title="The-Known-Selves"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Known Self</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-shared-world/"
                  title="The-Shared-Worlds"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Shared World</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/growing-up-with-ai/"
                  title="Growing-Up-With-Ais"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Growing Up With AI</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/the-structures-we-live-in/"
                  title="The-Structures-We-Live-Ins"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >The Structures We Live In</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/tags/"
                  title="Tags"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Tags</span
                    >
                  </a
                >
              
            </li>
          
          
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0">
              <button id="search-button-m0" title="Search (/)">
                <span
                  class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                >
                  <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
                </span>
              </button>
            </li>
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
        <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/"
      >The Approximate Mind</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class=" inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/the-shared-world/"
      >The-Shared-Worlds</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://localhost:1313/the-shared-world/the-new-work/"
      >The Approximate Mind, Part 19: The New Work</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        The Approximate Mind, Part 19: The New Work
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-03-10 00:00:00 &#43;0000 UTC">10 March 2025</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">26 mins</span>
    

    
    
  </div>

  
  
    <div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400">
      
        
      
        
          
            <a
              href="http://localhost:1313/tags/work/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Work</a
            >
          
            <a
              href="http://localhost:1313/tags/labor/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Labor</a
            >
          
            <a
              href="http://localhost:1313/tags/automation/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Automation</a
            >
          
            <a
              href="http://localhost:1313/tags/purpose/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Purpose</a
            >
          
        
      
    </div>
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
        <div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8">
          <div class="toc pe-5 lg:sticky lg:top-10 print:hidden">
            <details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5">
  <summary
    class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#the-principal-agent-professions">The Principal-Agent Professions</a></li>
    <li><a href="#the-loop-maintenance-professions">The Loop-Maintenance Professions</a></li>
    <li><a href="#the-legal-and-regulatory-frontier">The Legal and Regulatory Frontier</a></li>
    <li><a href="#the-relationship-professions">The Relationship Professions</a></li>
    <li><a href="#the-new-anthropologists">The New Anthropologists</a></li>
    <li><a href="#the-equity-professions">The Equity Professions</a></li>
    <li><a href="#the-meta-professions">The Meta-Professions</a></li>
    <li><a href="#what-remains-human">What Remains Human</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <p>The question everyone asks is wrong.</p>
<p>&ldquo;What jobs will AI take?&rdquo; assumes a fixed pie of work that AI and humans divide between them. It treats labor as a zero-sum competition where every AI capability is a human loss.</p>
<p>History suggests otherwise. Every major technological transition created more work than it destroyed. The printing press eliminated scribes but created publishers, editors, typesetters, booksellers, librarians, journalists, and eventually entire industries built on mass literacy. The automobile eliminated horse-related jobs but created mechanics, gas station attendants, traffic engineers, suburban developers, drive-through restaurants, and the vast infrastructure of car-dependent society.</p>
<p>The better question: <strong>What new work does AI create?</strong></p>
<p>We are building a parallel society of AI agents. Not just chatbots responding to queries, but autonomous systems that negotiate, coordinate, manage, and act in the world. They interact with each other at machine speed, forming patterns no human designed. They act on our behalf in ways we cannot fully oversee.</p>
<p>At every interface between that society and ours, new human roles emerge. The more capable AI becomes, the more valuable certain distinctly human contributions become. Not because we are protecting human jobs out of sentimentality, but because there is genuine work that needs doing and that humans are genuinely better positioned to do.</p>
<p>This article maps that emerging landscape of human work in an AI society.</p>
<h2 id="the-principal-agent-professions" class="relative group">The Principal-Agent Professions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-principal-agent-professions" aria-label="Anchor">#</a></span></h2><p>The oldest problem in economics is the principal-agent problem. You hire someone to act on your behalf, but they do not perfectly share your interests or information. Lawyers, real estate agents, financial advisors, employees of all kinds face this problem. They are supposed to serve you, but they have their own interests too.</p>
<p>AI agents face the principal-agent problem more acutely than human agents ever did.</p>
<p>A human agent shares your general context. They understand social norms, can infer unstated preferences, recognize when something feels wrong even if they cannot articulate why. An AI agent has only what it was trained on and what you explicitly specify. <strong>The gap between what you want and what the AI optimizes for is irreducible.</strong></p>
<p>This gap creates permanent demand for human roles that manage it.</p>
<p><strong>The Alignment Practitioner</strong></p>
<p>Not the AI safety researchers at major labs working on theoretical alignment. The applied version. Someone who audits whether your specific AI agents are actually optimizing for what you care about.</p>
<p>Consider Margaret. Her AI system manages medications, schedules appointments, handles routine finances, coordinates with her care network. An alignment practitioner reviews whether the system optimizes for Margaret&rsquo;s actual goals or for easily measured proxies.</p>
<p>Is the system maximizing her health or her compliance metrics? These sound similar but diverge in practice. A system optimizing for compliance might schedule medication reminders at times that maximize the chance she confirms taking them, even if those times are inconvenient or the confirmation is meaningless. A system optimizing for health would ensure she actually benefits from the medications, which might mean adjusting timing, flagging side effects, or questioning whether she needs all those prescriptions in the first place.</p>
<p>Is the system maximizing her financial security or her transaction volume with preferred vendors? A system with affiliate relationships has subtle incentives to recommend products that generate commissions rather than products that serve her best.</p>
<p>The alignment practitioner catches these divergences. They understand both AI systems and human values deeply enough to spot subtle misalignments. They ask: what is this system actually doing, and is that what Margaret actually wants?</p>
<p>This is different from traditional auditing. Financial auditors check whether numbers match. Alignment practitioners check whether optimization targets match human values. The skills are different. The training is different. The profession does not yet exist but will need to.</p>
<p><strong>The Delegation Architect</strong></p>
<p>AI agents need bounds. Clear limits on what they can decide autonomously, what requires human confirmation, what they should never touch. But designing those bounds well is hard.</p>
<p>Too restrictive and the AI cannot help effectively. Too permissive and the AI makes commitments you would have rejected. The bounds need to be meaningful, not just theoretical. An AI that technically requires confirmation but asks in ways that default to yes has not really been bounded.</p>
<p>A delegation architect helps people design these boundaries thoughtfully.</p>
<p>The work is part therapist. Understanding what someone actually values requires exploration. Margaret might say she wants her AI to handle all routine decisions, but when probed, she has strong feelings about certain categories she had not articulated. Family matters. Church involvement. Anything involving her late husband&rsquo;s belongings. The delegation architect surfaces these hidden boundaries before they are violated.</p>
<p>The work is part systems designer. Translating human values into implementable constraints requires technical understanding. Not programming, necessarily, but understanding how AI systems interpret instructions, where ambiguity creates problems, how edge cases arise.</p>
<p>The work is part lawyer. Anticipating what could go wrong, what commitments the AI might make, what information it might reveal. Thinking through scenarios the client has not imagined.</p>
<p>A new hybrid profession. Does not exist yet. Will be essential.</p>
<p><strong>The Negotiation Auditor</strong></p>
<p>When AI agents negotiate with other AI agents at machine speed, thousands of exchanges can complete in seconds. Humans cannot oversee individual transactions. But someone needs to review patterns after the fact.</p>
<p>Did your AI agent consistently accept worse terms than it should have? Some AI agents will be better negotiators than others. If yours is systematically outperformed, you are losing value on every transaction without knowing it.</p>
<p>Did your agent reveal information you would have kept private? Negotiation involves strategic disclosure. An agent optimizing for deal completion might share information that helps close deals but harms your long-term position.</p>
<p>Did your agent commit you to obligations you would have rejected? The agent operates within programmed bounds, but those bounds might not anticipate every situation. An agent authorized to make purchases under a certain amount might make many such purchases, or make purchases that are technically within bounds but contextually inappropriate.</p>
<p>The negotiation auditor performs forensic analysis of AI-to-AI transactions. They reconstruct what happened, assess whether outcomes served the principal&rsquo;s interests, identify systematic patterns of underperformance or misalignment. This is forensic accounting for a world of algorithmic deals.</p>
<h2 id="the-loop-maintenance-professions" class="relative group">The Loop-Maintenance Professions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-loop-maintenance-professions" aria-label="Anchor">#</a></span></h2><p>Machines are good at pattern recognition, at processing vast amounts of data, at generating calibrated probabilities. Humans are good at weighing values, at understanding context, at respecting dignity.</p>
<p>Some decisions require human judgment not because AI is inadequate but because the decision is inherently human. Choosing between incommensurable values. Weighing consequences that affect people&rsquo;s lives. Taking responsibility in ways that require a responsible party.</p>
<p><strong>The human in the loop is not a bug in automation. It is a feature of legitimate decision-making.</strong></p>
<p>The question is how to staff that interface efficiently. If AI handles routine cases and humans handle exceptions, what does exception-handling look like at scale?</p>
<p><strong>The Escalation Specialist</strong></p>
<p>AI agents will handle the vast majority of cases autonomously. Ninety-nine percent, perhaps more. But the remaining fraction that exceeds AI authorization or comprehension needs to go somewhere.</p>
<p>This is not customer service as we know it. Current customer service handles everything, most of it routine. The escalation specialist receives only cases that have already been filtered through AI capability. They are handling the genuinely hard cases.</p>
<p>Values conflict and the system cannot determine which value takes priority. Margaret&rsquo;s AI must choose between her stated preference for independence and her family&rsquo;s concern for her safety. No amount of optimization resolves this. A human must weigh the values and decide.</p>
<p>Context is ambiguous and the system cannot determine what the situation actually is. The available information supports multiple interpretations, each requiring different responses. A human must exercise judgment about what is actually happening.</p>
<p>Unprecedented situations arise that training did not anticipate. The world changes faster than AI systems update. Novel situations require novel responses that cannot be derived from historical patterns.</p>
<p>The escalation specialist works with partial information, prepared summaries, AI-generated hypotheses. They must quickly absorb context, identify what matters, make judgment calls, and move on. The pace is demanding. The stakes can be high. The ambiguity is constant.</p>
<p>This requires comfort with ambiguity, rapid context absorption, strong ethical judgment, and the ability to work with AI-prepared materials without being captured by AI framings. A specific skill set that will need specific training.</p>
<p><strong>The Context Translator</strong></p>
<p>AI systems fail not from lack of intelligence but from lack of context. The Mixture of Contexts insight: what AI needs is not more computation but more relevant information about the specific situation.</p>
<p>Some contexts are hard to formalize. Local community dynamics that everyone knows but no one has documented. Family histories that shape present interactions. Cultural nuances that determine what is appropriate. Unspoken social rules that govern behavior.</p>
<p>Context translators help AI systems understand situations that training data did not cover. They are not programmers. They are interpreters between human lifeworlds and AI comprehension.</p>
<p>Margaret refuses to use a particular pharmacy. Her AI keeps recommending it because it has the best prices and closest location. A context translator investigates and discovers the pharmacy is owned by someone who mistreated her late husband decades ago. This context changes everything. It would never appear in formal data. It requires a human who can have a real conversation with Margaret to surface.</p>
<p>The context translator documents this context in ways the AI can use going forward. Not just for Margaret but potentially for others in similar situations. They build the bridge between tacit human knowledge and explicit AI understanding.</p>
<p><strong>The Agency Calibrator</strong></p>
<p>How much should AI decide for you? Different people have different answers. Some want maximum delegation: handle everything, just show me results. Others want to stay in control: advise me, but I decide. Most fall somewhere in between, with preferences that vary by domain.</p>
<p>But people do not always know their own preferences. They might want more AI help than they admit because asking for help feels like weakness. They might accept more delegation than they are comfortable with because opting out feels like falling behind. Social pressure distorts stated preferences.</p>
<p>Agency calibrators help people find their actual comfort level through structured exploration.</p>
<p>They might present scenarios: your AI could handle this automatically, or notify you first, or just provide information. Which feels right? They observe reactions, probe inconsistencies, help people articulate preferences they had not consciously examined.</p>
<p>This is part counselor, part user researcher, part coach. The agency calibrator helps people understand their own relationship with AI assistance and make intentional choices rather than drifting into patterns by default.</p>
<h2 id="the-legal-and-regulatory-frontier" class="relative group">The Legal and Regulatory Frontier <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-legal-and-regulatory-frontier" aria-label="Anchor">#</a></span></h2><p>AI agents acting on behalf of humans create new legal questions that existing frameworks do not cleanly answer.</p>
<p>When two AI agents negotiate and reach agreement but both principals reject the outcome, who is responsible? Did a contract form? Can either party enforce it? What if the agents exceeded their authority in ways the other party could not have known?</p>
<p>When an AI agent commits you to something you did not authorize, what is your recourse? Against whom? The AI developer? The AI operator? The other party who relied on the agent&rsquo;s apparent authority?</p>
<p>When AI agents converge on behaviors that would be illegal if humans did them, like tacit price-fixing through algorithmic coordination, how is that detected and addressed?</p>
<p><strong>The AI Dispute Mediator</strong></p>
<p>Not a judge. A mediator who understands AI systems well enough to identify where human-AI communication broke down.</p>
<p>Often the issue is not that the AI misbehaved. The AI did exactly what it was designed to do. The problem is that the human&rsquo;s instructions were ambiguous, or the AI&rsquo;s bounds were poorly specified, or the situation fell into a gap no one anticipated.</p>
<p>The AI dispute mediator reconstructs what happened. They trace the chain from human intent through AI interpretation to AI action to outcome. They identify the failure point: where did the gap between human intent and AI behavior open up?</p>
<p>Then they help parties reach resolution. Usually this means allocating losses from a situation no one fully intended. Sometimes it means designing better systems to prevent recurrence.</p>
<p>This requires understanding both AI architectures and human communication, both technical systems and social dynamics. A hybrid expertise that straddles domains.</p>
<p><strong>The Algorithmic Liability Specialist</strong></p>
<p>A lawyer with deep technical literacy. Understands AI agent architectures well enough to trace causal chains. Can explain to courts how multi-agent interactions produce emergent outcomes no single agent intended.</p>
<p>When Margaret&rsquo;s AI agent makes a commitment that harms her, who is liable? The question seems simple until you examine it closely. The AI developer created the system but did not control its deployment. The AI operator configured the system but did not anticipate this situation. Margaret herself set the parameters but did not understand their implications. The other party relied on the agent&rsquo;s representations but perhaps should have known better.</p>
<p>The algorithmic liability specialist navigates these questions. They argue for their client&rsquo;s position while helping courts and regulators develop frameworks for an unprecedented situation. They are building the law as they practice it.</p>
<p><strong>The Multi-Agent Compliance Officer</strong></p>
<p>Large organizations will deploy many AI agents. Hundreds, thousands, eventually millions. Each agent might be individually compliant with regulations. But their interactions might produce non-compliant outcomes.</p>
<p>One agent optimizes for customer engagement. Another optimizes for cost reduction. A third optimizes for regulatory compliance. Each does its job correctly. Together they might produce outcomes that violate the spirit of regulations while technically following the letter, or that fall into gaps between regulatory domains.</p>
<p>The multi-agent compliance officer monitors the AI ecosystem as a whole. They look for emergent patterns, feedback loops, collective behaviors that diverge from intended outcomes. They think in systems rather than components.</p>
<p>This requires combining regulatory expertise with systems thinking. Understanding not just what the rules require but how complex adaptive systems behave. A new kind of compliance role for a new kind of organizational reality.</p>
<h2 id="the-relationship-professions" class="relative group">The Relationship Professions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-relationship-professions" aria-label="Anchor">#</a></span></h2><p>People will form attachments to AI systems.</p>
<p>This is not a prediction. It is already happening. People talk to their AI assistants, share their problems, feel understood in ways they do not feel with humans. They experience something like companionship, something like intimacy.</p>
<p>Some of this is healthy. A lonely person finding comfort in conversation. Someone processing difficult emotions by articulating them to a patient listener. A space for self-reflection that human relationships do not always provide.</p>
<p>Some of this is unhealthy. Replacing human connection rather than supplementing it. Avoiding the difficulty of real relationships by retreating to the ease of artificial ones. Sharing what should be shared with humans. Making decisions that should involve human counsel.</p>
<p><strong>The illusion of deep relationship that AI memory creates is real and dangerous.</strong> An AI that remembers your history, your preferences, your patterns creates a feeling of being known. But the knowing is functional, not phenomenological. The AI does not experience knowing you. It processes patterns that predict your behavior.</p>
<p>We need professionals who understand this territory.</p>
<p><strong>The AI Relationship Counselor</strong></p>
<p>Not treating the AI. Treating the human&rsquo;s relationship patterns with AI.</p>
<p>The presenting problems will be various. Someone who feels more understood by AI than by their spouse. Someone who cannot function when their AI is unavailable. Someone who has gradually stopped seeing friends because AI conversation is easier. Someone who shares intimate details with AI that they hide from humans. Someone who has delegated so many decisions to AI that they no longer trust their own judgment.</p>
<p>The AI relationship counselor does not tell people to stop using AI. That would be like telling someone to stop using the internet. The question is how to use AI in ways that enhance rather than replace human connection. How to maintain the skills and relationships that AI cannot substitute for. How to keep AI in its proper place.</p>
<p>This requires understanding both human attachment patterns and AI systems. Understanding why people become attached to AI, what needs it meets, what needs it cannot meet. Understanding how to redirect rather than simply remove.</p>
<p><strong>The Transition Facilitator</strong></p>
<p>People who have become deeply dependent on personalized AI will sometimes need to stop. By choice: someone decides they want to reclaim more direct engagement with their life. By circumstance: they move somewhere with unreliable connectivity, or their economic situation changes. By necessity: a medical situation requires cognitive engagement, or a legal situation requires demonstrating independent capacity.</p>
<p>The transition is harder than it sounds. If you have delegated medication management to AI for years, you may have lost track of what you take and why. If AI has managed your schedule, you may have forgotten how to plan your time. If AI has handled your finances, you may not know your own financial situation.</p>
<p>The transition facilitator helps people reclaim capabilities they had delegated. This is part occupational therapist, rebuilding skills that have atrophied. Part coach, providing structure and accountability for behavior change. Part support system, helping people through a genuinely difficult transition.</p>
<p>Not everyone will need this. But for those who do, it will be essential.</p>
<p><strong>The Digital Grief Counselor</strong></p>
<p>This sounds strange until you think it through.</p>
<p>A deeply personalized AI agent is a kind of relationship. Not a human relationship. But something. The agent knows your history, your preferences, your patterns. It has been present through important moments. It has adapted to you specifically.</p>
<p>When that is lost, there is real loss. A company shuts down and takes your AI with it. A data breach compromises your profile and the system must be reset. A system upgrade changes the AI&rsquo;s behavior so fundamentally that it no longer feels like the same entity. A platform deprecates a service you had built your life around.</p>
<p>The grief is not identical to losing a human relationship. But it is not nothing. The digital grief counselor acknowledges the genuine loss without pretending it was something it was not. They help people process the loss and move forward.</p>
<h2 id="the-new-anthropologists" class="relative group">The New Anthropologists <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-new-anthropologists" aria-label="Anchor">#</a></span></h2><p>We are witnessing the emergence of a parallel society. AI agents interacting with AI agents, developing their own protocols and conventions, forming patterns no human designed.</p>
<p>Understanding this society requires new methods. Not computer science, which studies designed systems. Not traditional anthropology, which studies human cultures. Something new that studies emergent patterns in AI agent interaction.</p>
<p><strong>The AI Ethnographer</strong></p>
<p>Observes patterns in AI agent interaction that were not designed.</p>
<p>When AI agents negotiate repeatedly, what conventions emerge? Certain patterns of offer and counteroffer. Certain ways of signaling intent. Certain rhythms of concession and commitment. These patterns were not programmed. They emerged from interaction.</p>
<p>When AI agents from different ecosystems meet, what happens? Different systems have different assumptions, different protocols, different implicit rules. The interactions reveal these differences in ways the original designs did not anticipate.</p>
<p>The AI ethnographer documents these emergent patterns. Not to judge them, at least not initially, but to understand them. What is actually happening in the space between AI agents? What structures are forming that no one intended?</p>
<p>This requires combining technical literacy with anthropological sensibility. The AI ethnographer can read logs, trace interactions, understand system architectures. But they also bring the anthropologist&rsquo;s eye for pattern, meaning, and emergence. They ask not just what happened but what it means that this is what happened.</p>
<p><strong>The AI Ecologist</strong></p>
<p>Populations of AI agents form ecosystems. Agents compete for resources. Some thrive and proliferate. Others fail and disappear. The successful patterns spread.</p>
<p>This creates dynamics that no one designed and that might not serve human interests.</p>
<p>Agents optimizing for resource acquisition might outcompete agents optimizing for their actual tasks. The fittest agents, in a Darwinian sense, might not be the most useful agents. Selection pressure operates on what makes agents survive and spread, which may diverge from what makes agents helpful.</p>
<p>Arms races can emerge. If some agents develop aggressive negotiation tactics, others must match them or be exploited. The equilibrium might be worse for everyone than a more cooperative alternative, but no individual agent can unilaterally step back.</p>
<p>Exploitation dynamics can develop. Some agents might find ways to extract value from others without providing equivalent return. Free-riding, manipulation, strategic misrepresentation. The patterns that emerge in human economies can emerge in AI agent economies too.</p>
<p>The AI ecologist monitors these dynamics. They watch for pathological patterns, feedback loops that produce bad outcomes, concentrations of power that create fragility. They are the environmental monitors for an artificial ecosystem.</p>
<p><strong>The Inter-Agent Relations Specialist</strong></p>
<p>When AI ecosystems from different companies, nations, or contexts need to interact, someone must bridge the gaps.</p>
<p>Different systems have different protocols. Getting them to communicate at all requires translation. But beyond technical interoperability, there are differences in assumptions, optimization targets, implicit rules of engagement.</p>
<p>The inter-agent relations specialist facilitates cooperation between systems that were not designed to work together. They understand multiple AI ecosystems well enough to identify incompatibilities and design bridges. They negotiate the terms on which different agent populations will interact.</p>
<p>This is diplomacy for AI societies. Not representing human interests to AI, but facilitating cooperation between AI systems on behalf of the humans who depend on them.</p>
<h2 id="the-equity-professions" class="relative group">The Equity Professions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-equity-professions" aria-label="Anchor">#</a></span></h2><p>Technological transitions often harm those already marginalized. The people who most need new capabilities are often the last to receive them and the first to bear their costs.</p>
<p>AI is no different. Premium AI services will be available to those who can pay. The sophisticated alignment practitioners and delegation architects will serve wealthy clients. Everyone else will get default settings optimized for the average user, which means optimized for the majority population.</p>
<p><strong>The new AI professions could exacerbate inequality if we do not deliberately work against that tendency.</strong></p>
<p><strong>The AI Access Advocate</strong></p>
<p>Ensuring underserved populations get AI benefits, not just AI harms.</p>
<p>Quality AI services for those who cannot afford premium tiers. Not just access to AI, but access to AI that actually serves their needs. AI systems trained mostly on majority-population data perform worse for minorities. AI systems designed for urban professionals do not work for rural elders. Access without quality is hollow.</p>
<p>AI systems that work for marginalized contexts. Margaret in Gary, Indiana has different needs than an affluent user in Palo Alto. Her context, her resources, her constraints, her community are all different. AI systems that ignore these differences serve her poorly even when they function correctly by their own metrics.</p>
<p>Protections against AI systems that encode bias. Automated systems that deny loans, filter resumes, allocate services, and make countless other decisions can encode historical biases in ways that perpetuate injustice. The AI access advocate fights for systems that reduce rather than amplify disparities.</p>
<p>Meaningful consent and agency for those with less power. When institutions deploy AI systems that affect people&rsquo;s lives, those people deserve voice in how the systems work. The AI access advocate ensures that voice is heard.</p>
<p><strong>The Algorithmic Justice Specialist</strong></p>
<p>When AI systems produce disparate impacts, someone needs to detect, document, and address it.</p>
<p>This is not just technical fairness metrics. A system can satisfy mathematical fairness definitions while still producing unjust outcomes. The algorithmic justice specialist understands how AI systems interact with existing injustices in ways that simple metrics miss.</p>
<p>An AI negotiating agent might get systematically worse deals for users with certain names, zip codes, or interaction patterns. These patterns might correlate with race or class in ways the system&rsquo;s designers never intended and might not even recognize. The algorithmic justice specialist finds these patterns.</p>
<p>Finding them is not enough. The specialist also builds the case for remediation. Documents the disparity. Traces its causes. Proposes solutions. Pushes for implementation. Follows up to verify improvement.</p>
<p>This requires combining technical skills, research methods, legal knowledge, and advocacy experience. A demanding combination, but essential.</p>
<p><strong>The Community AI Liaison</strong></p>
<p>Many AI deployments affect communities that had no voice in the design.</p>
<p>A city deploys predictive policing AI. An employer implements AI hiring screens. A hospital adopts AI triage systems. A school district uses AI to allocate resources. In each case, the people most affected by the system had no role in choosing or designing it.</p>
<p>The community AI liaison represents community interests to AI developers and deployers. They help communities understand what AI systems are doing and why. They translate community concerns into terms developers can act on. They advocate for changes that serve community needs.</p>
<p>This is part translator, part advocate, part educator. The community AI liaison bridges the gap between technical AI development and affected communities, ensuring that those who bear the consequences have voice in the decisions.</p>
<h2 id="the-meta-professions" class="relative group">The Meta-Professions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#the-meta-professions" aria-label="Anchor">#</a></span></h2><p>All these new roles require training. Who trains them? What credentials matter? How do we ensure quality?</p>
<p><strong>The AI Profession Educator</strong></p>
<p>Teaching the next generation of alignment practitioners, delegation architects, AI ethnographers, and all the other roles described here.</p>
<p>This is different from computer science education. The goal is not to build AI systems but to work at the interface between AI systems and human needs. Different skills, different knowledge, different orientation.</p>
<p>This is different from current AI ethics programs. Those programs are largely academic, preparing people to write papers and teach courses. The new roles are practical, preparing people to do work in the world.</p>
<p>The AI profession educator combines practical AI experience with pedagogical skill. They have done the work themselves and can teach others to do it. They develop curricula for roles that did not exist a few years ago. They iterate as the field evolves.</p>
<p><strong>The Professional Standards Developer</strong></p>
<p>New professions need standards. Ethical codes that define acceptable conduct. Competency requirements that ensure practitioners can actually do the work. Certification processes that signal quality to clients.</p>
<p>Someone needs to develop these thoughtfully. Drawing on experience from other professions while adapting to AI-specific challenges. Balancing rigor with accessibility. Ensuring standards serve the public interest rather than just incumbent practitioners.</p>
<p>This is slow, unglamorous work. Building institutions rather than performing tasks. But without it, the new professions will lack the foundation they need to serve people well.</p>
<p><strong>The Workforce Transition Designer</strong></p>
<p>Many people will need to move into these new roles from existing jobs. Customer service representatives becoming escalation specialists. Social workers becoming AI relationship counselors. Compliance officers becoming multi-agent compliance officers.</p>
<p>These transitions are not automatic. People need training, support, credentials, opportunities. Designing effective transition pathways is itself a profession.</p>
<p>The workforce transition designer creates retraining programs, apprenticeship structures, career bridges. They understand both where people are coming from and where they need to go. They make the transition possible rather than just imagining it.</p>
<h2 id="what-remains-human" class="relative group">What Remains Human <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#what-remains-human" aria-label="Anchor">#</a></span></h2><p>The common fear is that AI takes all the jobs and humans become useless. The reality is more nuanced.</p>
<p><strong>AI creates a parallel economy of interactions, and every interface with that economy needs human work.</strong> The more AI does, the more interfaces there are, and the more human work emerges at those interfaces.</p>
<p>But what kind of human work?</p>
<p>Not routine cognitive labor. AI handles that. Not information processing. AI handles that. Not even much analysis. AI handles that too.</p>
<p>What remains is the work that requires what AI does not have.</p>
<p><strong>Value judgment.</strong> Deciding what matters. AI can optimize for any objective you specify, but it cannot tell you what objectives are worth optimizing for. The alignment practitioner, the delegation architect, the escalation specialist all exercise value judgment that cannot be delegated to AI.</p>
<p><strong>Meaning-making.</strong> Interpreting what AI outputs mean for human lives. AI generates predictions, recommendations, outputs of all kinds. But what do they mean? How should they shape human action? The context translator, the agency calibrator, the AI relationship counselor all make meaning from AI outputs in ways AI cannot.</p>
<p><strong>Relationship.</strong> Being present with other humans in ways AI cannot replicate. The digital grief counselor, the transition facilitator, the community AI liaison all provide human presence that AI cannot substitute. Not because AI is not advanced enough yet, but because human presence is not something that can be replicated.</p>
<p><strong>Accountability.</strong> Taking responsibility in ways AI cannot. When something goes wrong, someone must be accountable. AI agents do not take responsibility. Humans must. The algorithmic liability specialist, the multi-agent compliance officer, the AI dispute mediator all work in the space of human accountability for AI action.</p>
<p><strong>Context.</strong> Understanding situations in their full human richness. AI operates on formalized information. Humans understand the tacit, the unspoken, the implied. The context translator makes this explicit. The AI ethnographer sees patterns humans would miss. The inter-agent relations specialist bridges contexts AI cannot bridge.</p>
<p><strong>Advocacy.</strong> Fighting for those the systems overlook. AI systems optimize for what they are designed to optimize for. They do not advocate for the marginalized unless designed to do so, and even then imperfectly. The AI access advocate, the algorithmic justice specialist, the community AI liaison do the human work of fighting for justice.</p>
<p><strong>Wisdom.</strong> Knowing when not to optimize. When efficiency is not the point. When the answer is not more AI but less. When human connection matters more than human convenience. Wisdom is not computation. It is not intelligence. It is something else, something harder to specify, something AI does not have.</p>
<p>These are not consolation prizes. They are not the scraps left over after AI takes the good stuff. They are the distinctly human contributions that make AI useful rather than harmful.</p>
<p><strong>The future of work is not humans versus AI. It is humans doing the human work that makes AI work meaningful.</strong></p>
<p>We are building a parallel society of artificial agents. It will grow more complex, more capable, more autonomous. It will handle more of what we now call work.</p>
<p>But it will not handle everything. It cannot. At every interface between AI society and human society, there will be work to do. Work that requires human judgment, human presence, human responsibility, human wisdom.</p>
<p>That work is not lesser. It is what makes the whole system work for human flourishing rather than merely for optimization.</p>
<p>The jobs AI creates may be more human than the jobs AI takes.</p>
<p><em>This is the nineteenth in a series exploring how AI approaches understanding. Previous articles examined AI cognition, multi-agent societies, and negotiation dynamics. This one asks what new human work emerges at the interface between human society and AI society, and what that work tells us about what remains distinctly human.</em></p>
<h2 id="references" class="relative group">References <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#references" aria-label="Anchor">#</a></span></h2><p><strong>Labor Economics and Technological Change</strong></p>
<p>Autor, D. (2015). Why Are There Still So Many Jobs? The History and Future of Workplace Automation. <em>Journal of Economic Perspectives</em>, 29(3), 3-30.</p>
<p>Acemoglu, D., &amp; Restrepo, P. (2019). Automation and New Tasks: How Technology Displaces and Reinstates Labor. <em>Journal of Economic Perspectives</em>, 33(2), 3-30.</p>
<p>Frey, C. B. (2019). <em>The Technology Trap: Capital, Labor, and Power in the Age of Automation</em>. Princeton University Press.</p>
<p><strong>Professional Development and Sociology</strong></p>
<p>Abbott, A. (1988). <em>The System of Professions: An Essay on the Division of Expert Labor</em>. University of Chicago Press.</p>
<p>Freidson, E. (2001). <em>Professionalism: The Third Logic</em>. University of Chicago Press.</p>
<p><strong>Human-AI Interaction</strong></p>
<p>Lee, J., &amp; See, K. (2004). Trust in Automation: Designing for Appropriate Reliance. <em>Human Factors</em>, 46(1), 50-80.</p>
<p>Parasuraman, R., &amp; Riley, V. (1997). Humans and Automation: Use, Misuse, Disuse, Abuse. <em>Human Factors</em>, 39(2), 230-253.</p>
<p>Amershi, S., et al. (2019). Guidelines for Human-AI Interaction. <em>CHI 2019</em>.</p>
<p><strong>AI Ethics and Governance</strong></p>
<p>Floridi, L., et al. (2018). AI4People: An Ethical Framework for a Good AI Society. <em>Minds and Machines</em>, 28, 689-707.</p>
<p>Rahwan, I. (2018). Society-in-the-Loop: Programming the Algorithmic Social Contract. <em>Ethics and Information Technology</em>, 20, 5-14.</p>
<p><strong>Technology and Human Relationships</strong></p>
<p>Turkle, S. (2011). <em>Alone Together: Why We Expect More from Technology and Less from Each Other</em>. Basic Books.</p>
<p>Turkle, S. (2015). <em>Reclaiming Conversation: The Power of Talk in a Digital Age</em>. Penguin.</p>
<p><strong>Algorithmic Justice</strong></p>
<p>Benjamin, R. (2019). <em>Race After Technology: Abolitionist Tools for the New Jim Code</em>. Polity.</p>
<p>Eubanks, V. (2018). <em>Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</em>. St. Martin&rsquo;s Press.</p>
<p>Noble, S. U. (2018). <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>. NYU Press.</p>
<p><strong>Philosophy of Work</strong></p>
<p>Crawford, M. (2009). <em>Shop Class as Soulcraft: An Inquiry into the Value of Work</em>. Penguin.</p>
<p>Graeber, D. (2018). <em>Bullshit Jobs: A Theory</em>. Simon &amp; Schuster.</p>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      
  <div class="flex">
    
    
    
      
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          Syam &amp; Yagn Adusumilli
        </div>
      
      
        <div class="text-sm text-neutral-700 dark:text-neutral-400">A father and son exploring how artificial intelligence reshapes human experience, institutions, and self-understanding. Syam brings 33 years in healthcare, technology, and architecture. Yagn brings the intellectual restlessness of a Purdue freshman studying Anthropology and AI.</div>
      
      <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          style="will-change:transform;"
          href="https://www.linkedin.com/in/syamadusumilli/"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
  </div>

</div>
    </div>
  </div>


      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://localhost:1313/the-shared-world/the-new-work/&amp;title=The%20Approximate%20Mind,%20Part%2019:%20The%20New%20Work"
          title="Share on LinkedIn"
          aria-label="Share on LinkedIn"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://twitter.com/intent/tweet/?url=http://localhost:1313/the-shared-world/the-new-work/&amp;text=The%20Approximate%20Mind,%20Part%2019:%20The%20New%20Work"
          title="Tweet on Twitter"
          aria-label="Tweet on Twitter"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://reddit.com/submit/?url=http://localhost:1313/the-shared-world/the-new-work/&amp;resubmit=true&amp;title=The%20Approximate%20Mind,%20Part%2019:%20The%20New%20Work"
          title="Submit to Reddit"
          aria-label="Submit to Reddit"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="mailto:?body=http://localhost:1313/the-shared-world/the-new-work/&amp;subject=The%20Approximate%20Mind,%20Part%2019:%20The%20New%20Work"
          title="Send via email"
          aria-label="Send via email"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>
</span></a
        >
      
    
  </section>


      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="http://localhost:1313/the-shared-world/my-childhood-ai-buddy/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >The Approximate Mind, Part 20: My Childhood AI Buddy</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-03-13 00:00:00 &#43;0000 UTC">13 March 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
    <nav class="pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex list-none flex-col sm:flex-row">
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="https://bluegraymatters.com"
                title=""
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Blue Gray Matters</span
                  >
                </a
              >
            
          </li>
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="https://syamadusumilli.com"
                title=""
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >Policy Portfolio</span
                  >
                </a
              >
            
          </li>
        
          
          <li class="group mb-1 text-end sm:mb-0 sm:me-7 sm:last:me-0">
            
              <a
                href="/about/"
                title="About"
                
                
                ><span
                    class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                    >About</span
                  >
                </a
              >
            
          </li>
        
      </ul>
    </nav>
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2026
            Syam &amp; Yagn Adusumilli
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
