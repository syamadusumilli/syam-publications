<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Seeing Differently: Design Approaches to State Agency Implementation | Syam Adusumilli</title>
<meta name="keywords" content="rural-health, rhtp, state-policy, series-5, companion">
<meta name="description" content="RHTP Series 5: Seeing Differently: Design Approaches to State Agency Implementation">
<meta name="author" content="Syam Adusumilli">
<link rel="canonical" href="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1324d480049e0a82077f08d0ee9a7ce0c8f917d468a61974dd878f3838870c9c.css" integrity="sha256-EyTUgASeCoIHfwjQ7pp84Mj5F9Rophl03YePODiHDJw=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/">
  <meta property="og:site_name" content="Syam Adusumilli">
  <meta property="og:title" content="Seeing Differently: Design Approaches to State Agency Implementation">
  <meta property="og:description" content="RHTP Series 5: Seeing Differently: Design Approaches to State Agency Implementation">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="rural-health">
    <meta property="article:published_time" content="2026-05-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2026-05-12T00:00:00+00:00">
    <meta property="article:tag" content="Rural-Health">
    <meta property="article:tag" content="Rhtp">
    <meta property="article:tag" content="State-Policy">
    <meta property="article:tag" content="Series-5">
    <meta property="article:tag" content="Companion">
    <meta property="og:image" content="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover.webp">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/state-agency-decision-authority-matrix/">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/which-state-agency-structures-support-transformation/">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/federal-state-relationship-cooperative-federalism-and-its-discontents/">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/performance-measurement-accountability-theater/">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/procurement-and-contracting-the-compliance-trap/">
      <meta property="og:see_also" content="http://localhost:1313/rural-health/series-5/stakeholder-coordination-the-limits-of-convening/">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover.webp">
<meta name="twitter:title" content="Seeing Differently: Design Approaches to State Agency Implementation">
<meta name="twitter:description" content="RHTP Series 5: Seeing Differently: Design Approaches to State Agency Implementation">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Rural Health Transformation Project",
      "item": "http://localhost:1313/rural-health/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Series 5: State Agency Structures",
      "item": "http://localhost:1313/rural-health/series-5/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Seeing Differently: Design Approaches to State Agency Implementation",
      "item": "http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Seeing Differently: Design Approaches to State Agency Implementation",
  "name": "Seeing Differently: Design Approaches to State Agency Implementation",
  "description": "RHTP Series 5: Seeing Differently: Design Approaches to State Agency Implementation",
  "keywords": [
    "rural-health", "rhtp", "state-policy", "series-5", "companion"
  ],
  "articleBody": "The organizational chart shows the Department of Health as lead agency. The consultant recommends better coordination mechanisms. The federal monitor suggests relationship-building investments. The evaluator proposes improved metrics for inter-agency collaboration.\nEveryone is solving the wrong problem.\nThe coordination challenge exists because someone designed a system requiring coordination. The relationship dependency exists because someone designed a system that fails without strong relationships. The measurement gap exists because someone designed requirements exceeding state capacity to document.\nThese are design failures, not implementation failures. Solving them requires different design, not better measurement of dysfunctional design.\nThe Series 5 Synthesis concluded that leadership, relationships, capacity, and political commitment matter more than structures for implementation success. The natural policy response is to measure these things: develop relationship quality indicators, track leadership attention metrics, assess political commitment scores, document capacity development progress.\nThis response extends the compliance orientation that Series 5 critiques. It treats measurement as the solution to problems that measurement created. It assumes that tracking alignment produces alignment, that documenting relationships builds relationships, that assessing commitment generates commitment.\nIt does not. Measurement changes what it measures. Relationships that become measured become performed. Leadership attention that becomes tracked becomes theatrical. The authentic phenomena that predict implementation success cannot survive their transformation into metrics.\nThis companion document takes a different approach. Rather than asking how to improve state agency implementation through better measurement, it asks how to see state agency implementation differently. The goal is not better metrics but better design: creating conditions where alignment emerges naturally rather than conditions where alignment must be monitored into existence.\nPart I: The Measurement Trap How Measurement Crowds Out Alignment Series 5 documented performance measurement as accountability theater. States produce reports satisfying requirements without informing decisions. Measurement consumes capacity that could serve communities. Gaming indicators replaces achieving outcomes. The measurement system performs accountability rather than creating it.\nThe standard response is better measurement. More meaningful indicators. Outcome metrics rather than process metrics. Learning systems rather than compliance systems.\nThis response assumes measurement solves measurement problems. It does not.\nMeasurement changes what it measures. The act of measuring transforms the phenomenon measured. Relationships subjected to assessment become relationships performed for assessors. When CMS evaluates federal-state relationship quality, states optimize for relationship appearance. The authentic collaboration that produces implementation success differs fundamentally from collaboration performed for evaluators. Both may look similar in documentation. They produce different results.\nMeasurement consumes attention. Every hour documenting coordination is an hour not coordinating. Every meeting about measurement systems is a meeting not about implementation. Every staff position dedicated to reporting is a position not dedicated to service. The overhead of accountability crowds out the substance accountability supposedly ensures.\nMeasurement creates adversarial dynamics. Evaluation inherently judges. Judgment creates defensiveness. Defensiveness undermines trust. Trust enables the authentic relationships that implementation requires. The measurement relationship is structurally adversarial even when evaluators intend partnership. States being assessed cannot fully trust assessors. The dynamic is inherent to the relationship, not a function of evaluator intentions.\nMeasurement assumes the measurer knows what matters. Federal indicators reflect federal priorities. State indicators reflect state priorities. Community indicators reflect community priorities. These may align or diverge. The act of selecting indicators embeds assumptions about value that the indicator system cannot question. When federal indicators dominate (as they do in RHTP), federal assumptions about value dominate regardless of whether those assumptions fit local reality.\nWhat Measurement Cannot Capture The factors predicting implementation success, according to Series 5, are precisely those measurement degrades.\nLeadership focus that emerges from genuine priority differs from leadership focus responding to measurement incentives. A governor who cares about rural health because rural communities matter to them behaves differently from a governor performing care because leadership attention metrics require it. The external behavior may look similar. The underlying commitment differs. When pressure mounts and tradeoffs sharpen, genuine commitment persists while performed commitment evaporates. Measurement cannot distinguish them until the moment of pressure reveals the difference.\nRelationship quality emerging from trust differs from relationship quality performed for assessment. When states know CMS evaluates their federal relationship, they optimize for appearance. Calls get made that would not otherwise occur. Documentation gets produced that overstates collaboration. The measurement system generates evidence of relationships rather than relationships themselves. Authentic collaboration becomes impossible when collaboration is being judged because judgment introduces the adversarial dynamic that collaboration requires transcending.\nPolitical commitment accepting genuine cost differs from political commitment accepting measurable cost. Politicians willing to make difficult decisions do so because they believe the outcome justifies the cost. Belief cannot be measured without changing it. Political commitment metrics would generate commitment performance: the appearance of willingness to bear cost without the substance. When the cost actually arrives, performed commitment fails.\nCapacity enabling implementation differs from capacity satisfying assessment. States can document evaluation infrastructure without having functional evaluation. They can demonstrate procurement processes without executing timely procurement. They can show coordination mechanisms without coordinating. The documentation and the capacity are different things. Measurement systems that accept documentation as evidence of capacity systematically overestimate capacity because documentation is easier than function.\nThe Design Alternative Rather than measuring alignment, design systems where alignment emerges naturally.\nThis requires different questions. Not “how do we measure leadership attention?” but “what conditions create genuine leadership attention without measurement?” Not “how do we assess relationship quality?” but “what structures make collaboration rational rather than performed?” Not “how do we track capacity development?” but “what program designs match available capacity rather than requiring capacity that does not exist?”\nThe alternative is design thinking applied to implementation challenges. Design thinking asks what conditions produce desired outcomes, then creates those conditions. It does not ask how to measure whether desired outcomes occurred, then pressure systems toward measured performance.\nDesign creates conditions. Measurement documents conditions. When conditions are wrong, measurement documents failure without changing it. When conditions are right, measurement is unnecessary because success emerges from the conditions themselves.\nThe rest of this document applies design thinking to the implementation challenges Series 5 identified. Each section offers an alternative lens: a way of seeing challenges that reveals design solutions invisible to measurement orientation.\nPart II: Alternative Lenses Lens 1: The Authority Clarity Lens The standard view: Authority fragmentation creates coordination challenges. Multiple agencies hold pieces of implementation authority. No single entity controls enough to act decisively. The solution is better coordination: mechanisms, processes, relationships that bridge authority gaps. Measure coordination effectiveness to ensure coordination occurs.\nThe alternative view: Authority fragmentation creates coordination requirements. The coordination challenge exists because the system was designed to require coordination. The solution is reducing fragmentation so coordination becomes unnecessary. The best coordination is no coordination because the system does not require it.\nEvery coordination mechanism is a design failure made visible. Someone designed a system where Agency A controls budgets, Agency B controls programs, and Agency C controls Medicaid. This design created the coordination requirement. The coordination mechanisms addressing this requirement are patches on flawed design, not solutions.\nConsolidation over coordination. Where authority can be consolidated, consolidate it. Michigan’s DHHS holds authority that Georgia distributes across DCH and DPH. Michigan requires less coordination because Michigan’s design consolidated what Georgia’s design fragmented. For Georgia, the solution is not better DCH-DPH coordination but authority consolidation that makes coordination unnecessary. Whether Georgia can achieve consolidation depends on political factors. The design insight remains: coordination requirements are design failures that consolidation eliminates.\nSeparation over integration. Where consolidation is politically impossible, clean separation may outperform messy integration. Distinct domains with clear boundaries require less coordination than overlapping domains with shared authority. If Agency A handles all workforce functions and Agency B handles all facility functions with no overlap, coordination requirements shrink to the interface between domains. The design question becomes: where should domain boundaries fall to minimize coordination requirements?\nAutomation over negotiation. Where decisions repeat, automate them. Every decision reduced to algorithm is a decision removed from coordination dependency. Procurement thresholds allowing direct purchase avoid procurement negotiation. Pre-approved modification authorities avoid modification negotiation. Automatic flexibility triggers avoid flexibility negotiation. The goal is not faster negotiation but eliminated negotiation because the system handles decisions automatically.\nPractical application: Before investing in coordination mechanisms, ask why this decision requires coordination. Often the answer reveals design choices creating the coordination requirement. The design insight is not “coordinate better” but “redesign so coordination becomes unnecessary.”\nGeorgia could invest in DCH-DPH coordination infrastructure. Or Georgia could consolidate authority so coordination infrastructure becomes unnecessary. The second approach solves the problem; the first manages it. Managing problems is necessary when solving them is impossible. But solving should be attempted before managing is accepted.\nLens 2: The Incentive Alignment Lens The standard view: State and federal interests diverge. States pursue state priorities; CMS pursues federal priorities. When these conflict, states underperform on federal objectives. The solution is federal oversight ensuring states pursue federal objectives despite state preferences. Measure compliance to ensure states do what CMS requires.\nThe alternative view: State and federal interests diverge because program design creates divergence. The incentive misalignment is not natural but designed. The solution is redesigning programs so state and federal interests naturally align. When incentives align, compliance is unnecessary because states pursue federal objectives for state reasons.\nWhen states optimize for metrics rather than outcomes, the problem is not state behavior but program design. The program created metrics misaligned with outcomes. Better metrics do not solve this; they relocate the misalignment. The solution is program design where pursuing state interests automatically pursues federal interests.\nOutcome funding over process funding. RHTP funds flow for performed processes: activities documented, reports submitted, milestones claimed. This creates incentive to perform processes regardless of outcomes. Alternative design where funds flow for achieved outcomes (rural health improvement measured, access expansion demonstrated, mortality reduction documented) would align state incentives with federal objectives without compliance measurement. States would pursue outcomes because funding depends on outcomes, not because compliance systems pressure outcome pursuit.\nRisk sharing over risk transfer. Current design transfers implementation risk to states. States must perform or face consequences. CMS bears no risk from program design failures. This misaligns incentives: CMS designs programs without bearing design failure costs; states implement programs bearing all failure costs including design-caused failure. Alternative design sharing risk (federal funds contingent on federal support effectiveness, CMS accountability for design adequacy) would align federal and state incentives around program success rather than program compliance.\nFlexibility as default over flexibility as exception. Current design requires states to justify deviation from federal standards. The default is federal uniformity; flexibility requires permission. This creates incentive to follow federal templates even when templates fit poorly. Alternative design where flexibility is default (federal justification required for imposing uniformity rather than state justification required for deviation) would align incentives toward state-appropriate implementation.\nPolitical credit alignment. Governors seek credit for success. Current design allows CMS to claim credit for investment (“we provided $50 billion”) while states bear accountability for outcomes (“the state failed to implement effectively”). This misaligns political incentives: governors gain little from RHTP success because credit flows federally while bearing substantial risk from RHTP failure because blame flows to states. Alternative design enabling gubernatorial credit-claiming for rural health improvement would align political incentives with implementation success.\nPractical application: Before creating compliance mechanisms, ask why state incentives diverge from federal objectives. Often the answer reveals program design choices creating the divergence. The design insight is not “enforce compliance” but “redesign so compliance becomes unnecessary because state interests align with federal objectives.”\nThe 2030 sustainability cliff illustrates incentive misalignment. States must build sustainable systems knowing funding ends. Governors investing in systems that collapse after they leave office gain little political benefit. Federal design created this sustainability disincentive; federal redesign could solve it. Automatic RHTP extension contingent on outcome achievement would align gubernatorial incentives with sustainability investment without sustainability metrics.\nLens 3: The Capacity Reality Lens The standard view: States lack capacity to implement sophisticated programs. Rural health offices are understaffed. Evaluation expertise is scarce. Procurement systems are slow. The solution is capacity building: technical assistance, training, staff development, system investment. Measure capacity development to ensure capacity grows.\nThe alternative view: Programs exceed state capacity because programs are designed without capacity constraints. The capacity gap is not a state failure but a program design failure. The solution is designing programs states can actually implement. Design to capacity rather than designing beyond capacity and hoping capacity catches up.\nDesigning programs exceeding implementer capacity guarantees implementation failure. This is obvious in principle but ignored in practice. RHTP requirements assume evaluation capacity, procurement speed, and coordination sophistication that many states demonstrably lack. The design guarantees some states will fail because the design requires capacity those states do not have.\nDesign to capacity, not to ambition. Current RHTP design reflects federal ambition: sophisticated measurement, comprehensive coordination, rapid deployment. Designing instead to actual state capacity (simpler measurement, reduced coordination requirements, realistic timelines) would improve implementation without capacity building. Capacity building takes years. Design simplification takes decisions. States lacking evaluation infrastructure cannot build it fast enough for RHTP’s timeline. But RHTP could be redesigned to require evaluation infrastructure states actually have.\nTiered programs over uniform programs. One program design cannot fit fifty states with different capacities. Massachusetts has evaluation infrastructure Kansas lacks. California has procurement systems Wyoming cannot match. Uniform requirements guarantee that high-capacity states are under-challenged while low-capacity states are overwhelmed. Tiered design (sophisticated version for states that can implement it, simplified version for states that cannot) matches implementation requirements to implementation ability.\nCapacity as constraint, not variable. Planning that treats capacity as constraint asks: what can we accomplish with available capacity? Planning that treats capacity as variable asks: how do we build capacity to accomplish our ambition? The first approach implements. The second approach plans to implement while waiting for capacity that may never arrive. RHTP’s five-year timeline does not provide time for substantial capacity building. Treating capacity as constraint produces realistic plans; treating capacity as variable produces aspirational plans that fail.\nOutsourcing over building. States lacking capacity can access capacity rather than build it. Universities have evaluation expertise. Consultants have procurement experience. Other states have implementation knowledge. Program design facilitating capacity access (encouraging partnerships, enabling contracts, connecting peer states) enables implementation without waiting for capacity development.\nPractical application: Before investing in capacity building, ask why this program requires capacity the state lacks. Often the answer reveals design choices creating the capacity requirement. The design insight is not “build capacity faster” but “redesign so available capacity suffices.”\nThe measurement sophistication RHTP requires exceeds many states’ evaluation capacity. Capacity building would take years. Measurement simplification would take decisions. Fewer, simpler metrics that low-capacity states can actually produce would generate better data than complex requirements producing compliance fiction from states that cannot implement them.\nLens 4: The Relationship Substrate Lens The standard view: Relationships matter for implementation. The Montana vignette shows how strong federal-state relationships enable rapid problem-solving. The Georgia vignette shows how weak relationships produce delays harming communities. The solution is relationship investment: building trust, cultivating partnerships, developing personal connections. Assess relationship quality to ensure relationships are adequate.\nThe alternative view: Relationships matter because program design creates relationship dependency. Implementation depending on relationships depends on factors no design can control. The solution is designing programs that succeed regardless of relationship quality. Robust design works with bad relationships while performing better with good ones.\nRelationships emerge from personal chemistry, accumulated history, institutional culture, and circumstances that programs cannot mandate. Some project officers and state directors will develop trust. Others will not. Some states enter RHTP with collaborative federal histories. Others enter with adversarial legacies. Program design cannot change these starting points. Program design can determine whether these starting points determine implementation success.\nRobustness over optimization. Designs requiring good relationships to succeed are fragile. When relationships are strong, they succeed; when relationships are weak, they fail. Robust designs succeed adequately with weak relationships while performing better with strong ones. The design question is not “how do we ensure good relationships” but “how do we succeed regardless of relationship quality.”\nStructural alignment over relational alignment. When structures align interests, relationships matter less. When structures misalign interests, even good relationships face strain. Two agencies with conflicting mandates will struggle to collaborate regardless of personal relationships between directors. Two agencies with aligned mandates will collaborate more easily even without strong personal relationships. Structural alignment creates conditions where relationships can flourish; it also reduces dependence on relationships flourishing.\nRedundancy over dependency. Single points of relationship failure create fragility. If implementation depends on one project officer relationship, project officer turnover threatens implementation. If implementation depends on one key partnership, partnership deterioration threatens implementation. Redundant relationships (multiple federal contacts, multiple state partnerships, multiple communication channels) survive individual relationship failures.\nFormalization as relationship insurance. Informal relationships work until they do not. The handshake agreement holds until the parties shake hands with different people. The understanding persists until someone misunderstands. Formalization (MOUs, contracts, documented agreements, written protocols) provides insurance against relationship failure. When relationships work, formalization is unnecessary overhead. When relationships fail, formalization enables continuation despite failure. The goal is not replacing relationships with formalization but ensuring formalization exists when relationships fail.\nPractical application: Before investing in relationship building, ask why implementation depends on this relationship. Often the answer reveals design choices creating the dependency. The design insight is not “build stronger relationships” but “redesign so implementation succeeds regardless of relationship strength.”\nMontana’s rapid response to hospital closure reflected strong relationships. But implementation design could have enabled adequate response regardless of relationship quality. Automatic flexibility for defined circumstances (provider closure meets predefined criteria, modification authority triggers automatically) would remove relationship dependency from flexibility access. States with weak CMS relationships would access the same flexibility as states with strong relationships because flexibility would be structural rather than relational.\nLens 5: The Political Economy Lens The standard view: Political factors constrain implementation. Governors face electoral pressures. Legislatures control budgets. Provider interests exercise influence. These dynamics limit what agencies can accomplish. The solution is building political support: cultivating champions, creating coalitions, demonstrating benefits. Assess political commitment to ensure adequate political backing.\nThe alternative view: Political constraints exist because program design ignores political economy. Programs requiring political actors to behave against their incentives will fail. The solution is designing programs aligning with political incentives rather than fighting them. Work with political reality rather than wishing it were different.\nGovernors will pursue electoral advantage. Legislators will respond to influential interests. Providers will protect their economic position. These behaviors are not failures of political will but predictable responses to political incentives. Program design ignoring these incentives designs for a political world that does not exist.\nCredit distribution matters. Politicians support programs generating political credit. RHTP design that enables gubernatorial credit-claiming generates gubernatorial support without requiring governors to transcend political self-interest. Design reserving credit for federal officials or diffusing credit across many actors generates less state political investment. The question is not whether governors should be more public-spirited but how program design can align credit flows with implementation needs.\nBlame avoidance matters more. Politicians fear programs creating blame risk more than they value programs creating credit opportunity. RHTP design concentrating blame on states (state implementation failed) while diffusing credit (federal investment succeeded, outcomes varied by state) creates political incentive to minimize engagement, not maximize it. Design protecting state officials from blame for design failures (federal accountability for program adequacy, shared responsibility for outcome shortfalls) would enable implementation investment by reducing political risk.\nInterest group alignment matters. Provider interests dominate health policy in most state capitals. Hospital associations, physician organizations, and health system lobbies exercise substantial political influence. RHTP design threatening provider interests generates provider opposition creating political cost that governors must bear or avoid. Design aligning transformation with provider interests (or at least neutralizing opposition through grandfather provisions, transition support, or alternative value propositions) reduces political constraint on implementation.\nElectoral cycle alignment matters. Governors facing reelection invest in visible, quick wins. Programs producing visible results within electoral cycles attract gubernatorial attention. Programs requiring long-term investment before visible results attract gubernatorial neglect. RHTP’s five-year timeline spans multiple electoral cycles. Design producing early visible wins (Year 1-2 achievements governors can claim) would align electoral incentives with implementation investment. Design where visible results arrive only in Year 4-5 (after many governors have moved on) misaligns electoral timing with program timeline.\nPractical application: Before building political coalitions, ask why this program faces political opposition or neglect. Often the answer reveals design choices creating the political problem. The design insight is not “overcome political resistance” but “redesign so political incentives support implementation.”\nThe sustainability challenge illustrates political economy failure. RHTP requires states to build systems potentially not surviving beyond 2030. Governors investing in programs that collapse after they leave office gain little political benefit and bear substantial political risk (they built something that failed). Design extending RHTP contingent on outcome achievement would align gubernatorial incentives with sustainability investment by ensuring political benefit from long-term system building.\nLens 6: The Community Agency Lens The standard view: Community engagement improves implementation. Stakeholder input helps programs fit local needs. Advisory committees surface local knowledge. Public participation builds program legitimacy. The solution is robust engagement processes: stakeholder meetings, public comment, advisory structures. Assess participation to ensure communities are engaged.\nThe alternative view: Community engagement fails because communities lack agency, not voice. Participation without power is theater. The solution is designing programs where communities hold actual authority, not programs where communities provide input that may or may not influence decisions others make. Transfer authority, not process.\nAdvisory committees that provide input ignored teach community members their time is wasted. Stakeholder processes that solicit perspectives without changing decisions produce cynicism undermining future engagement. Public participation that performs inclusion without practicing it generates the appearance of community voice without its substance.\nAuthority over input. Communities deciding implementation details engage differently than communities advising on implementation details. The difference is not participation level but authority distribution. Community members asked “what do you think we should do?” engage differently than community members asked “what have you decided to do?” The first is consultation; the second is governance. Design transferring actual authority produces different engagement than design soliciting input on decisions made elsewhere.\nResources over process. Community organizations with resources can act. Community organizations without resources can only advise. Transferring decision authority without transferring resources produces authority without capacity: communities that can decide but cannot implement their decisions. Design directing resources to community control enables community agency that advisory processes cannot create.\nAccountability reversal. Current design holds states accountable to CMS for community engagement. States must document stakeholder processes, show participation evidence, demonstrate input solicitation. This accountability direction makes communities objects of engagement rather than subjects holding power. Alternative design holding states accountable to communities for implementation quality (community authority to assess state performance, community voice in determining state compliance) would reverse accountability direction and the power dynamics flowing from it.\nExit over voice. Communities depending on single providers have voice but not exit. They can complain about services but cannot choose alternatives. Voice without exit is weak. Design creating options (multiple providers, alternative delivery models, competitive service availability) enables community agency that voice processes cannot replace. Communities that can leave have power; communities that can only comment do not.\nPractical application: Before designing stakeholder processes, ask what authority communities will actually hold. If the answer is “input that may or may not influence decisions,” recognize the limitation. The design insight is not “improve participation quality” but “transfer actual authority so participation becomes governance.”\nRHTP’s stakeholder requirements produce advisory committees across fifty states. Almost none transfer actual authority to communities. Community members provide input; state agencies decide. Design requiring community approval for specified decisions (subaward allocations, priority setting, vendor selection) would transfer actual authority rather than creating input processes. Whether such design is politically feasible depends on state context. The design insight remains: participation without authority is theater that design improvements cannot make genuine.\nPart III: Design Principles The six lenses converge on principles transcending specific domains.\nPrinciple 1: Reduce Coordination Requirements Every coordination requirement is a potential failure point. Systems requiring extensive coordination depend on relationships, goodwill, and alignment that may not exist. Design reducing coordination requirements reduces failure modes.\nBefore creating coordination mechanisms, redesign to eliminate coordination need. Consolidate authority where possible. Separate domains cleanly where consolidation fails. Automate repeated decisions. The goal is not better coordination but less need to coordinate.\nPrinciple 2: Align Incentives Structurally When incentives misalign, behavior diverges from objectives regardless of measurement. Compliance systems attempting to force aligned behavior despite misaligned incentives face endless resistance. Design aligning incentives produces aligned behavior without compliance overhead.\nBefore creating compliance mechanisms, redesign to align incentives. Connect funding to outcomes. Share risk between federal and state partners. Distribute credit appropriately. Enable political benefit from implementation success. The goal is not enforced compliance but unnecessary compliance because incentives align.\nPrinciple 3: Design to Capacity Programs exceeding implementer capacity fail. Programs scaled to capacity succeed. Capacity building takes years; design simplification takes decisions.\nBefore investing in capacity building, redesign to match available capacity. Simplify requirements. Create tiered program designs. Accept that different states will implement different versions. Enable capacity access through partnership rather than capacity creation through development. The goal is not expanded capacity but reduced capacity requirements.\nPrinciple 4: Reduce Relationship Dependency Relationships emerge from factors design cannot control. Relationship-dependent implementation gambles on relationships forming. Robust design succeeds regardless of relationship quality.\nBefore investing in relationship building, redesign to reduce relationship dependency. Create structural alignment making relationships beneficial but not required. Build redundancy surviving individual relationship failures. Formalize as insurance when relationships fail. The goal is not stronger relationships but reduced dependence on relationship strength.\nPrinciple 5: Work With Political Incentives Programs requiring political actors to behave against their incentives will fail. Programs aligned with political incentives succeed without political cultivation.\nBefore building political support, redesign to align with political incentives. Enable credit-claiming. Protect against blame. Align with provider interests where possible. Produce visible results within electoral cycles. The goal is not overcoming political resistance but eliminating reasons for resistance.\nPrinciple 6: Transfer Authority, Not Process Community engagement without authority is theater. Communities with actual decision authority engage differently than communities invited to advise.\nBefore designing participation processes, determine what authority communities will actually hold. Transfer genuine authority where possible. Direct resources alongside authority. Create accountability to communities, not just accountability for engaging communities. The goal is not better participation but actual power.\nPart IV: What Cannot Be Redesigned Design thinking has limits. Some constraints are fixed.\nConstitutional federalism distributes authority between federal and state governments in ways RHTP cannot change. CMS can condition funding but cannot command state action. States retain implementation discretion that federal design cannot override. Design must work within this distribution.\nState political systems operate according to incentives design can align with but cannot eliminate. Governors will seek electoral advantage. Legislatures will respond to constituent interests. Providers will protect economic position. Design that ignores these realities fails; design that works with them succeeds.\nRHTP statutory structure fixes the five-year timeline, funding allocation, and basic program parameters. Design improvements must occur within existing statutory framework. Fundamental restructuring would require legislative action beyond RHTP’s administrative scope.\nPrior history shapes the context within which design operates. States enter RHTP with accumulated capacity, established relationships, and embedded political dynamics. Design cannot erase history. It can create conditions where history matters less.\nLeadership and commitment cannot be designed into existence. Design can create conditions favorable to leadership attention and political commitment. It cannot guarantee that attention materializes or commitment develops. The factors mattering most for implementation are precisely those design cannot control.\nPart V: The Honest Assessment What Design Can Accomplish Better design can reduce coordination failures by reducing coordination requirements. It can align behavior with objectives by aligning incentives structurally. It can enable implementation by matching requirements to capacity. It can reduce fragility by reducing relationship dependency. It can generate political support by aligning with political incentives. It can produce genuine engagement by transferring genuine authority.\nThese improvements matter. They create conditions where success becomes more likely because the system is designed for success rather than designed to be monitored toward success. They do not require measurement to achieve. They work by changing conditions rather than documenting conditions.\nWhat Design Cannot Accomplish Design cannot create leadership attention where leadership does not care. It cannot build trust where history has destroyed it. It cannot generate political commitment where political will is absent. It cannot produce capacity where resources are unavailable. It cannot transfer authority where power holders refuse to relinquish control.\nThe factors mattering most for implementation are precisely those design cannot control. This is the honest conclusion of Series 5 carried forward. Better design improves the context within which leadership, relationships, and political commitment operate. It cannot substitute for their absence.\nStates with strong leadership, functional relationships, substantial capacity, and political commitment will succeed with almost any reasonable design. States lacking these factors will struggle regardless of design optimization. Design matters at the margins: for states in the middle, where design quality could shift implementation toward success or failure.\nThe Gap Between Documentation and Delivery Rosa brings groceries from her own kitchen because the system is not designed for Maria to receive food. The navigation infrastructure documents food insecurity. The referral system transmits the documentation. The case management platform tracks the referral. The performance measurement system reports completion rates.\nNone of this delivers food.\nBetter metrics on food insecurity referrals will not change this. Better measurement of navigation effectiveness will not change this. More sophisticated evaluation of referral completion will not change this.\nDifferent design might. Systems where food reaches Maria because the system is built to deliver food, not systems where Maria’s food insecurity is documented and referred to services that do not exist. Systems designed around the outcome (Maria eats) rather than the process (Maria’s need is documented).\nThe gap between documentation and delivery is a design problem. Measurement orientation widens the gap by investing in documentation rather than delivery. Design orientation closes the gap by building systems that deliver rather than systems that document.\nSeries 5 examined state agencies as implementers. This companion has offered lenses for seeing implementation challenges as design problems rather than measurement problems. The lenses do not solve all problems. Some constraints will not yield to design. Some gaps will not close regardless of how cleverly systems are structured.\nBut seeing differently is the first step toward building differently. States that see coordination requirements as design failures may consolidate authority rather than investing in coordination mechanisms. States that see capacity gaps as program design failures may simplify requirements rather than waiting for capacity that will not arrive. States that see political constraints as incentive misalignments may redesign for political economy rather than fighting political resistance.\nWhether they will see differently depends on factors this document cannot control. The lenses are offered. Whether anyone looks through them remains to be seen.\nCross-References 5 Synthesis (Which State Agency Structures Support Transformation?): Analytical foundation establishing that structures matter less than leadership, relationships, capacity, and political commitment\n5A (Lead Agency Structures): Authority gap analysis informing the Authority Clarity lens\n5B (Stakeholder Coordination): Coordination theater analysis informing the Community Agency lens\n5C (Procurement and Contracting): Process compliance analysis informing multiple lenses\n5D (Performance Measurement): Measurement critique underlying Part I argument\n5E (Federal-State Relationship): Relationship dependency analysis informing the Relationship Substrate lens\n4 Synthesis (What We Know and What We Don’t): Evidence limitations context\n4 Companion A (Better Optimization): Parallel practical improvements within existing paradigm\n4 Companion B (Beyond Optimization): Paradigm shifts transcending optimization entirely\nSources Bardach, Eugene. A Practical Guide for Policy Analysis: The Eightfold Path to More Effective Problem Solving. CQ Press, 4th ed., 2012.\nBovens, Mark, et al. The Oxford Handbook of Public Accountability. Oxford University Press, 2014.\nDorst, Kees. “The Core of ‘Design Thinking’ and Its Application.” Design Studies, vol. 32, no. 6, 2011, pp. 521-532.\nHood, Christopher. “A Public Management for All Seasons?” Public Administration, vol. 69, no. 1, 1991, pp. 3-19.\nKettl, Donald F. The Transformation of Governance: Public Administration for the Twenty-First Century. Johns Hopkins University Press, 2002.\nMoynihan, Donald P. The Dynamics of Performance Management: Constructing Information and Reform. Georgetown University Press, 2008.\nOstrom, Elinor. Governing the Commons: The Evolution of Institutions for Collective Action. Cambridge University Press, 1990.\nPressman, Jeffrey L., and Aaron Wildavsky. Implementation: How Great Expectations in Washington Are Dashed in Oakland. University of California Press, 3rd ed., 1984.\nScott, James C. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. Yale University Press, 1998.\nSimon, Herbert A. The Sciences of the Artificial. MIT Press, 3rd ed., 1996.\nWeick, Karl E. “Educational Organizations as Loosely Coupled Systems.” Administrative Science Quarterly, vol. 21, no. 1, 1976, pp. 1-19.\nSeries 5: State Agencies Rural Health Transformation Project Version 1: January 2026\n",
  "wordCount" : "5467",
  "inLanguage": "en",
  "image":"http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover.webp","datePublished": "2026-05-12T00:00:00Z",
  "dateModified": "2026-05-12T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Syam Adusumilli"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Syam Adusumilli",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Syam Adusumilli (Alt + H)">Syam Adusumilli</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/rural-health/" title="Rural Health">
                    <span>Rural Health</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/work-requirements/" title="Work Requirements">
                    <span>Work Requirements</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/rural-health/">Rural Health Transformation Project</a>&nbsp;»&nbsp;<a href="http://localhost:1313/rural-health/series-5/">Series 5: State Agency Structures</a></div>
    <h1 class="post-title entry-hint-parent">
      Seeing Differently: Design Approaches to State Agency Implementation
    </h1>
    <div class="post-description">
      RHTP Series 5: Seeing Differently: Design Approaches to State Agency Implementation
    </div>
    <div class="post-meta"><span title='2026-05-12 00:00:00 +0000 UTC'>May 12, 2026</span>&nbsp;·&nbsp;<span>26 min</span>&nbsp;·&nbsp;<span>5467 words</span>&nbsp;·&nbsp;<span>Syam Adusumilli</span>

</div>
  </header> 
<figure class="entry-cover">
            <img loading="eager"
                srcset='http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover_hu_328ac611ab832783.webp 360w,http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover_hu_e9621f502ef3aa17.webp 480w,http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover_hu_8cd42e2e89b5c8.webp 720w,http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover.webp 1024w'
                src="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/cover.webp"
                sizes="(min-width: 768px) 720px, 100vw"
                width="1024" height="1024"
                alt="Seeing Differently: Design Approaches to State Agency Implementation">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#part-i-the-measurement-trap" aria-label="Part I: The Measurement Trap">Part I: The Measurement Trap</a><ul>
                        
                <li>
                    <a href="#how-measurement-crowds-out-alignment" aria-label="How Measurement Crowds Out Alignment">How Measurement Crowds Out Alignment</a></li>
                <li>
                    <a href="#what-measurement-cannot-capture" aria-label="What Measurement Cannot Capture">What Measurement Cannot Capture</a></li>
                <li>
                    <a href="#the-design-alternative" aria-label="The Design Alternative">The Design Alternative</a></li></ul>
                </li>
                <li>
                    <a href="#part-ii-alternative-lenses" aria-label="Part II: Alternative Lenses">Part II: Alternative Lenses</a><ul>
                        
                <li>
                    <a href="#lens-1-the-authority-clarity-lens" aria-label="Lens 1: The Authority Clarity Lens">Lens 1: The Authority Clarity Lens</a></li>
                <li>
                    <a href="#lens-2-the-incentive-alignment-lens" aria-label="Lens 2: The Incentive Alignment Lens">Lens 2: The Incentive Alignment Lens</a></li>
                <li>
                    <a href="#lens-3-the-capacity-reality-lens" aria-label="Lens 3: The Capacity Reality Lens">Lens 3: The Capacity Reality Lens</a></li>
                <li>
                    <a href="#lens-4-the-relationship-substrate-lens" aria-label="Lens 4: The Relationship Substrate Lens">Lens 4: The Relationship Substrate Lens</a></li>
                <li>
                    <a href="#lens-5-the-political-economy-lens" aria-label="Lens 5: The Political Economy Lens">Lens 5: The Political Economy Lens</a></li>
                <li>
                    <a href="#lens-6-the-community-agency-lens" aria-label="Lens 6: The Community Agency Lens">Lens 6: The Community Agency Lens</a></li></ul>
                </li>
                <li>
                    <a href="#part-iii-design-principles" aria-label="Part III: Design Principles">Part III: Design Principles</a><ul>
                        
                <li>
                    <a href="#principle-1-reduce-coordination-requirements" aria-label="Principle 1: Reduce Coordination Requirements">Principle 1: Reduce Coordination Requirements</a></li>
                <li>
                    <a href="#principle-2-align-incentives-structurally" aria-label="Principle 2: Align Incentives Structurally">Principle 2: Align Incentives Structurally</a></li>
                <li>
                    <a href="#principle-3-design-to-capacity" aria-label="Principle 3: Design to Capacity">Principle 3: Design to Capacity</a></li>
                <li>
                    <a href="#principle-4-reduce-relationship-dependency" aria-label="Principle 4: Reduce Relationship Dependency">Principle 4: Reduce Relationship Dependency</a></li>
                <li>
                    <a href="#principle-5-work-with-political-incentives" aria-label="Principle 5: Work With Political Incentives">Principle 5: Work With Political Incentives</a></li>
                <li>
                    <a href="#principle-6-transfer-authority-not-process" aria-label="Principle 6: Transfer Authority, Not Process">Principle 6: Transfer Authority, Not Process</a></li></ul>
                </li>
                <li>
                    <a href="#part-iv-what-cannot-be-redesigned" aria-label="Part IV: What Cannot Be Redesigned">Part IV: What Cannot Be Redesigned</a></li>
                <li>
                    <a href="#part-v-the-honest-assessment" aria-label="Part V: The Honest Assessment">Part V: The Honest Assessment</a><ul>
                        
                <li>
                    <a href="#what-design-can-accomplish" aria-label="What Design Can Accomplish">What Design Can Accomplish</a></li>
                <li>
                    <a href="#what-design-cannot-accomplish" aria-label="What Design Cannot Accomplish">What Design Cannot Accomplish</a></li>
                <li>
                    <a href="#the-gap-between-documentation-and-delivery" aria-label="The Gap Between Documentation and Delivery">The Gap Between Documentation and Delivery</a></li></ul>
                </li>
                <li>
                    <a href="#cross-references" aria-label="Cross-References">Cross-References</a></li>
                <li>
                    <a href="#sources" aria-label="Sources">Sources</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="article-with-sidebar">



<nav class="series-sidebar" id="series-sidebar">
  <button class="sidebar-toggle" onclick="document.getElementById('series-sidebar').classList.toggle('collapsed')">
    <span class="toggle-icon">◀</span>
  </button>
  <div class="sidebar-inner">
    <div class="sidebar-project-label">Rural Health Transformation Project</div>
    <h3><a href="http://localhost:1313/rural-health/series-5/">Series 5: State Agency Structures</a></h3>
    <ul>
      
      <li class="current">
        <a href="http://localhost:1313/rural-health/series-5/seeing-differently-design-approaches-to-state-agency-implementation/">Seeing Differently: Design Approaches to State Agency Implementation</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/state-agency-decision-authority-matrix/">State Agency Decision Authority Matrix</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/which-state-agency-structures-support-transformation/">Which State Agency Structures Support Transformation?</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/federal-state-relationship-cooperative-federalism-and-its-discontents/">Federal-State Relationship: Cooperative Federalism and Its Discontents</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/performance-measurement-accountability-theater/">Performance Measurement: Accountability Theater</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/procurement-and-contracting-the-compliance-trap/">Procurement and Contracting: The Compliance Trap</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/stakeholder-coordination-the-limits-of-convening/">Stakeholder Coordination: The Limits of Convening</a>
      </li>
      
      <li>
        <a href="http://localhost:1313/rural-health/series-5/lead-agency-structures-and-the-accountability-illusion/">Lead Agency Structures and the Accountability Illusion</a>
      </li>
      
    </ul>
    
    <h3 class="other-series-heading"><a href="http://localhost:1313/rural-health/">All Series</a></h3>
    <ul class="other-series">
      
      
      <li><a href="http://localhost:1313/rural-health/series-1/">Series 1: Understanding Rural and Deep Rural America</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-10/">Series 10: Regional Profiles</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-11/">Series 11: Clinical Reality</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-12/">Series 12: Coverage and Financing</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-13/">Series 13: Trust and Navigation</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-14/">Series 14: Infrastructure Models</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-15/">Series 15: Regulatory and Workforce</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-16/">Series 16: Integration and Scenarios</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-2/">Series 2: The Federal Architecture of Rural Health</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-3/">Series 3: State-by-State Analysis</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-4/">Series 4: Evidence-Based Strategies</a></li>
      
      
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-6/">Series 6: Intermediary Organizations</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-7/">Series 7: Rural Provider Landscape</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-8/">Series 8: Community Infrastructure</a></li>
      
      
      
      <li><a href="http://localhost:1313/rural-health/series-9/">Series 9: Special Populations</a></li>
      
      
    </ul>
    
  </div>
</nav>
<div class="post-content">
<div style="margin: 0.75rem 0 1.5rem; padding: 0.5rem 0.75rem;
     background: var(--code-bg); border-radius: 4px; font-size: 0.85rem;">
  <a href="../seeing-differently-design-approaches-to-state-agency-implementation-summary/" style="text-decoration: none; color: var(--primary);">
    Read the Executive Summary
  </a>
</div>

<p>The organizational chart shows the Department of Health as lead agency. The consultant recommends better coordination mechanisms. The federal monitor suggests relationship-building investments. The evaluator proposes improved metrics for inter-agency collaboration.</p>
<p>Everyone is solving the wrong problem.</p>
<p>The coordination challenge exists because someone designed a system requiring coordination. The relationship dependency exists because someone designed a system that fails without strong relationships. The measurement gap exists because someone designed requirements exceeding state capacity to document.</p>
<p><strong>These are design failures, not implementation failures.</strong> Solving them requires different design, not better measurement of dysfunctional design.</p>
<p>The Series 5 Synthesis concluded that leadership, relationships, capacity, and political commitment matter more than structures for implementation success. The natural policy response is to measure these things: develop relationship quality indicators, track leadership attention metrics, assess political commitment scores, document capacity development progress.</p>
<p>This response extends the compliance orientation that Series 5 critiques. It treats measurement as the solution to problems that measurement created. It assumes that tracking alignment produces alignment, that documenting relationships builds relationships, that assessing commitment generates commitment.</p>
<p>It does not. <strong>Measurement changes what it measures.</strong> Relationships that become measured become performed. Leadership attention that becomes tracked becomes theatrical. The authentic phenomena that predict implementation success cannot survive their transformation into metrics.</p>
<p>This companion document takes a different approach. Rather than asking how to improve state agency implementation through better measurement, it asks <strong>how to see state agency implementation differently</strong>. The goal is not better metrics but better design: creating conditions where alignment emerges naturally rather than conditions where alignment must be monitored into existence.</p>
<h2 id="part-i-the-measurement-trap">Part I: The Measurement Trap<a hidden class="anchor" aria-hidden="true" href="#part-i-the-measurement-trap">#</a></h2>
<h3 id="how-measurement-crowds-out-alignment">How Measurement Crowds Out Alignment<a hidden class="anchor" aria-hidden="true" href="#how-measurement-crowds-out-alignment">#</a></h3>
<p>Series 5 documented performance measurement as accountability theater. States produce reports satisfying requirements without informing decisions. Measurement consumes capacity that could serve communities. Gaming indicators replaces achieving outcomes. The measurement system performs accountability rather than creating it.</p>
<p>The standard response is better measurement. More meaningful indicators. Outcome metrics rather than process metrics. Learning systems rather than compliance systems.</p>
<p>This response assumes measurement solves measurement problems. It does not.</p>
<p><strong>Measurement changes what it measures.</strong> The act of measuring transforms the phenomenon measured. Relationships subjected to assessment become relationships performed for assessors. When CMS evaluates federal-state relationship quality, states optimize for relationship appearance. The authentic collaboration that produces implementation success differs fundamentally from collaboration performed for evaluators. Both may look similar in documentation. They produce different results.</p>
<p><strong>Measurement consumes attention.</strong> Every hour documenting coordination is an hour not coordinating. Every meeting about measurement systems is a meeting not about implementation. Every staff position dedicated to reporting is a position not dedicated to service. The overhead of accountability crowds out the substance accountability supposedly ensures.</p>
<p><strong>Measurement creates adversarial dynamics.</strong> Evaluation inherently judges. Judgment creates defensiveness. Defensiveness undermines trust. Trust enables the authentic relationships that implementation requires. <strong>The measurement relationship is structurally adversarial</strong> even when evaluators intend partnership. States being assessed cannot fully trust assessors. The dynamic is inherent to the relationship, not a function of evaluator intentions.</p>
<p><strong>Measurement assumes the measurer knows what matters.</strong> Federal indicators reflect federal priorities. State indicators reflect state priorities. Community indicators reflect community priorities. These may align or diverge. The act of selecting indicators embeds assumptions about value that the indicator system cannot question. When federal indicators dominate (as they do in RHTP), federal assumptions about value dominate regardless of whether those assumptions fit local reality.</p>
<h3 id="what-measurement-cannot-capture">What Measurement Cannot Capture<a hidden class="anchor" aria-hidden="true" href="#what-measurement-cannot-capture">#</a></h3>
<p>The factors predicting implementation success, according to Series 5, are precisely those measurement degrades.</p>
<p><strong>Leadership focus</strong> that emerges from genuine priority differs from leadership focus responding to measurement incentives. A governor who cares about rural health because rural communities matter to them behaves differently from a governor performing care because leadership attention metrics require it. The external behavior may look similar. The underlying commitment differs. When pressure mounts and tradeoffs sharpen, genuine commitment persists while performed commitment evaporates. Measurement cannot distinguish them until the moment of pressure reveals the difference.</p>
<p><strong>Relationship quality</strong> emerging from trust differs from relationship quality performed for assessment. When states know CMS evaluates their federal relationship, they optimize for appearance. Calls get made that would not otherwise occur. Documentation gets produced that overstates collaboration. The measurement system generates evidence of relationships rather than relationships themselves. Authentic collaboration becomes impossible when collaboration is being judged because judgment introduces the adversarial dynamic that collaboration requires transcending.</p>
<p><strong>Political commitment</strong> accepting genuine cost differs from political commitment accepting measurable cost. Politicians willing to make difficult decisions do so because they believe the outcome justifies the cost. Belief cannot be measured without changing it. Political commitment metrics would generate commitment performance: the appearance of willingness to bear cost without the substance. When the cost actually arrives, performed commitment fails.</p>
<p><strong>Capacity</strong> enabling implementation differs from capacity satisfying assessment. States can document evaluation infrastructure without having functional evaluation. They can demonstrate procurement processes without executing timely procurement. They can show coordination mechanisms without coordinating. <strong>The documentation and the capacity are different things.</strong> Measurement systems that accept documentation as evidence of capacity systematically overestimate capacity because documentation is easier than function.</p>
<h3 id="the-design-alternative">The Design Alternative<a hidden class="anchor" aria-hidden="true" href="#the-design-alternative">#</a></h3>
<p>Rather than measuring alignment, <strong>design systems where alignment emerges naturally</strong>.</p>
<p>This requires different questions. Not &ldquo;how do we measure leadership attention?&rdquo; but &ldquo;what conditions create genuine leadership attention without measurement?&rdquo; Not &ldquo;how do we assess relationship quality?&rdquo; but &ldquo;what structures make collaboration rational rather than performed?&rdquo; Not &ldquo;how do we track capacity development?&rdquo; but &ldquo;what program designs match available capacity rather than requiring capacity that does not exist?&rdquo;</p>
<p>The alternative is design thinking applied to implementation challenges. Design thinking asks what conditions produce desired outcomes, then creates those conditions. It does not ask how to measure whether desired outcomes occurred, then pressure systems toward measured performance.</p>
<p><strong>Design creates conditions. Measurement documents conditions.</strong> When conditions are wrong, measurement documents failure without changing it. When conditions are right, measurement is unnecessary because success emerges from the conditions themselves.</p>
<p>The rest of this document applies design thinking to the implementation challenges Series 5 identified. Each section offers an alternative lens: a way of seeing challenges that reveals design solutions invisible to measurement orientation.</p>
<h2 id="part-ii-alternative-lenses">Part II: Alternative Lenses<a hidden class="anchor" aria-hidden="true" href="#part-ii-alternative-lenses">#</a></h2>
<h3 id="lens-1-the-authority-clarity-lens">Lens 1: The Authority Clarity Lens<a hidden class="anchor" aria-hidden="true" href="#lens-1-the-authority-clarity-lens">#</a></h3>
<p><strong>The standard view:</strong> Authority fragmentation creates coordination challenges. Multiple agencies hold pieces of implementation authority. No single entity controls enough to act decisively. The solution is better coordination: mechanisms, processes, relationships that bridge authority gaps. Measure coordination effectiveness to ensure coordination occurs.</p>
<p><strong>The alternative view:</strong> Authority fragmentation creates coordination requirements. The coordination challenge exists because the system was designed to require coordination. The solution is reducing fragmentation so coordination becomes unnecessary. <strong>The best coordination is no coordination because the system does not require it.</strong></p>
<p>Every coordination mechanism is a design failure made visible. Someone designed a system where Agency A controls budgets, Agency B controls programs, and Agency C controls Medicaid. This design created the coordination requirement. The coordination mechanisms addressing this requirement are patches on flawed design, not solutions.</p>
<p><strong>Consolidation over coordination.</strong> Where authority can be consolidated, consolidate it. Michigan&rsquo;s DHHS holds authority that Georgia distributes across DCH and DPH. Michigan requires less coordination because Michigan&rsquo;s design consolidated what Georgia&rsquo;s design fragmented. For Georgia, the solution is not better DCH-DPH coordination but authority consolidation that makes coordination unnecessary. Whether Georgia can achieve consolidation depends on political factors. The design insight remains: coordination requirements are design failures that consolidation eliminates.</p>
<p><strong>Separation over integration.</strong> Where consolidation is politically impossible, clean separation may outperform messy integration. Distinct domains with clear boundaries require less coordination than overlapping domains with shared authority. If Agency A handles all workforce functions and Agency B handles all facility functions with no overlap, coordination requirements shrink to the interface between domains. The design question becomes: where should domain boundaries fall to minimize coordination requirements?</p>
<p><strong>Automation over negotiation.</strong> Where decisions repeat, automate them. Every decision reduced to algorithm is a decision removed from coordination dependency. Procurement thresholds allowing direct purchase avoid procurement negotiation. Pre-approved modification authorities avoid modification negotiation. Automatic flexibility triggers avoid flexibility negotiation. The goal is not faster negotiation but eliminated negotiation because the system handles decisions automatically.</p>
<p><strong>Practical application:</strong> Before investing in coordination mechanisms, ask why this decision requires coordination. Often the answer reveals design choices creating the coordination requirement. The design insight is not &ldquo;coordinate better&rdquo; but &ldquo;redesign so coordination becomes unnecessary.&rdquo;</p>
<p>Georgia could invest in DCH-DPH coordination infrastructure. Or Georgia could consolidate authority so coordination infrastructure becomes unnecessary. The second approach solves the problem; the first manages it. Managing problems is necessary when solving them is impossible. But solving should be attempted before managing is accepted.</p>
<h3 id="lens-2-the-incentive-alignment-lens">Lens 2: The Incentive Alignment Lens<a hidden class="anchor" aria-hidden="true" href="#lens-2-the-incentive-alignment-lens">#</a></h3>
<p><strong>The standard view:</strong> State and federal interests diverge. States pursue state priorities; CMS pursues federal priorities. When these conflict, states underperform on federal objectives. The solution is federal oversight ensuring states pursue federal objectives despite state preferences. Measure compliance to ensure states do what CMS requires.</p>
<p><strong>The alternative view:</strong> State and federal interests diverge because program design creates divergence. The incentive misalignment is not natural but designed. The solution is redesigning programs so state and federal interests naturally align. <strong>When incentives align, compliance is unnecessary because states pursue federal objectives for state reasons.</strong></p>
<p>When states optimize for metrics rather than outcomes, the problem is not state behavior but program design. The program created metrics misaligned with outcomes. Better metrics do not solve this; they relocate the misalignment. The solution is program design where pursuing state interests automatically pursues federal interests.</p>
<p><strong>Outcome funding over process funding.</strong> RHTP funds flow for performed processes: activities documented, reports submitted, milestones claimed. This creates incentive to perform processes regardless of outcomes. Alternative design where funds flow for achieved outcomes (rural health improvement measured, access expansion demonstrated, mortality reduction documented) would align state incentives with federal objectives without compliance measurement. States would pursue outcomes because funding depends on outcomes, not because compliance systems pressure outcome pursuit.</p>
<p><strong>Risk sharing over risk transfer.</strong> Current design transfers implementation risk to states. States must perform or face consequences. CMS bears no risk from program design failures. This misaligns incentives: CMS designs programs without bearing design failure costs; states implement programs bearing all failure costs including design-caused failure. Alternative design sharing risk (federal funds contingent on federal support effectiveness, CMS accountability for design adequacy) would align federal and state incentives around program success rather than program compliance.</p>
<p><strong>Flexibility as default over flexibility as exception.</strong> Current design requires states to justify deviation from federal standards. The default is federal uniformity; flexibility requires permission. This creates incentive to follow federal templates even when templates fit poorly. Alternative design where flexibility is default (federal justification required for imposing uniformity rather than state justification required for deviation) would align incentives toward state-appropriate implementation.</p>
<p><strong>Political credit alignment.</strong> Governors seek credit for success. Current design allows CMS to claim credit for investment (&ldquo;we provided $50 billion&rdquo;) while states bear accountability for outcomes (&ldquo;the state failed to implement effectively&rdquo;). This misaligns political incentives: governors gain little from RHTP success because credit flows federally while bearing substantial risk from RHTP failure because blame flows to states. Alternative design enabling gubernatorial credit-claiming for rural health improvement would align political incentives with implementation success.</p>
<p><strong>Practical application:</strong> Before creating compliance mechanisms, ask why state incentives diverge from federal objectives. Often the answer reveals program design choices creating the divergence. The design insight is not &ldquo;enforce compliance&rdquo; but &ldquo;redesign so compliance becomes unnecessary because state interests align with federal objectives.&rdquo;</p>
<p>The 2030 sustainability cliff illustrates incentive misalignment. States must build sustainable systems knowing funding ends. Governors investing in systems that collapse after they leave office gain little political benefit. Federal design created this sustainability disincentive; federal redesign could solve it. Automatic RHTP extension contingent on outcome achievement would align gubernatorial incentives with sustainability investment without sustainability metrics.</p>
<h3 id="lens-3-the-capacity-reality-lens">Lens 3: The Capacity Reality Lens<a hidden class="anchor" aria-hidden="true" href="#lens-3-the-capacity-reality-lens">#</a></h3>
<p><strong>The standard view:</strong> States lack capacity to implement sophisticated programs. Rural health offices are understaffed. Evaluation expertise is scarce. Procurement systems are slow. The solution is capacity building: technical assistance, training, staff development, system investment. Measure capacity development to ensure capacity grows.</p>
<p><strong>The alternative view:</strong> Programs exceed state capacity because programs are designed without capacity constraints. The capacity gap is not a state failure but a program design failure. The solution is designing programs states can actually implement. <strong>Design to capacity rather than designing beyond capacity and hoping capacity catches up.</strong></p>
<p>Designing programs exceeding implementer capacity guarantees implementation failure. This is obvious in principle but ignored in practice. RHTP requirements assume evaluation capacity, procurement speed, and coordination sophistication that many states demonstrably lack. The design guarantees some states will fail because the design requires capacity those states do not have.</p>
<p><strong>Design to capacity, not to ambition.</strong> Current RHTP design reflects federal ambition: sophisticated measurement, comprehensive coordination, rapid deployment. Designing instead to actual state capacity (simpler measurement, reduced coordination requirements, realistic timelines) would improve implementation without capacity building. Capacity building takes years. Design simplification takes decisions. States lacking evaluation infrastructure cannot build it fast enough for RHTP&rsquo;s timeline. But RHTP could be redesigned to require evaluation infrastructure states actually have.</p>
<p><strong>Tiered programs over uniform programs.</strong> One program design cannot fit fifty states with different capacities. Massachusetts has evaluation infrastructure Kansas lacks. California has procurement systems Wyoming cannot match. Uniform requirements guarantee that high-capacity states are under-challenged while low-capacity states are overwhelmed. Tiered design (sophisticated version for states that can implement it, simplified version for states that cannot) matches implementation requirements to implementation ability.</p>
<p><strong>Capacity as constraint, not variable.</strong> Planning that treats capacity as constraint asks: what can we accomplish with available capacity? Planning that treats capacity as variable asks: how do we build capacity to accomplish our ambition? The first approach implements. The second approach plans to implement while waiting for capacity that may never arrive. RHTP&rsquo;s five-year timeline does not provide time for substantial capacity building. Treating capacity as constraint produces realistic plans; treating capacity as variable produces aspirational plans that fail.</p>
<p><strong>Outsourcing over building.</strong> States lacking capacity can access capacity rather than build it. Universities have evaluation expertise. Consultants have procurement experience. Other states have implementation knowledge. Program design facilitating capacity access (encouraging partnerships, enabling contracts, connecting peer states) enables implementation without waiting for capacity development.</p>
<p><strong>Practical application:</strong> Before investing in capacity building, ask why this program requires capacity the state lacks. Often the answer reveals design choices creating the capacity requirement. The design insight is not &ldquo;build capacity faster&rdquo; but &ldquo;redesign so available capacity suffices.&rdquo;</p>
<p>The measurement sophistication RHTP requires exceeds many states&rsquo; evaluation capacity. Capacity building would take years. Measurement simplification would take decisions. Fewer, simpler metrics that low-capacity states can actually produce would generate better data than complex requirements producing compliance fiction from states that cannot implement them.</p>
<h3 id="lens-4-the-relationship-substrate-lens">Lens 4: The Relationship Substrate Lens<a hidden class="anchor" aria-hidden="true" href="#lens-4-the-relationship-substrate-lens">#</a></h3>
<p><strong>The standard view:</strong> Relationships matter for implementation. The Montana vignette shows how strong federal-state relationships enable rapid problem-solving. The Georgia vignette shows how weak relationships produce delays harming communities. The solution is relationship investment: building trust, cultivating partnerships, developing personal connections. Assess relationship quality to ensure relationships are adequate.</p>
<p><strong>The alternative view:</strong> Relationships matter because program design creates relationship dependency. Implementation depending on relationships depends on factors no design can control. The solution is designing programs that succeed regardless of relationship quality. <strong>Robust design works with bad relationships while performing better with good ones.</strong></p>
<p>Relationships emerge from personal chemistry, accumulated history, institutional culture, and circumstances that programs cannot mandate. Some project officers and state directors will develop trust. Others will not. Some states enter RHTP with collaborative federal histories. Others enter with adversarial legacies. Program design cannot change these starting points. Program design can determine whether these starting points determine implementation success.</p>
<p><strong>Robustness over optimization.</strong> Designs requiring good relationships to succeed are fragile. When relationships are strong, they succeed; when relationships are weak, they fail. Robust designs succeed adequately with weak relationships while performing better with strong ones. The design question is not &ldquo;how do we ensure good relationships&rdquo; but &ldquo;how do we succeed regardless of relationship quality.&rdquo;</p>
<p><strong>Structural alignment over relational alignment.</strong> When structures align interests, relationships matter less. When structures misalign interests, even good relationships face strain. Two agencies with conflicting mandates will struggle to collaborate regardless of personal relationships between directors. Two agencies with aligned mandates will collaborate more easily even without strong personal relationships. Structural alignment creates conditions where relationships can flourish; it also reduces dependence on relationships flourishing.</p>
<p><strong>Redundancy over dependency.</strong> Single points of relationship failure create fragility. If implementation depends on one project officer relationship, project officer turnover threatens implementation. If implementation depends on one key partnership, partnership deterioration threatens implementation. Redundant relationships (multiple federal contacts, multiple state partnerships, multiple communication channels) survive individual relationship failures.</p>
<p><strong>Formalization as relationship insurance.</strong> Informal relationships work until they do not. The handshake agreement holds until the parties shake hands with different people. The understanding persists until someone misunderstands. Formalization (MOUs, contracts, documented agreements, written protocols) provides insurance against relationship failure. When relationships work, formalization is unnecessary overhead. When relationships fail, formalization enables continuation despite failure. <strong>The goal is not replacing relationships with formalization but ensuring formalization exists when relationships fail.</strong></p>
<p><strong>Practical application:</strong> Before investing in relationship building, ask why implementation depends on this relationship. Often the answer reveals design choices creating the dependency. The design insight is not &ldquo;build stronger relationships&rdquo; but &ldquo;redesign so implementation succeeds regardless of relationship strength.&rdquo;</p>
<p>Montana&rsquo;s rapid response to hospital closure reflected strong relationships. But implementation design could have enabled adequate response regardless of relationship quality. Automatic flexibility for defined circumstances (provider closure meets predefined criteria, modification authority triggers automatically) would remove relationship dependency from flexibility access. States with weak CMS relationships would access the same flexibility as states with strong relationships because flexibility would be structural rather than relational.</p>
<h3 id="lens-5-the-political-economy-lens">Lens 5: The Political Economy Lens<a hidden class="anchor" aria-hidden="true" href="#lens-5-the-political-economy-lens">#</a></h3>
<p><strong>The standard view:</strong> Political factors constrain implementation. Governors face electoral pressures. Legislatures control budgets. Provider interests exercise influence. These dynamics limit what agencies can accomplish. The solution is building political support: cultivating champions, creating coalitions, demonstrating benefits. Assess political commitment to ensure adequate political backing.</p>
<p><strong>The alternative view:</strong> Political constraints exist because program design ignores political economy. Programs requiring political actors to behave against their incentives will fail. The solution is designing programs aligning with political incentives rather than fighting them. <strong>Work with political reality rather than wishing it were different.</strong></p>
<p>Governors will pursue electoral advantage. Legislators will respond to influential interests. Providers will protect their economic position. These behaviors are not failures of political will but predictable responses to political incentives. Program design ignoring these incentives designs for a political world that does not exist.</p>
<p><strong>Credit distribution matters.</strong> Politicians support programs generating political credit. RHTP design that enables gubernatorial credit-claiming generates gubernatorial support without requiring governors to transcend political self-interest. Design reserving credit for federal officials or diffusing credit across many actors generates less state political investment. The question is not whether governors should be more public-spirited but how program design can align credit flows with implementation needs.</p>
<p><strong>Blame avoidance matters more.</strong> Politicians fear programs creating blame risk more than they value programs creating credit opportunity. RHTP design concentrating blame on states (state implementation failed) while diffusing credit (federal investment succeeded, outcomes varied by state) creates political incentive to minimize engagement, not maximize it. Design protecting state officials from blame for design failures (federal accountability for program adequacy, shared responsibility for outcome shortfalls) would enable implementation investment by reducing political risk.</p>
<p><strong>Interest group alignment matters.</strong> Provider interests dominate health policy in most state capitals. Hospital associations, physician organizations, and health system lobbies exercise substantial political influence. RHTP design threatening provider interests generates provider opposition creating political cost that governors must bear or avoid. Design aligning transformation with provider interests (or at least neutralizing opposition through grandfather provisions, transition support, or alternative value propositions) reduces political constraint on implementation.</p>
<p><strong>Electoral cycle alignment matters.</strong> Governors facing reelection invest in visible, quick wins. Programs producing visible results within electoral cycles attract gubernatorial attention. Programs requiring long-term investment before visible results attract gubernatorial neglect. RHTP&rsquo;s five-year timeline spans multiple electoral cycles. Design producing early visible wins (Year 1-2 achievements governors can claim) would align electoral incentives with implementation investment. Design where visible results arrive only in Year 4-5 (after many governors have moved on) misaligns electoral timing with program timeline.</p>
<p><strong>Practical application:</strong> Before building political coalitions, ask why this program faces political opposition or neglect. Often the answer reveals design choices creating the political problem. The design insight is not &ldquo;overcome political resistance&rdquo; but &ldquo;redesign so political incentives support implementation.&rdquo;</p>
<p>The sustainability challenge illustrates political economy failure. RHTP requires states to build systems potentially not surviving beyond 2030. Governors investing in programs that collapse after they leave office gain little political benefit and bear substantial political risk (they built something that failed). Design extending RHTP contingent on outcome achievement would align gubernatorial incentives with sustainability investment by ensuring political benefit from long-term system building.</p>
<h3 id="lens-6-the-community-agency-lens">Lens 6: The Community Agency Lens<a hidden class="anchor" aria-hidden="true" href="#lens-6-the-community-agency-lens">#</a></h3>
<p><strong>The standard view:</strong> Community engagement improves implementation. Stakeholder input helps programs fit local needs. Advisory committees surface local knowledge. Public participation builds program legitimacy. The solution is robust engagement processes: stakeholder meetings, public comment, advisory structures. Assess participation to ensure communities are engaged.</p>
<p><strong>The alternative view:</strong> Community engagement fails because communities lack agency, not voice. Participation without power is theater. The solution is designing programs where communities hold actual authority, not programs where communities provide input that may or may not influence decisions others make. <strong>Transfer authority, not process.</strong></p>
<p>Advisory committees that provide input ignored teach community members their time is wasted. Stakeholder processes that solicit perspectives without changing decisions produce cynicism undermining future engagement. Public participation that performs inclusion without practicing it generates the appearance of community voice without its substance.</p>
<p><strong>Authority over input.</strong> Communities deciding implementation details engage differently than communities advising on implementation details. The difference is not participation level but authority distribution. Community members asked &ldquo;what do you think we should do?&rdquo; engage differently than community members asked &ldquo;what have you decided to do?&rdquo; The first is consultation; the second is governance. Design transferring actual authority produces different engagement than design soliciting input on decisions made elsewhere.</p>
<p><strong>Resources over process.</strong> Community organizations with resources can act. Community organizations without resources can only advise. Transferring decision authority without transferring resources produces authority without capacity: communities that can decide but cannot implement their decisions. Design directing resources to community control enables community agency that advisory processes cannot create.</p>
<p><strong>Accountability reversal.</strong> Current design holds states accountable to CMS for community engagement. States must document stakeholder processes, show participation evidence, demonstrate input solicitation. This accountability direction makes communities objects of engagement rather than subjects holding power. Alternative design holding states accountable to communities for implementation quality (community authority to assess state performance, community voice in determining state compliance) would reverse accountability direction and the power dynamics flowing from it.</p>
<p><strong>Exit over voice.</strong> Communities depending on single providers have voice but not exit. They can complain about services but cannot choose alternatives. Voice without exit is weak. Design creating options (multiple providers, alternative delivery models, competitive service availability) enables community agency that voice processes cannot replace. Communities that can leave have power; communities that can only comment do not.</p>
<p><strong>Practical application:</strong> Before designing stakeholder processes, ask what authority communities will actually hold. If the answer is &ldquo;input that may or may not influence decisions,&rdquo; recognize the limitation. The design insight is not &ldquo;improve participation quality&rdquo; but &ldquo;transfer actual authority so participation becomes governance.&rdquo;</p>
<p>RHTP&rsquo;s stakeholder requirements produce advisory committees across fifty states. Almost none transfer actual authority to communities. Community members provide input; state agencies decide. Design requiring community approval for specified decisions (subaward allocations, priority setting, vendor selection) would transfer actual authority rather than creating input processes. Whether such design is politically feasible depends on state context. The design insight remains: participation without authority is theater that design improvements cannot make genuine.</p>
<h2 id="part-iii-design-principles">Part III: Design Principles<a hidden class="anchor" aria-hidden="true" href="#part-iii-design-principles">#</a></h2>
<p>The six lenses converge on principles transcending specific domains.</p>
<h3 id="principle-1-reduce-coordination-requirements">Principle 1: Reduce Coordination Requirements<a hidden class="anchor" aria-hidden="true" href="#principle-1-reduce-coordination-requirements">#</a></h3>
<p>Every coordination requirement is a potential failure point. Systems requiring extensive coordination depend on relationships, goodwill, and alignment that may not exist. Design reducing coordination requirements reduces failure modes.</p>
<p>Before creating coordination mechanisms, redesign to eliminate coordination need. Consolidate authority where possible. Separate domains cleanly where consolidation fails. Automate repeated decisions. <strong>The goal is not better coordination but less need to coordinate.</strong></p>
<h3 id="principle-2-align-incentives-structurally">Principle 2: Align Incentives Structurally<a hidden class="anchor" aria-hidden="true" href="#principle-2-align-incentives-structurally">#</a></h3>
<p>When incentives misalign, behavior diverges from objectives regardless of measurement. Compliance systems attempting to force aligned behavior despite misaligned incentives face endless resistance. Design aligning incentives produces aligned behavior without compliance overhead.</p>
<p>Before creating compliance mechanisms, redesign to align incentives. Connect funding to outcomes. Share risk between federal and state partners. Distribute credit appropriately. Enable political benefit from implementation success. <strong>The goal is not enforced compliance but unnecessary compliance because incentives align.</strong></p>
<h3 id="principle-3-design-to-capacity">Principle 3: Design to Capacity<a hidden class="anchor" aria-hidden="true" href="#principle-3-design-to-capacity">#</a></h3>
<p>Programs exceeding implementer capacity fail. Programs scaled to capacity succeed. Capacity building takes years; design simplification takes decisions.</p>
<p>Before investing in capacity building, redesign to match available capacity. Simplify requirements. Create tiered program designs. Accept that different states will implement different versions. Enable capacity access through partnership rather than capacity creation through development. <strong>The goal is not expanded capacity but reduced capacity requirements.</strong></p>
<h3 id="principle-4-reduce-relationship-dependency">Principle 4: Reduce Relationship Dependency<a hidden class="anchor" aria-hidden="true" href="#principle-4-reduce-relationship-dependency">#</a></h3>
<p>Relationships emerge from factors design cannot control. Relationship-dependent implementation gambles on relationships forming. Robust design succeeds regardless of relationship quality.</p>
<p>Before investing in relationship building, redesign to reduce relationship dependency. Create structural alignment making relationships beneficial but not required. Build redundancy surviving individual relationship failures. Formalize as insurance when relationships fail. <strong>The goal is not stronger relationships but reduced dependence on relationship strength.</strong></p>
<h3 id="principle-5-work-with-political-incentives">Principle 5: Work With Political Incentives<a hidden class="anchor" aria-hidden="true" href="#principle-5-work-with-political-incentives">#</a></h3>
<p>Programs requiring political actors to behave against their incentives will fail. Programs aligned with political incentives succeed without political cultivation.</p>
<p>Before building political support, redesign to align with political incentives. Enable credit-claiming. Protect against blame. Align with provider interests where possible. Produce visible results within electoral cycles. <strong>The goal is not overcoming political resistance but eliminating reasons for resistance.</strong></p>
<h3 id="principle-6-transfer-authority-not-process">Principle 6: Transfer Authority, Not Process<a hidden class="anchor" aria-hidden="true" href="#principle-6-transfer-authority-not-process">#</a></h3>
<p>Community engagement without authority is theater. Communities with actual decision authority engage differently than communities invited to advise.</p>
<p>Before designing participation processes, determine what authority communities will actually hold. Transfer genuine authority where possible. Direct resources alongside authority. Create accountability to communities, not just accountability for engaging communities. <strong>The goal is not better participation but actual power.</strong></p>
<h2 id="part-iv-what-cannot-be-redesigned">Part IV: What Cannot Be Redesigned<a hidden class="anchor" aria-hidden="true" href="#part-iv-what-cannot-be-redesigned">#</a></h2>
<p>Design thinking has limits. Some constraints are fixed.</p>
<p><strong>Constitutional federalism</strong> distributes authority between federal and state governments in ways RHTP cannot change. CMS can condition funding but cannot command state action. States retain implementation discretion that federal design cannot override. Design must work within this distribution.</p>
<p><strong>State political systems</strong> operate according to incentives design can align with but cannot eliminate. Governors will seek electoral advantage. Legislatures will respond to constituent interests. Providers will protect economic position. Design that ignores these realities fails; design that works with them succeeds.</p>
<p><strong>RHTP statutory structure</strong> fixes the five-year timeline, funding allocation, and basic program parameters. Design improvements must occur within existing statutory framework. Fundamental restructuring would require legislative action beyond RHTP&rsquo;s administrative scope.</p>
<p><strong>Prior history</strong> shapes the context within which design operates. States enter RHTP with accumulated capacity, established relationships, and embedded political dynamics. Design cannot erase history. It can create conditions where history matters less.</p>
<p><strong>Leadership and commitment</strong> cannot be designed into existence. Design can create conditions favorable to leadership attention and political commitment. It cannot guarantee that attention materializes or commitment develops. The factors mattering most for implementation are precisely those design cannot control.</p>
<h2 id="part-v-the-honest-assessment">Part V: The Honest Assessment<a hidden class="anchor" aria-hidden="true" href="#part-v-the-honest-assessment">#</a></h2>
<h3 id="what-design-can-accomplish">What Design Can Accomplish<a hidden class="anchor" aria-hidden="true" href="#what-design-can-accomplish">#</a></h3>
<p>Better design can reduce coordination failures by reducing coordination requirements. It can align behavior with objectives by aligning incentives structurally. It can enable implementation by matching requirements to capacity. It can reduce fragility by reducing relationship dependency. It can generate political support by aligning with political incentives. It can produce genuine engagement by transferring genuine authority.</p>
<p>These improvements matter. They create conditions where success becomes more likely because the system is designed for success rather than designed to be monitored toward success. They do not require measurement to achieve. They work by changing conditions rather than documenting conditions.</p>
<h3 id="what-design-cannot-accomplish">What Design Cannot Accomplish<a hidden class="anchor" aria-hidden="true" href="#what-design-cannot-accomplish">#</a></h3>
<p>Design cannot create leadership attention where leadership does not care. It cannot build trust where history has destroyed it. It cannot generate political commitment where political will is absent. It cannot produce capacity where resources are unavailable. It cannot transfer authority where power holders refuse to relinquish control.</p>
<p><strong>The factors mattering most for implementation are precisely those design cannot control.</strong> This is the honest conclusion of Series 5 carried forward. Better design improves the context within which leadership, relationships, and political commitment operate. It cannot substitute for their absence.</p>
<p>States with strong leadership, functional relationships, substantial capacity, and political commitment will succeed with almost any reasonable design. States lacking these factors will struggle regardless of design optimization. Design matters at the margins: for states in the middle, where design quality could shift implementation toward success or failure.</p>
<h3 id="the-gap-between-documentation-and-delivery">The Gap Between Documentation and Delivery<a hidden class="anchor" aria-hidden="true" href="#the-gap-between-documentation-and-delivery">#</a></h3>
<p>Rosa brings groceries from her own kitchen because the system is not designed for Maria to receive food. The navigation infrastructure documents food insecurity. The referral system transmits the documentation. The case management platform tracks the referral. The performance measurement system reports completion rates.</p>
<p>None of this delivers food.</p>
<p>Better metrics on food insecurity referrals will not change this. Better measurement of navigation effectiveness will not change this. More sophisticated evaluation of referral completion will not change this.</p>
<p>Different design might. Systems where food reaches Maria because the system is built to deliver food, not systems where Maria&rsquo;s food insecurity is documented and referred to services that do not exist. Systems designed around the outcome (Maria eats) rather than the process (Maria&rsquo;s need is documented).</p>
<p><strong>The gap between documentation and delivery is a design problem.</strong> Measurement orientation widens the gap by investing in documentation rather than delivery. Design orientation closes the gap by building systems that deliver rather than systems that document.</p>
<p>Series 5 examined state agencies as implementers. This companion has offered lenses for seeing implementation challenges as design problems rather than measurement problems. The lenses do not solve all problems. Some constraints will not yield to design. Some gaps will not close regardless of how cleverly systems are structured.</p>
<p>But seeing differently is the first step toward building differently. States that see coordination requirements as design failures may consolidate authority rather than investing in coordination mechanisms. States that see capacity gaps as program design failures may simplify requirements rather than waiting for capacity that will not arrive. States that see political constraints as incentive misalignments may redesign for political economy rather than fighting political resistance.</p>
<p>Whether they will see differently depends on factors this document cannot control. The lenses are offered. Whether anyone looks through them remains to be seen.</p>
<h2 id="cross-references">Cross-References<a hidden class="anchor" aria-hidden="true" href="#cross-references">#</a></h2>
<p><strong>5 Synthesis (Which State Agency Structures Support Transformation?):</strong> Analytical foundation establishing that structures matter less than leadership, relationships, capacity, and political commitment</p>
<p><strong>5A (Lead Agency Structures):</strong> Authority gap analysis informing the Authority Clarity lens</p>
<p><strong>5B (Stakeholder Coordination):</strong> Coordination theater analysis informing the Community Agency lens</p>
<p><strong>5C (Procurement and Contracting):</strong> Process compliance analysis informing multiple lenses</p>
<p><strong>5D (Performance Measurement):</strong> Measurement critique underlying Part I argument</p>
<p><strong>5E (Federal-State Relationship):</strong> Relationship dependency analysis informing the Relationship Substrate lens</p>
<p><strong>4 Synthesis (What We Know and What We Don&rsquo;t):</strong> Evidence limitations context</p>
<p><strong>4 Companion A (Better Optimization):</strong> Parallel practical improvements within existing paradigm</p>
<p><strong>4 Companion B (Beyond Optimization):</strong> Paradigm shifts transcending optimization entirely</p>
<h2 id="sources">Sources<a hidden class="anchor" aria-hidden="true" href="#sources">#</a></h2>
<p>Bardach, Eugene. <em>A Practical Guide for Policy Analysis: The Eightfold Path to More Effective Problem Solving</em>. CQ Press, 4th ed., 2012.</p>
<p>Bovens, Mark, et al. <em>The Oxford Handbook of Public Accountability</em>. Oxford University Press, 2014.</p>
<p>Dorst, Kees. &ldquo;The Core of &lsquo;Design Thinking&rsquo; and Its Application.&rdquo; <em>Design Studies</em>, vol. 32, no. 6, 2011, pp. 521-532.</p>
<p>Hood, Christopher. &ldquo;A Public Management for All Seasons?&rdquo; <em>Public Administration</em>, vol. 69, no. 1, 1991, pp. 3-19.</p>
<p>Kettl, Donald F. <em>The Transformation of Governance: Public Administration for the Twenty-First Century</em>. Johns Hopkins University Press, 2002.</p>
<p>Moynihan, Donald P. <em>The Dynamics of Performance Management: Constructing Information and Reform</em>. Georgetown University Press, 2008.</p>
<p>Ostrom, Elinor. <em>Governing the Commons: The Evolution of Institutions for Collective Action</em>. Cambridge University Press, 1990.</p>
<p>Pressman, Jeffrey L., and Aaron Wildavsky. <em>Implementation: How Great Expectations in Washington Are Dashed in Oakland</em>. University of California Press, 3rd ed., 1984.</p>
<p>Scott, James C. <em>Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed</em>. Yale University Press, 1998.</p>
<p>Simon, Herbert A. <em>The Sciences of the Artificial</em>. MIT Press, 3rd ed., 1996.</p>
<p>Weick, Karl E. &ldquo;Educational Organizations as Loosely Coupled Systems.&rdquo; <em>Administrative Science Quarterly</em>, vol. 21, no. 1, 1976, pp. 1-19.</p>
<p><em>Series 5: State Agencies</em>
<em>Rural Health Transformation Project</em>
<em>Version 1: January 2026</em></p>


    </div>
  </div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/rural-health/">Rural-Health</a></li>
      <li><a href="http://localhost:1313/tags/rhtp/">Rhtp</a></li>
      <li><a href="http://localhost:1313/tags/state-policy/">State-Policy</a></li>
      <li><a href="http://localhost:1313/tags/series-5/">Series-5</a></li>
      <li><a href="http://localhost:1313/tags/companion/">Companion</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/rural-health/series-6/hospital-associations/">
    <span class="title">« Prev</span>
    <br>
    <span>Hospital Associations</span>
  </a>
  <a class="next" href="http://localhost:1313/rural-health/series-5/state-agency-decision-authority-matrix/">
    <span class="title">Next »</span>
    <br>
    <span>State Agency Decision Authority Matrix</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Seeing Differently: Design Approaches to State Agency Implementation on x"
            href="https://x.com/intent/tweet/?text=Seeing%20Differently%3a%20Design%20Approaches%20to%20State%20Agency%20Implementation&amp;url=http%3a%2f%2flocalhost%3a1313%2frural-health%2fseries-5%2fseeing-differently-design-approaches-to-state-agency-implementation%2f&amp;hashtags=rural-health%2crhtp%2cstate-policy%2cseries-5%2ccompanion">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Seeing Differently: Design Approaches to State Agency Implementation on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2frural-health%2fseries-5%2fseeing-differently-design-approaches-to-state-agency-implementation%2f&amp;title=Seeing%20Differently%3a%20Design%20Approaches%20to%20State%20Agency%20Implementation&amp;summary=Seeing%20Differently%3a%20Design%20Approaches%20to%20State%20Agency%20Implementation&amp;source=http%3a%2f%2flocalhost%3a1313%2frural-health%2fseries-5%2fseeing-differently-design-approaches-to-state-agency-implementation%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="http://localhost:1313/">Syam Adusumilli</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><div class="ggh-footer-branding">
  <a href="https://groundgame.health" target="_blank" rel="noopener">
    <img src="/images/ggh-logo.png" alt="GroundGame.Health" />
  </a>
</div>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
