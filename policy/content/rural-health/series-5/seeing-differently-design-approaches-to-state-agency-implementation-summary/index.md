---
title: "Executive Summary: Seeing Differently: Design Approaches to State Agency Implementation"
date: 2026-05-12
author: "Syam Adusumilli"
summary: "Executive summary of Seeing Differently: Design Approaches to State Agency Implementation"
tags: ["rural-health", "rhtp", "state-policy", "series-5", "summary"]
showtoc: false
ShowReadingTime: true
ShowBreadCrumbs: true
params:
  is_summary: true
  full_article_url: "../seeing-differently-design-approaches-to-state-agency-implementation/"
  article_id: "RHTP-5-Comp-S-Summary"
  collection: "rural-health"
weight: 999
cover:
  image: "cover.webp"
  alt: "Cover image"
  relative: true
build:
  list: never
---

The Rural Health Transformation Program's implementation failures stem not from poor execution but from fundamental design flaws that measurement cannot fix. State agencies struggle to coordinate across fragmented authorities, relationships collapse under the weight of compliance demands, and sophisticated requirements exceed available capacity. The conventional response proposes better metrics, improved indicators, and more sophisticated evaluation systems to track coordination effectiveness, relationship quality, and capacity development. This response extends the very measurement orientation that created the problems it now attempts to solve.

**Measurement changes what it measures**, transforming authentic phenomena into performed compliance. Relationships subjected to assessment become relationships optimized for assessors rather than collaboration optimized for communities. When CMS evaluates federal-state relationship quality, states perform relationship behaviors that satisfy evaluation criteria without necessarily producing implementation success. The Montana vignette demonstrates how genuine trust enables rapid problem-solving during hospital closures, but such trust cannot survive its transformation into tracked metrics. Leadership attention that becomes measured becomes theatrical. Political commitment that becomes assessed becomes performed. The very factors predicting implementation success, according to Series 5's analysis of state agency structures, are precisely those that measurement degrades.

The measurement trap operates through multiple mechanisms that compound dysfunction. Measurement consumes attention and capacity that could otherwise serve communities. Every hour documenting coordination is an hour not coordinating. Every staff position dedicated to reporting is a position not dedicated to service delivery. States produce performance reports satisfying federal requirements without informing state decisions, creating accountability theater where documentation substitutes for achievement. **Gaming indicators replaces achieving outcomes** as states optimize for measurable compliance rather than community benefit. The overhead of accountability crowds out the substance that accountability supposedly ensures.

Measurement creates inherently adversarial dynamics that undermine the trust implementation requires. Evaluation judges, judgment creates defensiveness, and defensiveness destroys trust. States being assessed cannot fully trust assessors regardless of evaluator intentions because the measurement relationship is structurally adversarial. This dynamic is inherent to the assessment relationship itself, not a function of individual actors' goodwill. When CMS evaluates state implementation, the evaluation introduces power dynamics that preclude the authentic partnership that successful implementation demands. The measurement system performs accountability rather than creating it.

The factors that Series 5 identified as critical for implementation success cannot be captured through measurement without destroying them. Leadership focus emerging from genuine priority differs fundamentally from leadership focus responding to measurement incentives. A governor who cares about rural health because rural communities matter behaves differently from a governor performing care because leadership attention metrics require it. The external behavior may appear similar in documentation, but the underlying commitment differs. When pressure mounts and tradeoffs sharpen, genuine commitment persists while performed commitment evaporates. Measurement cannot distinguish them until crisis reveals the difference, at which point the measurement has already failed its purpose.

**Capacity enabling implementation differs from capacity satisfying assessment.** States can document evaluation infrastructure without having functional evaluation. They can demonstrate procurement processes without executing timely procurement. They can show coordination mechanisms without coordinating effectively. Documentation and function are different things. Measurement systems accepting documentation as evidence of capacity systematically overestimate actual capacity because documentation is easier than function. The result is that federal oversight believes capacity exists based on documented processes while implementation fails because functional capacity remains absent.

The alternative to measurement-driven implementation is design thinking applied to structural challenges. Rather than asking how to measure alignment, ask how to design systems where alignment emerges naturally from structure. Not "how do we assess relationship quality?" but "what conditions make collaboration rational rather than performed?" Not "how do we track capacity development?" but "what program requirements match available capacity rather than requiring capacity that does not exist?" **Design creates conditions while measurement merely documents conditions.** When conditions are wrong, measurement documents failure without changing it. When conditions are right, measurement becomes unnecessary because success emerges from the conditions themselves.

The authority clarity lens reveals that coordination requirements are design failures made visible. Every coordination mechanism represents a point where someone designed a system requiring coordination. Michigan's consolidated Department of Health and Human Services holds authority that Georgia distributes across separate departments for community health and public health. Michigan requires less coordination because Michigan's design consolidated what Georgia's design fragmented. For Georgia, the solution is not better coordination infrastructure but authority consolidation that makes coordination unnecessary. Whether Georgia can achieve consolidation depends on political factors outside program control, but the design insight remains valid. Coordination over integration represents a second-best approach. Where consolidation proves politically impossible, clean separation with clear boundaries requires less coordination than messy integration with overlapping authorities. The goal is reducing coordination requirements, not improving coordination effectiveness.

The incentive alignment lens demonstrates that state and federal interests diverge because program design creates divergence. The misalignment is not natural but designed. RHTP funds flow for performed processes rather than achieved outcomes, creating incentive to document activities regardless of results. Alternative design where funds flow for demonstrated health improvement would align state incentives with federal objectives without compliance measurement. States would pursue outcomes because funding depends on outcomes, not because oversight systems pressure outcome pursuit. **Risk sharing over risk transfer** would align federal and state incentives around program success. Current design transfers all implementation risk to states while CMS bears no risk from program design failures. This misaligns incentives because CMS designs programs without bearing design failure costs while states implement programs bearing all failure costs including those caused by inadequate design. Shared risk arrangements would create federal accountability for design adequacy.

The 2030 sustainability cliff illustrates profound incentive misalignment. States must build systems potentially not surviving beyond program termination. Governors investing in programs that collapse after they leave office gain little political benefit while bearing substantial risk that they built something that failed. Federal design created this sustainability disincentive. Automatic RHTP extension contingent on outcome achievement would align gubernatorial incentives with sustainability investment without requiring sustainability metrics. Governors would pursue sustainable systems because success produces continuation, not because compliance systems track sustainability planning.

The capacity reality lens exposes how programs are designed without capacity constraints, guaranteeing implementation failure. RHTP requirements assume evaluation capacity, procurement speed, and coordination sophistication that many states demonstrably lack. **Design to capacity rather than designing beyond capacity and hoping capacity catches up.** Massachusetts has evaluation infrastructure that Kansas lacks. California has procurement systems that Wyoming cannot match. Uniform requirements guarantee that high-capacity states are under-challenged while low-capacity states are overwhelmed. Tiered program designs matching sophisticated versions to states that can implement them and simplified versions to states that cannot would align implementation requirements with implementation ability. Capacity building takes years. Design simplification takes decisions. RHTP's five-year timeline provides insufficient time for substantial capacity development in low-capacity states. Treating capacity as constraint produces realistic plans that can succeed. Treating capacity as variable produces aspirational plans that fail while waiting for capacity that may never arrive.

The relationship substrate lens shows that relationships matter because program design creates relationship dependency. The Montana vignette demonstrates how strong federal-state relationships enable rapid problem-solving during provider crises. The Georgia vignette shows how weak relationships produce delays harming communities. The standard response invests in relationship building through trust cultivation and partnership development. This response treats relationships as programmable when they emerge from personal chemistry, accumulated history, institutional culture, and circumstances that programs cannot mandate. Some project officers and state directors will develop trust. Others will not. **Robust design works with bad relationships while performing better with good ones.** Systems requiring good relationships to succeed are fragile. Designs succeeding adequately with weak relationships while performing better with strong ones are robust. Montana's rapid crisis response reflected strong relationships, but implementation design could have enabled adequate response regardless of relationship quality. Automatic flexibility for defined circumstances would remove relationship dependency from flexibility access. States with weak CMS relationships would access the same flexibility as states with strong relationships because flexibility would be structural rather than relational.

The political economy lens recognizes that political constraints exist because program design ignores political reality. Governors will pursue electoral advantage. Legislators will respond to influential interests. Providers will protect economic position. These behaviors are not failures of political will but predictable responses to political incentives. Program design ignoring these incentives designs for a political world that does not exist. RHTP design that enables gubernatorial credit-claiming generates gubernatorial support without requiring governors to transcend political self-interest. Design reserving credit for federal officials generates less state political investment. Blame avoidance matters more than credit opportunity. Politicians fear programs creating blame risk more than they value programs creating credit opportunity. RHTP design concentrating blame on states for implementation failures while diffusing credit for federal investment creates political incentive to minimize engagement. Design protecting state officials from blame for design failures would enable implementation investment by reducing political risk. The electoral cycle reality means governors facing reelection invest in visible quick wins rather than long-term system building. RHTP's five-year timeline spans multiple electoral cycles. Design producing early visible wins that governors can claim would align electoral incentives with implementation investment.

The community agency lens exposes how participation without power produces theater rather than genuine engagement. Advisory committees providing input that agencies may or may not incorporate teach community members their time is wasted. Stakeholder processes soliciting perspectives without changing decisions produce cynicism undermining future engagement. **Transfer authority, not process.** Communities deciding implementation details engage differently than communities advising on decisions others make. The difference is not participation level but authority distribution. Community members asked "what do you think we should do?" engage differently than community members asked "what